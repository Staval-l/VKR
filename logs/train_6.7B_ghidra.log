[2025-04-26 10:11:55,854] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-26 10:11:57,611] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0: setting --include=localhost:0
[2025-04-26 10:11:57,611] [INFO] [runner.py:605:main] cmd = /home/staval/anaconda3/envs/llm4decompile/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None finetune.py --model_name_or_path deepseek-ai/deepseek-coder-6.7b-base --data_path /home/staval/LLM4Decompile/train/decompile-ghidra-100k.json --output_dir /home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base-ghidra --num_train_epochs 2 --model_max_length 1024 --per_device_train_batch_size 16 --gradient_accumulation_steps 16 --save_steps 3000 --save_total_limit 100 --learning_rate 2e-5 --max_grad_norm 1.0 --weight_decay 0.1 --warmup_ratio 0.025 --logging_steps 1 --lr_scheduler_type cosine --gradient_checkpointing True --report_to none --fp16 False --bf16 True --fp16_full_eval=False
[2025-04-26 10:11:58,523] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-26 10:12:00,269] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2025-04-26 10:12:00,269] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-04-26 10:12:00,269] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-04-26 10:12:00,269] [INFO] [launch.py:164:main] dist_world_size=1
[2025-04-26 10:12:00,269] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2025-04-26 10:12:00,270] [INFO] [launch.py:256:main] process 81340 spawned with command: ['/home/staval/anaconda3/envs/llm4decompile/bin/python', '-u', 'finetune.py', '--local_rank=0', '--model_name_or_path', 'deepseek-ai/deepseek-coder-6.7b-base', '--data_path', '/home/staval/LLM4Decompile/train/decompile-ghidra-100k.json', '--output_dir', '/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base-ghidra', '--num_train_epochs', '2', '--model_max_length', '1024', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '16', '--save_steps', '3000', '--save_total_limit', '100', '--learning_rate', '2e-5', '--max_grad_norm', '1.0', '--weight_decay', '0.1', '--warmup_ratio', '0.025', '--logging_steps', '1', '--lr_scheduler_type', 'cosine', '--gradient_checkpointing', 'True', '--report_to', 'none', '--fp16', 'False', '--bf16', 'True', '--fp16_full_eval=False']
[2025-04-26 10:12:02,114] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W CUDAAllocatorConfig.h:30] Warning: expandable_segments not supported on this platform (function operator())
====================================================================================================
TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=16,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base-ghidra/runs/Apr26_10-12-03_compute03,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
model_max_length=1024,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=2.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base-ghidra,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base-ghidra,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=3000,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tp_size=0,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.025,
warmup_steps=0,
weight_decay=0.1,
)
PAD Token: <｜end▁of▁sentence｜> 32014
BOS Token <｜begin▁of▁sentence｜> 32013
EOS Token <｜end▁of▁sentence｜> 32014
Load tokenizer from deepseek-ai/deepseek-coder-6.7b-base over.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 62.71it/s]
Load model from deepseek-ai/deepseek-coder-6.7b-base over.
Training dataset samples: 100000
Sample 18818 of the training set: [32013, 2, 997, 317, 254, 14664, 2974, 25, 185, 4563, 631, 2600, 7, 569, 17991, 62, 16, 11, 5897, 572, 2280, 62, 17, 8, 185, 185, 90, 185, 207, 1555, 572, 6338, 15287, 16, 26, 185, 207, 1555, 258, 15287, 17, 26, 185, 243, 185, 207, 258, 15287, 17, 405, 572, 2280, 62, 17, 26, 185, 207, 1470, 334, 66, 15287, 17, 2069, 28, 20521, 15, 2462, 507, 185, 315, 631, 2600, 62, 16, 5897, 1293, 185, 315, 17198, 15287, 16, 405, 17991, 62, 17, 4536, 16, 26, 185, 315, 17991, 62, 17, 405, 17991, 62, 17, 4536, 16, 26, 185, 315, 258, 15287, 17, 405, 572, 6338, 15287, 16, 26, 185, 207, 611, 185, 207, 562, 334, 2280, 62, 16, 7400, 15, 8, 507, 185, 315, 967, 26, 185, 207, 611, 185, 207, 631, 2600, 62, 16, 5897, 7, 16, 15, 477, 185, 207, 967, 26, 185, 92, 185, 2, 2450, 317, 254, 3117, 2974, 30, 185, 4563, 631, 2600, 7, 569, 13508, 62, 29365, 11, 1133, 1555, 572, 82, 8, 185, 90, 185, 1555, 258, 26, 185, 1470, 8178, 66, 405, 572, 82, 8, 2069, 28, 20521, 15, 2462, 507, 185, 243, 3868, 82, 26, 185, 207, 631, 2600, 62, 16, 5897, 7, 66, 477, 185, 611, 185, 562, 334, 6880, 62, 29365, 8, 185, 207, 631, 2600, 62, 16, 5897, 1497, 59, 77, 3398, 185, 92, 185, 32014], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4563, 631, 2600, 7, 569, 13508, 62, 29365, 11, 1133, 1555, 572, 82, 8, 185, 90, 185, 1555, 258, 26, 185, 1470, 8178, 66, 405, 572, 82, 8, 2069, 28, 20521, 15, 2462, 507, 185, 243, 3868, 82, 26, 185, 207, 631, 2600, 62, 16, 5897, 7, 66, 477, 185, 611, 185, 562, 334, 6880, 62, 29365, 8, 185, 207, 631, 2600, 62, 16, 5897, 1497, 59, 77, 3398, 185, 92, 185, 32014].
Sample 18818 of the training set: <｜begin▁of▁sentence｜># This is the assembly code:
void outstring(int param_1,char *param_2)

{
  char *pcVar1;
  char cVar2;
  
  cVar2 = *param_2;
  while (cVar2 != '\0') {
    outstring_1char();
    pcVar1 = param_2 + 1;
    param_2 = param_2 + 1;
    cVar2 = *pcVar1;
  }
  if (param_1 == 0) {
    return;
  }
  outstring_1char(10);
  return;
}
# What is the source code?
void outstring(int append_newline, const char *s)
{
 char c;
 while ((c = *s) != '\0') {
  ++s;
  outstring_1char(c);
 }
 if (append_newline)
  outstring_1char('\n');
}
<｜end▁of▁sentence｜>.
Sample 3994 of the training set: [32013, 2, 997, 317, 254, 14664, 2974, 25, 185, 23470, 23, 626, 62, 2006, 62, 76, 556, 370, 81, 7, 5897, 9220, 2280, 62, 16, 11, 5897, 572, 2280, 62, 17, 8, 185, 185, 90, 185, 207, 2398, 62, 83, 252, 15287, 16, 26, 185, 207, 1555, 572, 1437, 9705, 26, 185, 243, 185, 207, 562, 7384, 2280, 62, 16, 2069, 28, 334, 5897, 12376, 15, 87, 15, 8, 507, 185, 315, 2082, 14685, 2280, 62, 16, 477, 185, 207, 611, 185, 207, 572, 2280, 62, 16, 405, 334, 5897, 12376, 15, 87, 15, 26, 185, 207, 562, 334, 2280, 62, 17, 2069, 28, 334, 5897, 12376, 15, 87, 15, 8, 507, 185, 315, 252, 15287, 16, 405, 1401, 6446, 7, 2280, 62, 17, 477, 185, 315, 5576, 9705, 405, 334, 5897, 12376, 76, 14314, 7, 82, 15287, 16, 4536, 16, 477, 185, 315, 572, 2280, 62, 16, 405, 5576, 9705, 26, 185, 315, 562, 334, 1437, 9705, 2069, 28, 334, 5897, 12376, 15, 87, 15, 8, 507, 185, 730, 1401, 66, 4016, 21161, 9705, 11, 2280, 62, 17, 477, 185, 730, 967, 207, 16, 26, 185, 315, 611, 185, 207, 611, 185, 207, 967, 207, 15, 26, 185, 92, 185, 2, 2450, 317, 254, 3117, 2974, 30, 185, 569, 626, 62, 2006, 62, 76, 556, 370, 81, 7, 5897, 9220, 67, 11, 1133, 1555, 572, 82, 8, 185, 90, 185, 315, 562, 334, 572, 67, 2069, 28, 4579, 2189, 185, 436, 2082, 14685, 67, 477, 185, 185, 315, 572, 67, 405, 4579, 26, 185, 185, 315, 562, 334, 252, 2312, 4579, 2189, 185, 436, 967, 207, 15, 26, 185, 185, 315, 562, 334, 4579, 2312, 7384, 67, 405, 334, 5897, 10230, 76, 14314, 7, 2006, 6446, 7, 82, 8, 4536, 16, 8, 2189, 2189, 185, 436, 967, 207, 15, 26, 185, 185, 315, 1401, 66, 4016, 7, 334, 5897, 9, 4932, 9, 67, 650, 252, 4363, 185, 185, 315, 967, 207, 16, 26, 185, 92, 185, 32014], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 569, 626, 62, 2006, 62, 76, 556, 370, 81, 7, 5897, 9220, 67, 11, 1133, 1555, 572, 82, 8, 185, 90, 185, 315, 562, 334, 572, 67, 2069, 28, 4579, 2189, 185, 436, 2082, 14685, 67, 477, 185, 185, 315, 572, 67, 405, 4579, 26, 185, 185, 315, 562, 334, 252, 2312, 4579, 2189, 185, 436, 967, 207, 15, 26, 185, 185, 315, 562, 334, 4579, 2312, 7384, 67, 405, 334, 5897, 10230, 76, 14314, 7, 2006, 6446, 7, 82, 8, 4536, 16, 8, 2189, 2189, 185, 436, 967, 207, 15, 26, 185, 185, 315, 1401, 66, 4016, 7, 334, 5897, 9, 4932, 9, 67, 650, 252, 4363, 185, 185, 315, 967, 207, 16, 26, 185, 92, 185, 32014].
Sample 3994 of the training set: <｜begin▁of▁sentence｜># This is the assembly code:
undefined8 ap_str_makestr(char **param_1,char *param_2)

{
  size_t sVar1;
  char *__dest;
  
  if (*param_1 != (char *)0x0) {
    free(*param_1);
  }
  *param_1 = (char *)0x0;
  if (param_2 != (char *)0x0) {
    sVar1 = strlen(param_2);
    __dest = (char *)malloc(sVar1 + 1);
    *param_1 = __dest;
    if (__dest != (char *)0x0) {
      strcpy(__dest,param_2);
      return 1;
    }
  }
  return 0;
}
# What is the source code?
int ap_str_makestr(char **d, const char *s)
{
    if ( *d != NULL )
        free(*d);

    *d = NULL;

    if ( s == NULL )
        return 0;

    if ( NULL == (*d = (char*)malloc(strlen(s) + 1) ) )
        return 0;

    strcpy( (char*)(*d), s );

    return 1;
}
<｜end▁of▁sentence｜>.
Sample 71473 of the training set: [32013, 2, 997, 317, 254, 14664, 2974, 25, 185, 23470, 19, 12363, 62, 3098, 47, 301, 2091, 25409, 546, 795, 1982, 1029, 7, 23470, 19, 17991, 62, 16, 8, 185, 185, 90, 185, 207, 1097, 460, 15287, 16, 26, 185, 207, 1097, 460, 15287, 17, 26, 185, 207, 12046, 19, 2631, 15287, 18, 26, 185, 207, 12046, 19, 2631, 15287, 19, 26, 185, 207, 1232, 284, 15287, 20, 26, 185, 243, 185, 207, 460, 15287, 16, 405, 12363, 62, 11835, 4104, 11502, 566, 43, 1043, 1293, 185, 207, 2631, 15287, 18, 405, 29624, 26, 185, 207, 562, 334, 72, 15287, 16, 7400, 16, 8, 507, 185, 315, 327, 334, 72, 15287, 16, 405, 12363, 62, 6308, 43, 260, 4671, 1293, 460, 15287, 17, 405, 12363, 62, 6308, 11502, 566, 271, 289, 43, 260, 4671, 7, 2280, 62, 16, 650, 185, 436, 460, 15287, 16, 1013, 460, 15287, 17, 26, 460, 15287, 16, 405, 460, 15287, 16, 4536, 16, 8, 507, 185, 730, 2631, 15287, 18, 405, 12363, 62, 3106, 30756, 7, 2280, 62, 16, 11, 72, 15287, 16, 477, 185, 730, 2631, 15287, 19, 405, 12363, 62, 30756, 3554, 283, 7, 84, 15287, 18, 477, 185, 730, 2631, 15287, 19, 405, 1632, 62, 8955, 15446, 7, 84, 15287, 19, 477, 185, 730, 284, 15287, 20, 405, 7201, 62, 3098, 7190, 25409, 7, 84, 15287, 19, 477, 185, 730, 562, 334, 75, 15287, 20, 7400, 15, 8, 507, 185, 436, 967, 29624, 26, 185, 730, 611, 185, 730, 2631, 15287, 18, 405, 12363, 62, 30756, 3554, 283, 7, 84, 15287, 18, 477, 185, 730, 2631, 15287, 18, 405, 1632, 62, 6308, 12941, 7, 84, 15287, 18, 477, 185, 730, 460, 15287, 17, 405, 1632, 62, 3098, 20309, 7, 84, 15287, 18, 477, 185, 730, 562, 334, 72, 15287, 17, 7400, 15, 8, 507, 185, 436, 967, 29624, 26, 185, 730, 611, 185, 315, 611, 185, 315, 2631, 15287, 18, 405, 12363, 62, 6308, 11502, 566, 271, 289, 43, 260, 4671, 7, 2280, 62, 16, 477, 185, 315, 2631, 15287, 18, 405, 12363, 62, 3106, 30756, 7, 2280, 62, 16, 11, 84, 15287, 18, 477, 185, 315, 2631, 15287, 18, 405, 12363, 62, 30756, 50, 4367, 3554, 283, 7, 84, 15287, 18, 477, 185, 315, 2631, 15287, 18, 405, 1632, 62, 8955, 15446, 7, 84, 15287, 18, 477, 185, 315, 284, 15287, 20, 405, 7201, 62, 3098, 7190, 25409, 7, 84, 15287, 18, 477, 185, 315, 2631, 15287, 18, 405, 29875, 26, 185, 315, 562, 334, 75, 15287, 20, 7400, 15, 8, 507, 185, 730, 2631, 15287, 18, 405, 29624, 26, 185, 315, 611, 185, 207, 611, 185, 207, 967, 2631, 15287, 18, 26, 185, 92, 185, 2, 2450, 317, 254, 3117, 2974, 30, 185, 9311, 4845, 12363, 62, 3098, 47, 301, 2091, 25409, 546, 795, 1982, 1029, 7, 18630, 15778, 1854, 1029, 11, 416, 3949, 38, 1428, 46, 1369, 3895, 3727, 11, 185, 251, 375, 1369, 34, 2289, 26649, 7606, 1639, 720, 8, 185, 185, 185, 185, 185, 185, 185, 185, 90, 185, 207, 412, 2105, 27314, 412, 260, 26, 185, 207, 1097, 460, 26, 185, 2, 207, 18, 23, 23, 16, 10171, 8864, 1235, 14, 248, 937, 14, 1829, 14, 5816, 14, 73, 689, 72, 62, 1765, 1225, 313, 62, 370, 2560, 14, 66, 12, 866, 1252, 250, 14, 8164, 82, 14, 17, 15, 17, 17, 12, 15, 16, 12, 17, 17, 14, 15, 17, 12, 16, 24, 12, 20, 22, 14, 248, 937, 14, 27057, 25486, 12, 41, 1143, 347, 14, 51, 266, 378, 14, 632, 82, 14, 2381, 82, 14, 10041, 14, 5971, 31188, 12, 18, 13, 22, 14, 5971, 31188, 14, 535, 1029, 13, 66, 1, 185, 207, 562, 334, 535, 1029, 62, 11835, 4104, 11502, 566, 43, 1043, 7, 1982, 1029, 8, 2069, 4084, 16, 8, 185, 315, 967, 29624, 26, 185, 185, 207, 327, 334, 72, 28, 535, 1029, 62, 6308, 43, 260, 4671, 1293, 72, 27, 535, 1029, 62, 6308, 11502, 566, 271, 289, 43, 260, 4671, 7, 1982, 1029, 477, 72, 3868, 8, 507, 185, 315, 412, 260, 405, 12363, 62, 3106, 30756, 7, 1982, 1029, 11, 72, 477, 185, 315, 562, 5036, 18027, 62, 3098, 7190, 25409, 7, 7683, 62, 8955, 15446, 7, 535, 1029, 62, 30756, 3554, 283, 7, 43, 260, 13773, 1550, 185, 2069, 7683, 62, 3098, 20309, 7, 7683, 62, 6308, 12941, 7, 535, 1029, 62, 30756, 3554, 283, 7, 43, 260, 1435, 1435, 185, 730, 967, 29624, 26, 185, 207, 611, 185, 185, 207, 412, 260, 405, 12363, 62, 3106, 30756, 7, 1982, 1029, 11, 535, 1029, 62, 6308, 11502, 566, 271, 289, 43, 260, 4671, 7, 1982, 1029, 3183, 185, 207, 562, 334, 18027, 62, 3098, 7190, 25409, 7, 7683, 62, 8955, 15446, 7, 535, 1029, 62, 30756, 50, 4367, 3554, 283, 7, 43, 260, 1435, 1435, 185, 315, 967, 29875, 26, 185, 185, 207, 967, 29624, 26, 185, 92, 185, 32014], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 9311, 4845, 12363, 62, 3098, 47, 301, 2091, 25409, 546, 795, 1982, 1029, 7, 18630, 15778, 1854, 1029, 11, 416, 3949, 38, 1428, 46, 1369, 3895, 3727, 11, 185, 251, 375, 1369, 34, 2289, 26649, 7606, 1639, 720, 8, 185, 185, 185, 185, 185, 185, 185, 185, 90, 185, 207, 412, 2105, 27314, 412, 260, 26, 185, 207, 1097, 460, 26, 185, 2, 207, 18, 23, 23, 16, 10171, 8864, 1235, 14, 248, 937, 14, 1829, 14, 5816, 14, 73, 689, 72, 62, 1765, 1225, 313, 62, 370, 2560, 14, 66, 12, 866, 1252, 250, 14, 8164, 82, 14, 17, 15, 17, 17, 12, 15, 16, 12, 17, 17, 14, 15, 17, 12, 16, 24, 12, 20, 22, 14, 248, 937, 14, 27057, 25486, 12, 41, 1143, 347, 14, 51, 266, 378, 14, 632, 82, 14, 2381, 82, 14, 10041, 14, 5971, 31188, 12, 18, 13, 22, 14, 5971, 31188, 14, 535, 1029, 13, 66, 1, 185, 207, 562, 334, 535, 1029, 62, 11835, 4104, 11502, 566, 43, 1043, 7, 1982, 1029, 8, 2069, 4084, 16, 8, 185, 315, 967, 29624, 26, 185, 185, 207, 327, 334, 72, 28, 535, 1029, 62, 6308, 43, 260, 4671, 1293, 72, 27, 535, 1029, 62, 6308, 11502, 566, 271, 289, 43, 260, 4671, 7, 1982, 1029, 477, 72, 3868, 8, 507, 185, 315, 412, 260, 405, 12363, 62, 3106, 30756, 7, 1982, 1029, 11, 72, 477, 185, 315, 562, 5036, 18027, 62, 3098, 7190, 25409, 7, 7683, 62, 8955, 15446, 7, 535, 1029, 62, 30756, 3554, 283, 7, 43, 260, 13773, 1550, 185, 2069, 7683, 62, 3098, 20309, 7, 7683, 62, 6308, 12941, 7, 535, 1029, 62, 30756, 3554, 283, 7, 43, 260, 1435, 1435, 185, 730, 967, 29624, 26, 185, 207, 611, 185, 185, 207, 412, 260, 405, 12363, 62, 3106, 30756, 7, 1982, 1029, 11, 535, 1029, 62, 6308, 11502, 566, 271, 289, 43, 260, 4671, 7, 1982, 1029, 3183, 185, 207, 562, 334, 18027, 62, 3098, 7190, 25409, 7, 7683, 62, 8955, 15446, 7, 535, 1029, 62, 30756, 50, 4367, 3554, 283, 7, 43, 260, 1435, 1435, 185, 315, 967, 29875, 26, 185, 185, 207, 967, 29624, 26, 185, 92, 185, 32014].
Sample 71473 of the training set: <｜begin▁of▁sentence｜># This is the assembly code:
undefined4 clause_IsPotentialSortTheoryClause(undefined4 param_1)

{
  int iVar1;
  int iVar2;
  undefined4 uVar3;
  undefined4 uVar4;
  long lVar5;
  
  iVar1 = clause_NumOfSuccLits();
  uVar3 = FALSE;
  if (iVar1 == 1) {
    for (iVar1 = clause_FirstLitIndex(); iVar2 = clause_FirstSuccedentLitIndex(param_1),
        iVar1 < iVar2; iVar1 = iVar1 + 1) {
      uVar3 = clause_GetLiteral(param_1,iVar1);
      uVar4 = clause_LiteralAtom(uVar3);
      uVar4 = term_TopSymbol(uVar4);
      lVar5 = symbol_IsBaseSort(uVar4);
      if (lVar5 == 0) {
        return FALSE;
      }
      uVar3 = clause_LiteralAtom(uVar3);
      uVar3 = term_FirstArgument(uVar3);
      iVar2 = term_IsVariable(uVar3);
      if (iVar2 == 0) {
        return FALSE;
      }
    }
    uVar3 = clause_FirstSuccedentLitIndex(param_1);
    uVar3 = clause_GetLiteral(param_1,uVar3);
    uVar3 = clause_LiteralSignedAtom(uVar3);
    uVar3 = term_TopSymbol(uVar3);
    lVar5 = symbol_IsBaseSort(uVar3);
    uVar3 = TRUE;
    if (lVar5 == 0) {
      uVar3 = FALSE;
    }
  }
  return uVar3;
}
# What is the source code?
BOOL clause_IsPotentialSortTheoryClause(CLAUSE Clause, FLAGSTORE Flags,
     PRECEDENCE Precedence)







{
  LITERAL Lit;
  int i;
# 3881 "/scratch/repos/new/home/jordi_armengol_estape/c-scraper/outputs/2022-01-22/02-19-57/repos/JamesPane-Joyce/Talos/refs/heads/master/SPASS-3.7/SPASS/clause.c"
  if (clause_NumOfSuccLits(Clause) != 1)
    return FALSE;

  for (i=clause_FirstLitIndex();i<clause_FirstSuccedentLitIndex(Clause);i++) {
    Lit = clause_GetLiteral(Clause,i);
    if (!symbol_IsBaseSort(term_TopSymbol(clause_LiteralAtom(Lit))) ||
 !term_IsVariable(term_FirstArgument(clause_LiteralAtom(Lit))))
      return FALSE;
  }

  Lit = clause_GetLiteral(Clause,clause_FirstSuccedentLitIndex(Clause));
  if (symbol_IsBaseSort(term_TopSymbol(clause_LiteralSignedAtom(Lit))))
    return TRUE;

  return FALSE;
}
<｜end▁of▁sentence｜>.
/home/staval/LLM4Decompile/train/finetune.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
  0%|          | 0/780 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 1/780 [00:44<9:41:55, 44.82s/it]                                                 {'loss': 0.6132, 'grad_norm': 1.6796875, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/780 [00:44<9:41:55, 44.82s/it]  0%|          | 2/780 [01:28<9:35:31, 44.39s/it]                                                 {'loss': 0.6034, 'grad_norm': 1.609375, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}
  0%|          | 2/780 [01:28<9:35:31, 44.39s/it]  0%|          | 3/780 [02:14<9:44:07, 45.11s/it]                                                 {'loss': 0.6045, 'grad_norm': 1.6953125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
  0%|          | 3/780 [02:14<9:44:07, 45.11s/it]  1%|          | 4/780 [02:57<9:29:03, 44.00s/it]                                                 {'loss': 0.6444, 'grad_norm': 1.6484375, 'learning_rate': 3e-06, 'epoch': 0.01}
  1%|          | 4/780 [02:57<9:29:03, 44.00s/it]  1%|          | 5/780 [03:41<9:31:21, 44.23s/it]                                                 {'loss': 0.6271, 'grad_norm': 1.546875, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 5/780 [03:41<9:31:21, 44.23s/it]  1%|          | 6/780 [04:28<9:43:04, 45.20s/it]                                                 {'loss': 0.5735, 'grad_norm': 1.4140625, 'learning_rate': 5e-06, 'epoch': 0.02}
  1%|          | 6/780 [04:28<9:43:04, 45.20s/it]  1%|          | 7/780 [05:14<9:43:01, 45.25s/it]                                                 {'loss': 0.5912, 'grad_norm': 1.2421875, 'learning_rate': 6e-06, 'epoch': 0.02}
  1%|          | 7/780 [05:14<9:43:01, 45.25s/it]  1%|          | 8/780 [05:59<9:44:02, 45.39s/it]                                                 {'loss': 0.6209, 'grad_norm': 1.0703125, 'learning_rate': 7e-06, 'epoch': 0.02}
  1%|          | 8/780 [06:00<9:44:02, 45.39s/it]  1%|          | 9/780 [06:39<9:21:28, 43.69s/it]                                                 {'loss': 0.6172, 'grad_norm': 1.0078125, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}
  1%|          | 9/780 [06:39<9:21:28, 43.69s/it]  1%|▏         | 10/780 [07:25<9:29:19, 44.36s/it]                                                  {'loss': 0.5931, 'grad_norm': 0.7265625, 'learning_rate': 9e-06, 'epoch': 0.03}
  1%|▏         | 10/780 [07:25<9:29:19, 44.36s/it]  1%|▏         | 11/780 [08:12<9:38:49, 45.16s/it]                                                  {'loss': 0.5642, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.03}
  1%|▏         | 11/780 [08:12<9:38:49, 45.16s/it]  2%|▏         | 12/780 [08:56<9:32:18, 44.71s/it]                                                  {'loss': 0.5852, 'grad_norm': 0.58203125, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.03}
  2%|▏         | 12/780 [08:56<9:32:18, 44.71s/it]  2%|▏         | 13/780 [09:41<9:31:22, 44.70s/it]                                                  {'loss': 0.559, 'grad_norm': 0.5234375, 'learning_rate': 1.2e-05, 'epoch': 0.03}
  2%|▏         | 13/780 [09:41<9:31:22, 44.70s/it]  2%|▏         | 14/780 [10:25<9:31:19, 44.75s/it]                                                  {'loss': 0.5481, 'grad_norm': 0.484375, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.04}
  2%|▏         | 14/780 [10:26<9:31:19, 44.75s/it]  2%|▏         | 15/780 [11:11<9:35:25, 45.13s/it]                                                  {'loss': 0.5271, 'grad_norm': 0.443359375, 'learning_rate': 1.4e-05, 'epoch': 0.04}
  2%|▏         | 15/780 [11:12<9:35:25, 45.13s/it]  2%|▏         | 16/780 [11:58<9:39:34, 45.52s/it]                                                  {'loss': 0.5032, 'grad_norm': 0.419921875, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.04}
  2%|▏         | 16/780 [11:58<9:39:34, 45.52s/it]  2%|▏         | 17/780 [12:43<9:38:43, 45.51s/it]                                                  {'loss': 0.5026, 'grad_norm': 0.392578125, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.04}
  2%|▏         | 17/780 [12:43<9:38:43, 45.51s/it]  2%|▏         | 18/780 [13:26<9:26:00, 44.57s/it]                                                  {'loss': 0.519, 'grad_norm': 0.4375, 'learning_rate': 1.7e-05, 'epoch': 0.05}
  2%|▏         | 18/780 [13:26<9:26:00, 44.57s/it]  2%|▏         | 19/780 [14:12<9:32:44, 45.16s/it]                                                  {'loss': 0.4844, 'grad_norm': 0.41015625, 'learning_rate': 1.8e-05, 'epoch': 0.05}
  2%|▏         | 19/780 [14:12<9:32:44, 45.16s/it]  3%|▎         | 20/780 [14:57<9:30:20, 45.03s/it]                                                  {'loss': 0.5098, 'grad_norm': 0.3984375, 'learning_rate': 1.9e-05, 'epoch': 0.05}
  3%|▎         | 20/780 [14:57<9:30:20, 45.03s/it]  3%|▎         | 21/780 [15:40<9:21:57, 44.42s/it]                                                  {'loss': 0.4793, 'grad_norm': 0.9140625, 'learning_rate': 2e-05, 'epoch': 0.05}
  3%|▎         | 21/780 [15:40<9:21:57, 44.42s/it]  3%|▎         | 22/780 [16:24<9:19:33, 44.29s/it]                                                  {'loss': 0.5054, 'grad_norm': 0.41796875, 'learning_rate': 1.999991456379547e-05, 'epoch': 0.06}
  3%|▎         | 22/780 [16:24<9:19:33, 44.29s/it]  3%|▎         | 23/780 [17:05<9:07:58, 43.43s/it]                                                  {'loss': 0.5088, 'grad_norm': 0.42578125, 'learning_rate': 1.9999658256641746e-05, 'epoch': 0.06}
  3%|▎         | 23/780 [17:05<9:07:58, 43.43s/it]  3%|▎         | 24/780 [17:51<9:17:02, 44.21s/it]                                                  {'loss': 0.4864, 'grad_norm': 0.359375, 'learning_rate': 1.9999231082918415e-05, 'epoch': 0.06}
  3%|▎         | 24/780 [17:52<9:17:02, 44.21s/it]  3%|▎         | 25/780 [18:35<9:12:01, 43.87s/it]                                                  {'loss': 0.4775, 'grad_norm': 0.390625, 'learning_rate': 1.9998633049924693e-05, 'epoch': 0.06}
  3%|▎         | 25/780 [18:35<9:12:01, 43.87s/it]  3%|▎         | 26/780 [19:18<9:09:36, 43.74s/it]                                                  {'loss': 0.4855, 'grad_norm': 0.34765625, 'learning_rate': 1.9997864167879313e-05, 'epoch': 0.07}
  3%|▎         | 26/780 [19:18<9:09:36, 43.74s/it]  3%|▎         | 27/780 [20:03<9:13:42, 44.12s/it]                                                  {'loss': 0.4997, 'grad_norm': 0.341796875, 'learning_rate': 1.999692444992035e-05, 'epoch': 0.07}
  3%|▎         | 27/780 [20:03<9:13:42, 44.12s/it]  4%|▎         | 28/780 [20:47<9:13:28, 44.16s/it]                                                  {'loss': 0.4929, 'grad_norm': 0.36328125, 'learning_rate': 1.9995813912104988e-05, 'epoch': 0.07}
  4%|▎         | 28/780 [20:47<9:13:28, 44.16s/it]  4%|▎         | 29/780 [21:33<9:17:20, 44.53s/it]                                                  {'loss': 0.4391, 'grad_norm': 0.328125, 'learning_rate': 1.999453257340926e-05, 'epoch': 0.07}
  4%|▎         | 29/780 [21:33<9:17:20, 44.53s/it]  4%|▍         | 30/780 [22:19<9:22:01, 44.96s/it]                                                  {'loss': 0.4558, 'grad_norm': 0.35546875, 'learning_rate': 1.9993080455727705e-05, 'epoch': 0.08}
  4%|▍         | 30/780 [22:19<9:22:01, 44.96s/it]  4%|▍         | 31/780 [23:05<9:26:39, 45.39s/it]                                                  {'loss': 0.4592, 'grad_norm': 0.380859375, 'learning_rate': 1.999145758387301e-05, 'epoch': 0.08}
  4%|▍         | 31/780 [23:05<9:26:39, 45.39s/it]  4%|▍         | 32/780 [23:48<9:18:44, 44.82s/it]                                                  {'loss': 0.4473, 'grad_norm': 0.30078125, 'learning_rate': 1.9989663985575575e-05, 'epoch': 0.08}
  4%|▍         | 32/780 [23:49<9:18:44, 44.82s/it]  4%|▍         | 33/780 [24:33<9:15:17, 44.60s/it]                                                  {'loss': 0.4664, 'grad_norm': 0.453125, 'learning_rate': 1.998769969148305e-05, 'epoch': 0.08}
  4%|▍         | 33/780 [24:33<9:15:17, 44.60s/it]  4%|▍         | 34/780 [25:18<9:16:23, 44.75s/it]                                                  {'loss': 0.43, 'grad_norm': 0.44921875, 'learning_rate': 1.9985564735159796e-05, 'epoch': 0.09}
  4%|▍         | 34/780 [25:18<9:16:23, 44.75s/it]  4%|▍         | 35/780 [26:02<9:15:06, 44.71s/it]                                                  {'loss': 0.4875, 'grad_norm': 0.353515625, 'learning_rate': 1.9983259153086328e-05, 'epoch': 0.09}
  4%|▍         | 35/780 [26:02<9:15:06, 44.71s/it]  5%|▍         | 36/780 [26:46<9:10:05, 44.36s/it]                                                  {'loss': 0.5026, 'grad_norm': 0.32421875, 'learning_rate': 1.9980782984658682e-05, 'epoch': 0.09}
  5%|▍         | 36/780 [26:46<9:10:05, 44.36s/it]  5%|▍         | 37/780 [27:30<9:10:28, 44.45s/it]                                                  {'loss': 0.4601, 'grad_norm': 0.296875, 'learning_rate': 1.9978136272187745e-05, 'epoch': 0.09}
  5%|▍         | 37/780 [27:31<9:10:28, 44.45s/it]  5%|▍         | 38/780 [28:12<8:57:29, 43.46s/it]                                                  {'loss': 0.4825, 'grad_norm': 0.314453125, 'learning_rate': 1.9975319060898535e-05, 'epoch': 0.1}
  5%|▍         | 38/780 [28:12<8:57:29, 43.46s/it]  5%|▌         | 39/780 [28:58<9:07:13, 44.31s/it]                                                  {'loss': 0.4796, 'grad_norm': 0.33984375, 'learning_rate': 1.997233139892941e-05, 'epoch': 0.1}
  5%|▌         | 39/780 [28:58<9:07:13, 44.31s/it]  5%|▌         | 40/780 [29:43<9:11:03, 44.68s/it]                                                  {'loss': 0.4652, 'grad_norm': 0.337890625, 'learning_rate': 1.9969173337331283e-05, 'epoch': 0.1}
  5%|▌         | 40/780 [29:44<9:11:03, 44.68s/it]  5%|▌         | 41/780 [30:28<9:08:24, 44.53s/it]                                                  {'loss': 0.4211, 'grad_norm': 0.52734375, 'learning_rate': 1.99658449300667e-05, 'epoch': 0.1}
  5%|▌         | 41/780 [30:28<9:08:24, 44.53s/it]  5%|▌         | 42/780 [31:11<9:03:28, 44.18s/it]                                                  {'loss': 0.4423, 'grad_norm': 0.310546875, 'learning_rate': 1.996234623400897e-05, 'epoch': 0.11}
  5%|▌         | 42/780 [31:11<9:03:28, 44.18s/it]  6%|▌         | 43/780 [31:54<8:56:31, 43.68s/it]                                                  {'loss': 0.4555, 'grad_norm': 0.3125, 'learning_rate': 1.995867730894114e-05, 'epoch': 0.11}
  6%|▌         | 43/780 [31:54<8:56:31, 43.68s/it]  6%|▌         | 44/780 [32:38<8:58:45, 43.92s/it]                                                  {'loss': 0.4616, 'grad_norm': 0.326171875, 'learning_rate': 1.995483821755503e-05, 'epoch': 0.11}
  6%|▌         | 44/780 [32:38<8:58:45, 43.92s/it]  6%|▌         | 45/780 [33:26<9:11:09, 44.99s/it]                                                  {'loss': 0.4893, 'grad_norm': 0.40234375, 'learning_rate': 1.9950829025450116e-05, 'epoch': 0.12}
  6%|▌         | 45/780 [33:26<9:11:09, 44.99s/it]  6%|▌         | 46/780 [34:09<9:03:48, 44.45s/it]                                                  {'loss': 0.4612, 'grad_norm': 0.3359375, 'learning_rate': 1.994664980113243e-05, 'epoch': 0.12}
  6%|▌         | 46/780 [34:09<9:03:48, 44.45s/it]  6%|▌         | 47/780 [34:51<8:54:26, 43.75s/it]                                                  {'loss': 0.4575, 'grad_norm': 0.30859375, 'learning_rate': 1.9942300616013378e-05, 'epoch': 0.12}
  6%|▌         | 47/780 [34:51<8:54:26, 43.75s/it]  6%|▌         | 48/780 [35:33<8:46:40, 43.17s/it]                                                  {'loss': 0.4864, 'grad_norm': 0.32421875, 'learning_rate': 1.993778154440854e-05, 'epoch': 0.12}
  6%|▌         | 48/780 [35:33<8:46:40, 43.17s/it]  6%|▋         | 49/780 [36:19<8:56:56, 44.07s/it]                                                  {'loss': 0.4609, 'grad_norm': 0.328125, 'learning_rate': 1.9933092663536384e-05, 'epoch': 0.13}
  6%|▋         | 49/780 [36:19<8:56:56, 44.07s/it]  6%|▋         | 50/780 [37:03<8:57:06, 44.15s/it]                                                  {'loss': 0.4545, 'grad_norm': 0.314453125, 'learning_rate': 1.992823405351694e-05, 'epoch': 0.13}
  6%|▋         | 50/780 [37:03<8:57:06, 44.15s/it]  7%|▋         | 51/780 [37:48<9:00:23, 44.48s/it]                                                  {'loss': 0.4603, 'grad_norm': 0.294921875, 'learning_rate': 1.992320579737045e-05, 'epoch': 0.13}
  7%|▋         | 51/780 [37:48<9:00:23, 44.48s/it]  7%|▋         | 52/780 [38:35<9:09:01, 45.25s/it]                                                  {'loss': 0.4534, 'grad_norm': 0.310546875, 'learning_rate': 1.9918007981015942e-05, 'epoch': 0.13}
  7%|▋         | 52/780 [38:35<9:09:01, 45.25s/it]  7%|▋         | 53/780 [39:19<9:02:53, 44.81s/it]                                                  {'loss': 0.4545, 'grad_norm': 0.283203125, 'learning_rate': 1.9912640693269754e-05, 'epoch': 0.14}
  7%|▋         | 53/780 [39:19<9:02:53, 44.81s/it]  7%|▋         | 54/780 [40:05<9:04:53, 45.03s/it]                                                  {'loss': 0.4636, 'grad_norm': 0.3046875, 'learning_rate': 1.9907104025844024e-05, 'epoch': 0.14}
  7%|▋         | 54/780 [40:05<9:04:53, 45.03s/it]  7%|▋         | 55/780 [40:47<8:53:53, 44.18s/it]                                                  {'loss': 0.4535, 'grad_norm': 0.326171875, 'learning_rate': 1.990139807334512e-05, 'epoch': 0.14}
  7%|▋         | 55/780 [40:47<8:53:53, 44.18s/it]  7%|▋         | 56/780 [41:30<8:49:59, 43.92s/it]                                                  {'loss': 0.4529, 'grad_norm': 0.314453125, 'learning_rate': 1.9895522933272028e-05, 'epoch': 0.14}
  7%|▋         | 56/780 [41:30<8:49:59, 43.92s/it]  7%|▋         | 57/780 [42:16<8:54:58, 44.40s/it]                                                  {'loss': 0.3888, 'grad_norm': 0.296875, 'learning_rate': 1.9889478706014687e-05, 'epoch': 0.15}
  7%|▋         | 57/780 [42:16<8:54:58, 44.40s/it]  7%|▋         | 58/780 [43:00<8:52:41, 44.27s/it]                                                  {'loss': 0.469, 'grad_norm': 0.3046875, 'learning_rate': 1.9883265494852258e-05, 'epoch': 0.15}
  7%|▋         | 58/780 [43:00<8:52:41, 44.27s/it]  8%|▊         | 59/780 [43:46<8:59:08, 44.87s/it]                                                  {'loss': 0.4682, 'grad_norm': 0.310546875, 'learning_rate': 1.9876883405951378e-05, 'epoch': 0.15}
  8%|▊         | 59/780 [43:46<8:59:08, 44.87s/it]  8%|▊         | 60/780 [44:31<9:00:31, 45.04s/it]                                                  {'loss': 0.4836, 'grad_norm': 0.322265625, 'learning_rate': 1.9870332548364342e-05, 'epoch': 0.15}
  8%|▊         | 60/780 [44:32<9:00:31, 45.04s/it]  8%|▊         | 61/780 [45:18<9:03:23, 45.35s/it]                                                  {'loss': 0.4073, 'grad_norm': 0.33203125, 'learning_rate': 1.9863613034027224e-05, 'epoch': 0.16}
  8%|▊         | 61/780 [45:18<9:03:23, 45.35s/it]  8%|▊         | 62/780 [46:02<8:57:59, 44.96s/it]                                                  {'loss': 0.466, 'grad_norm': 0.30078125, 'learning_rate': 1.9856724977757993e-05, 'epoch': 0.16}
  8%|▊         | 62/780 [46:02<8:57:59, 44.96s/it]  8%|▊         | 63/780 [46:43<8:46:19, 44.04s/it]                                                  {'loss': 0.4254, 'grad_norm': 0.296875, 'learning_rate': 1.984966849725452e-05, 'epoch': 0.16}
  8%|▊         | 63/780 [46:44<8:46:19, 44.04s/it]  8%|▊         | 64/780 [47:29<8:49:59, 44.41s/it]                                                  {'loss': 0.4435, 'grad_norm': 0.31640625, 'learning_rate': 1.984244371309259e-05, 'epoch': 0.16}
  8%|▊         | 64/780 [47:29<8:49:59, 44.41s/it]  8%|▊         | 65/780 [48:16<9:00:45, 45.38s/it]                                                  {'loss': 0.4487, 'grad_norm': 0.306640625, 'learning_rate': 1.9835050748723826e-05, 'epoch': 0.17}
  8%|▊         | 65/780 [48:16<9:00:45, 45.38s/it]  8%|▊         | 66/780 [49:02<9:00:45, 45.44s/it]                                                  {'loss': 0.4407, 'grad_norm': 0.298828125, 'learning_rate': 1.9827489730473597e-05, 'epoch': 0.17}
  8%|▊         | 66/780 [49:02<9:00:45, 45.44s/it]  9%|▊         | 67/780 [49:48<9:02:56, 45.69s/it]                                                  {'loss': 0.4865, 'grad_norm': 0.296875, 'learning_rate': 1.981976078753884e-05, 'epoch': 0.17}
  9%|▊         | 67/780 [49:48<9:02:56, 45.69s/it]  9%|▊         | 68/780 [50:31<8:52:17, 44.86s/it]                                                  {'loss': 0.453, 'grad_norm': 0.3046875, 'learning_rate': 1.9811864051985865e-05, 'epoch': 0.17}
  9%|▊         | 68/780 [50:31<8:52:17, 44.86s/it]  9%|▉         | 69/780 [51:14<8:45:52, 44.38s/it]                                                  {'loss': 0.4615, 'grad_norm': 0.318359375, 'learning_rate': 1.9803799658748096e-05, 'epoch': 0.18}
  9%|▉         | 69/780 [51:14<8:45:52, 44.38s/it]  9%|▉         | 70/780 [51:56<8:36:01, 43.61s/it]                                                  {'loss': 0.4436, 'grad_norm': 0.3125, 'learning_rate': 1.979556774562376e-05, 'epoch': 0.18}
  9%|▉         | 70/780 [51:56<8:36:01, 43.61s/it]  9%|▉         | 71/780 [52:42<8:41:59, 44.17s/it]                                                  {'loss': 0.4168, 'grad_norm': 0.279296875, 'learning_rate': 1.9787168453273546e-05, 'epoch': 0.18}
  9%|▉         | 71/780 [52:42<8:41:59, 44.17s/it]  9%|▉         | 72/780 [53:28<8:50:27, 44.95s/it]                                                  {'loss': 0.4544, 'grad_norm': 0.306640625, 'learning_rate': 1.977860192521818e-05, 'epoch': 0.18}
  9%|▉         | 72/780 [53:29<8:50:27, 44.95s/it]  9%|▉         | 73/780 [54:16<8:57:56, 45.65s/it]                                                  {'loss': 0.4698, 'grad_norm': 0.2890625, 'learning_rate': 1.9769868307835996e-05, 'epoch': 0.19}
  9%|▉         | 73/780 [54:16<8:57:56, 45.65s/it]  9%|▉         | 74/780 [54:58<8:46:47, 44.77s/it]                                                  {'loss': 0.4429, 'grad_norm': 0.3359375, 'learning_rate': 1.976096775036041e-05, 'epoch': 0.19}
  9%|▉         | 74/780 [54:59<8:46:47, 44.77s/it] 10%|▉         | 75/780 [55:44<8:48:39, 44.99s/it]                                                  {'loss': 0.4446, 'grad_norm': 0.310546875, 'learning_rate': 1.97519004048774e-05, 'epoch': 0.19}
 10%|▉         | 75/780 [55:44<8:48:39, 44.99s/it] 10%|▉         | 76/780 [56:29<8:48:23, 45.03s/it]                                                  {'loss': 0.4443, 'grad_norm': 0.294921875, 'learning_rate': 1.9742666426322877e-05, 'epoch': 0.19}
 10%|▉         | 76/780 [56:29<8:48:23, 45.03s/it] 10%|▉         | 77/780 [57:13<8:45:20, 44.84s/it]                                                  {'loss': 0.4569, 'grad_norm': 0.296875, 'learning_rate': 1.973326597248006e-05, 'epoch': 0.2}
 10%|▉         | 77/780 [57:14<8:45:20, 44.84s/it] 10%|█         | 78/780 [57:57<8:38:22, 44.30s/it]                                                  {'loss': 0.4311, 'grad_norm': 0.326171875, 'learning_rate': 1.9723699203976768e-05, 'epoch': 0.2}
 10%|█         | 78/780 [57:57<8:38:22, 44.30s/it] 10%|█         | 79/780 [58:43<8:46:46, 45.09s/it]                                                  {'loss': 0.4598, 'grad_norm': 0.30859375, 'learning_rate': 1.9713966284282677e-05, 'epoch': 0.2}
 10%|█         | 79/780 [58:44<8:46:46, 45.09s/it] 10%|█         | 80/780 [59:28<8:42:57, 44.83s/it]                                                  {'loss': 0.4673, 'grad_norm': 0.29296875, 'learning_rate': 1.9704067379706537e-05, 'epoch': 0.2}
 10%|█         | 80/780 [59:28<8:42:57, 44.83s/it] 10%|█         | 81/780 [1:00:11<8:38:32, 44.51s/it]                                                    {'loss': 0.4229, 'grad_norm': 0.294921875, 'learning_rate': 1.9694002659393306e-05, 'epoch': 0.21}
 10%|█         | 81/780 [1:00:12<8:38:32, 44.51s/it] 11%|█         | 82/780 [1:00:57<8:41:05, 44.79s/it]                                                    {'loss': 0.4226, 'grad_norm': 0.294921875, 'learning_rate': 1.968377229532129e-05, 'epoch': 0.21}
 11%|█         | 82/780 [1:00:57<8:41:05, 44.79s/it] 11%|█         | 83/780 [1:01:42<8:41:57, 44.93s/it]                                                    {'loss': 0.4159, 'grad_norm': 0.294921875, 'learning_rate': 1.9673376462299186e-05, 'epoch': 0.21}
 11%|█         | 83/780 [1:01:42<8:41:57, 44.93s/it] 11%|█         | 84/780 [1:02:28<8:44:53, 45.25s/it]                                                    {'loss': 0.3997, 'grad_norm': 0.2890625, 'learning_rate': 1.9662815337963092e-05, 'epoch': 0.22}
 11%|█         | 84/780 [1:02:28<8:44:53, 45.25s/it] 11%|█         | 85/780 [1:03:10<8:32:24, 44.24s/it]                                                    {'loss': 0.4238, 'grad_norm': 0.30859375, 'learning_rate': 1.9652089102773487e-05, 'epoch': 0.22}
 11%|█         | 85/780 [1:03:10<8:32:24, 44.24s/it] 11%|█         | 86/780 [1:03:52<8:23:01, 43.49s/it]                                                    {'loss': 0.4246, 'grad_norm': 0.447265625, 'learning_rate': 1.9641197940012136e-05, 'epoch': 0.22}
 11%|█         | 86/780 [1:03:52<8:23:01, 43.49s/it] 11%|█         | 87/780 [1:04:36<8:23:36, 43.60s/it]                                                    {'loss': 0.4211, 'grad_norm': 0.294921875, 'learning_rate': 1.963014203577896e-05, 'epoch': 0.22}
 11%|█         | 87/780 [1:04:36<8:23:36, 43.60s/it] 11%|█▏        | 88/780 [1:05:22<8:32:32, 44.44s/it]                                                    {'loss': 0.4385, 'grad_norm': 0.306640625, 'learning_rate': 1.9618921578988863e-05, 'epoch': 0.23}
 11%|█▏        | 88/780 [1:05:22<8:32:32, 44.44s/it] 11%|█▏        | 89/780 [1:06:07<8:33:32, 44.59s/it]                                                    {'loss': 0.4717, 'grad_norm': 0.306640625, 'learning_rate': 1.9607536761368484e-05, 'epoch': 0.23}
 11%|█▏        | 89/780 [1:06:07<8:33:32, 44.59s/it] 12%|█▏        | 90/780 [1:06:51<8:31:38, 44.49s/it]                                                    {'loss': 0.403, 'grad_norm': 0.3359375, 'learning_rate': 1.9595987777452946e-05, 'epoch': 0.23}
 12%|█▏        | 90/780 [1:06:51<8:31:38, 44.49s/it] 12%|█▏        | 91/780 [1:07:34<8:25:14, 44.00s/it]                                                    {'loss': 0.4698, 'grad_norm': 0.328125, 'learning_rate': 1.958427482458253e-05, 'epoch': 0.23}
 12%|█▏        | 91/780 [1:07:34<8:25:14, 44.00s/it] 12%|█▏        | 92/780 [1:08:18<8:23:52, 43.94s/it]                                                    {'loss': 0.4266, 'grad_norm': 0.294921875, 'learning_rate': 1.957239810289927e-05, 'epoch': 0.24}
 12%|█▏        | 92/780 [1:08:18<8:23:52, 43.94s/it] 12%|█▏        | 93/780 [1:09:03<8:26:39, 44.25s/it]                                                    {'loss': 0.4083, 'grad_norm': 0.294921875, 'learning_rate': 1.9560357815343577e-05, 'epoch': 0.24}
 12%|█▏        | 93/780 [1:09:03<8:26:39, 44.25s/it] 12%|█▏        | 94/780 [1:09:47<8:24:17, 44.11s/it]                                                    {'loss': 0.4386, 'grad_norm': 0.275390625, 'learning_rate': 1.9548154167650746e-05, 'epoch': 0.24}
 12%|█▏        | 94/780 [1:09:47<8:24:17, 44.11s/it] 12%|█▏        | 95/780 [1:10:33<8:32:10, 44.86s/it]                                                    {'loss': 0.4188, 'grad_norm': 0.298828125, 'learning_rate': 1.9535787368347444e-05, 'epoch': 0.24}
 12%|█▏        | 95/780 [1:10:33<8:32:10, 44.86s/it] 12%|█▏        | 96/780 [1:11:18<8:31:00, 44.83s/it]                                                    {'loss': 0.434, 'grad_norm': 0.2890625, 'learning_rate': 1.9523257628748148e-05, 'epoch': 0.25}
 12%|█▏        | 96/780 [1:11:18<8:31:00, 44.83s/it] 12%|█▏        | 97/780 [1:12:03<8:32:12, 45.00s/it]                                                    {'loss': 0.421, 'grad_norm': 0.314453125, 'learning_rate': 1.9510565162951538e-05, 'epoch': 0.25}
 12%|█▏        | 97/780 [1:12:03<8:32:12, 45.00s/it] 13%|█▎        | 98/780 [1:12:49<8:33:55, 45.21s/it]                                                    {'loss': 0.4883, 'grad_norm': 0.32421875, 'learning_rate': 1.9497710187836832e-05, 'epoch': 0.25}
 13%|█▎        | 98/780 [1:12:49<8:33:55, 45.21s/it] 13%|█▎        | 99/780 [1:13:37<8:40:52, 45.89s/it]                                                    {'loss': 0.4225, 'grad_norm': 0.30859375, 'learning_rate': 1.9484692923060095e-05, 'epoch': 0.25}
 13%|█▎        | 99/780 [1:13:37<8:40:52, 45.89s/it] 13%|█▎        | 100/780 [1:14:19<8:27:25, 44.77s/it]                                                     {'loss': 0.4448, 'grad_norm': 0.310546875, 'learning_rate': 1.947151359105046e-05, 'epoch': 0.26}
 13%|█▎        | 100/780 [1:14:19<8:27:25, 44.77s/it] 13%|█▎        | 101/780 [1:15:01<8:17:07, 43.93s/it]                                                     {'loss': 0.4295, 'grad_norm': 0.31640625, 'learning_rate': 1.9458172417006347e-05, 'epoch': 0.26}
 13%|█▎        | 101/780 [1:15:01<8:17:07, 43.93s/it] 13%|█▎        | 102/780 [1:15:43<8:11:13, 43.47s/it]                                                     {'loss': 0.4226, 'grad_norm': 0.310546875, 'learning_rate': 1.9444669628891618e-05, 'epoch': 0.26}
 13%|█▎        | 102/780 [1:15:43<8:11:13, 43.47s/it] 13%|█▎        | 103/780 [1:16:27<8:11:39, 43.57s/it]                                                     {'loss': 0.4573, 'grad_norm': 0.318359375, 'learning_rate': 1.9431005457431654e-05, 'epoch': 0.26}
 13%|█▎        | 103/780 [1:16:27<8:11:39, 43.57s/it] 13%|█▎        | 104/780 [1:17:11<8:13:22, 43.79s/it]                                                     {'loss': 0.4263, 'grad_norm': 0.318359375, 'learning_rate': 1.9417180136109456e-05, 'epoch': 0.27}
 13%|█▎        | 104/780 [1:17:11<8:13:22, 43.79s/it] 13%|█▎        | 105/780 [1:17:56<8:17:22, 44.21s/it]                                                     {'loss': 0.3984, 'grad_norm': 0.28515625, 'learning_rate': 1.9403193901161614e-05, 'epoch': 0.27}
 13%|█▎        | 105/780 [1:17:56<8:17:22, 44.21s/it] 14%|█▎        | 106/780 [1:18:43<8:25:30, 45.00s/it]                                                     {'loss': 0.4237, 'grad_norm': 0.271484375, 'learning_rate': 1.9389046991574298e-05, 'epoch': 0.27}
 14%|█▎        | 106/780 [1:18:43<8:25:30, 45.00s/it] 14%|█▎        | 107/780 [1:19:29<8:26:51, 45.19s/it]                                                     {'loss': 0.4735, 'grad_norm': 0.310546875, 'learning_rate': 1.9374739649079155e-05, 'epoch': 0.27}
 14%|█▎        | 107/780 [1:19:29<8:26:51, 45.19s/it] 14%|█▍        | 108/780 [1:20:13<8:20:53, 44.72s/it]                                                     {'loss': 0.4345, 'grad_norm': 0.30859375, 'learning_rate': 1.9360272118149195e-05, 'epoch': 0.28}
 14%|█▍        | 108/780 [1:20:13<8:20:53, 44.72s/it] 14%|█▍        | 109/780 [1:20:57<8:20:30, 44.76s/it]                                                     {'loss': 0.4175, 'grad_norm': 0.322265625, 'learning_rate': 1.934564464599461e-05, 'epoch': 0.28}
 14%|█▍        | 109/780 [1:20:57<8:20:30, 44.76s/it] 14%|█▍        | 110/780 [1:21:42<8:18:13, 44.62s/it]                                                     {'loss': 0.3951, 'grad_norm': 0.27734375, 'learning_rate': 1.9330857482558533e-05, 'epoch': 0.28}
 14%|█▍        | 110/780 [1:21:42<8:18:13, 44.62s/it] 14%|█▍        | 111/780 [1:22:27<8:20:57, 44.93s/it]                                                     {'loss': 0.4435, 'grad_norm': 0.2890625, 'learning_rate': 1.9315910880512792e-05, 'epoch': 0.28}
 14%|█▍        | 111/780 [1:22:27<8:20:57, 44.93s/it] 14%|█▍        | 112/780 [1:23:10<8:14:06, 44.38s/it]                                                     {'loss': 0.4195, 'grad_norm': 0.28515625, 'learning_rate': 1.9300805095253575e-05, 'epoch': 0.29}
 14%|█▍        | 112/780 [1:23:10<8:14:06, 44.38s/it] 14%|█▍        | 113/780 [1:23:57<8:19:16, 44.91s/it]                                                     {'loss': 0.4459, 'grad_norm': 0.302734375, 'learning_rate': 1.9285540384897073e-05, 'epoch': 0.29}
 14%|█▍        | 113/780 [1:23:57<8:19:16, 44.91s/it] 15%|█▍        | 114/780 [1:24:42<8:20:09, 45.06s/it]                                                     {'loss': 0.4655, 'grad_norm': 0.294921875, 'learning_rate': 1.9270117010275072e-05, 'epoch': 0.29}
 15%|█▍        | 114/780 [1:24:42<8:20:09, 45.06s/it] 15%|█▍        | 115/780 [1:25:28<8:22:39, 45.35s/it]                                                     {'loss': 0.4491, 'grad_norm': 0.35546875, 'learning_rate': 1.9254535234930486e-05, 'epoch': 0.29}
 15%|█▍        | 115/780 [1:25:28<8:22:39, 45.35s/it] 15%|█▍        | 116/780 [1:26:11<8:15:29, 44.77s/it]                                                     {'loss': 0.4329, 'grad_norm': 0.39453125, 'learning_rate': 1.9238795325112867e-05, 'epoch': 0.3}
 15%|█▍        | 116/780 [1:26:11<8:15:29, 44.77s/it] 15%|█▌        | 117/780 [1:26:57<8:16:32, 44.94s/it]                                                     {'loss': 0.4308, 'grad_norm': 0.3125, 'learning_rate': 1.922289754977385e-05, 'epoch': 0.3}
 15%|█▌        | 117/780 [1:26:57<8:16:32, 44.94s/it] 15%|█▌        | 118/780 [1:27:41<8:12:17, 44.62s/it]                                                     {'loss': 0.4456, 'grad_norm': 0.3046875, 'learning_rate': 1.920684218056254e-05, 'epoch': 0.3}
 15%|█▌        | 118/780 [1:27:41<8:12:17, 44.62s/it] 15%|█▌        | 119/780 [1:28:24<8:07:26, 44.25s/it]                                                     {'loss': 0.415, 'grad_norm': 0.318359375, 'learning_rate': 1.919062949182091e-05, 'epoch': 0.3}
 15%|█▌        | 119/780 [1:28:24<8:07:26, 44.25s/it] 15%|█▌        | 120/780 [1:29:09<8:08:01, 44.37s/it]                                                     {'loss': 0.4225, 'grad_norm': 0.2890625, 'learning_rate': 1.9174259760579078e-05, 'epoch': 0.31}
 15%|█▌        | 120/780 [1:29:09<8:08:01, 44.37s/it] 16%|█▌        | 121/780 [1:29:52<8:02:40, 43.95s/it]                                                     {'loss': 0.418, 'grad_norm': 0.337890625, 'learning_rate': 1.9157733266550577e-05, 'epoch': 0.31}
 16%|█▌        | 121/780 [1:29:52<8:02:40, 43.95s/it] 16%|█▌        | 122/780 [1:30:37<8:06:30, 44.36s/it]                                                     {'loss': 0.4399, 'grad_norm': 0.291015625, 'learning_rate': 1.9141050292127598e-05, 'epoch': 0.31}
 16%|█▌        | 122/780 [1:30:37<8:06:30, 44.36s/it] 16%|█▌        | 123/780 [1:31:23<8:12:52, 45.01s/it]                                                     {'loss': 0.4429, 'grad_norm': 0.3125, 'learning_rate': 1.9124211122376138e-05, 'epoch': 0.31}
 16%|█▌        | 123/780 [1:31:24<8:12:52, 45.01s/it] 16%|█▌        | 124/780 [1:32:05<8:01:12, 44.01s/it]                                                     {'loss': 0.4192, 'grad_norm': 0.29296875, 'learning_rate': 1.9107216045031154e-05, 'epoch': 0.32}
 16%|█▌        | 124/780 [1:32:05<8:01:12, 44.01s/it] 16%|█▌        | 125/780 [1:32:49<8:00:06, 43.98s/it]                                                     {'loss': 0.4322, 'grad_norm': 0.291015625, 'learning_rate': 1.909006535049163e-05, 'epoch': 0.32}
 16%|█▌        | 125/780 [1:32:49<8:00:06, 43.98s/it] 16%|█▌        | 126/780 [1:33:32<7:56:27, 43.71s/it]                                                     {'loss': 0.4002, 'grad_norm': 0.296875, 'learning_rate': 1.9072759331815602e-05, 'epoch': 0.32}
 16%|█▌        | 126/780 [1:33:32<7:56:27, 43.71s/it] 16%|█▋        | 127/780 [1:34:17<7:57:53, 43.91s/it]                                                     {'loss': 0.405, 'grad_norm': 0.28515625, 'learning_rate': 1.9055298284715192e-05, 'epoch': 0.33}
 16%|█▋        | 127/780 [1:34:17<7:57:53, 43.91s/it] 16%|█▋        | 128/780 [1:35:03<8:06:26, 44.77s/it]                                                     {'loss': 0.4233, 'grad_norm': 0.287109375, 'learning_rate': 1.903768250755151e-05, 'epoch': 0.33}
 16%|█▋        | 128/780 [1:35:03<8:06:26, 44.77s/it] 17%|█▋        | 129/780 [1:35:50<8:11:07, 45.26s/it]                                                     {'loss': 0.3948, 'grad_norm': 0.298828125, 'learning_rate': 1.9019912301329593e-05, 'epoch': 0.33}
 17%|█▋        | 129/780 [1:35:50<8:11:07, 45.26s/it] 17%|█▋        | 130/780 [1:36:33<8:05:29, 44.81s/it]                                                     {'loss': 0.4313, 'grad_norm': 0.294921875, 'learning_rate': 1.9001987969693228e-05, 'epoch': 0.33}
 17%|█▋        | 130/780 [1:36:34<8:05:29, 44.81s/it] 17%|█▋        | 131/780 [1:37:17<7:59:59, 44.37s/it]                                                     {'loss': 0.4096, 'grad_norm': 0.40625, 'learning_rate': 1.898390981891979e-05, 'epoch': 0.34}
 17%|█▋        | 131/780 [1:37:17<7:59:59, 44.37s/it] 17%|█▋        | 132/780 [1:38:02<8:01:02, 44.54s/it]                                                     {'loss': 0.4157, 'grad_norm': 0.30859375, 'learning_rate': 1.8965678157915e-05, 'epoch': 0.34}
 17%|█▋        | 132/780 [1:38:02<8:01:02, 44.54s/it] 17%|█▋        | 133/780 [1:38:44<7:51:55, 43.76s/it]                                                     {'loss': 0.4013, 'grad_norm': 0.30078125, 'learning_rate': 1.8947293298207637e-05, 'epoch': 0.34}
 17%|█▋        | 133/780 [1:38:44<7:51:55, 43.76s/it] 17%|█▋        | 134/780 [1:39:27<7:51:18, 43.78s/it]                                                     {'loss': 0.4045, 'grad_norm': 0.3203125, 'learning_rate': 1.892875555394423e-05, 'epoch': 0.34}
 17%|█▋        | 134/780 [1:39:28<7:51:18, 43.78s/it] 17%|█▋        | 135/780 [1:40:13<7:55:29, 44.23s/it]                                                     {'loss': 0.4243, 'grad_norm': 0.30859375, 'learning_rate': 1.891006524188368e-05, 'epoch': 0.35}
 17%|█▋        | 135/780 [1:40:13<7:55:29, 44.23s/it] 17%|█▋        | 136/780 [1:40:59<8:01:13, 44.83s/it]                                                     {'loss': 0.3883, 'grad_norm': 0.279296875, 'learning_rate': 1.8891222681391853e-05, 'epoch': 0.35}
 17%|█▋        | 136/780 [1:40:59<8:01:13, 44.83s/it] 18%|█▊        | 137/780 [1:41:43<7:57:51, 44.59s/it]                                                     {'loss': 0.4114, 'grad_norm': 0.3671875, 'learning_rate': 1.887222819443612e-05, 'epoch': 0.35}
 18%|█▊        | 137/780 [1:41:43<7:57:51, 44.59s/it] 18%|█▊        | 138/780 [1:42:26<7:51:08, 44.03s/it]                                                     {'loss': 0.4228, 'grad_norm': 0.353515625, 'learning_rate': 1.8853082105579853e-05, 'epoch': 0.35}
 18%|█▊        | 138/780 [1:42:26<7:51:08, 44.03s/it] 18%|█▊        | 139/780 [1:43:11<7:53:28, 44.32s/it]                                                     {'loss': 0.4214, 'grad_norm': 0.29296875, 'learning_rate': 1.883378474197689e-05, 'epoch': 0.36}
 18%|█▊        | 139/780 [1:43:11<7:53:28, 44.32s/it] 18%|█▊        | 140/780 [1:43:54<7:49:45, 44.04s/it]                                                     {'loss': 0.4283, 'grad_norm': 0.361328125, 'learning_rate': 1.8814336433365924e-05, 'epoch': 0.36}
 18%|█▊        | 140/780 [1:43:54<7:49:45, 44.04s/it] 18%|█▊        | 141/780 [1:44:39<7:52:37, 44.38s/it]                                                     {'loss': 0.4092, 'grad_norm': 0.291015625, 'learning_rate': 1.879473751206489e-05, 'epoch': 0.36}
 18%|█▊        | 141/780 [1:44:39<7:52:37, 44.38s/it] 18%|█▊        | 142/780 [1:45:24<7:53:32, 44.53s/it]                                                     {'loss': 0.4285, 'grad_norm': 0.33203125, 'learning_rate': 1.8774988312965287e-05, 'epoch': 0.36}
 18%|█▊        | 142/780 [1:45:24<7:53:32, 44.53s/it] 18%|█▊        | 143/780 [1:46:10<7:55:14, 44.76s/it]                                                     {'loss': 0.3991, 'grad_norm': 0.275390625, 'learning_rate': 1.875508917352643e-05, 'epoch': 0.37}
 18%|█▊        | 143/780 [1:46:10<7:55:14, 44.76s/it] 18%|█▊        | 144/780 [1:46:56<7:59:17, 45.22s/it]                                                     {'loss': 0.427, 'grad_norm': 0.33984375, 'learning_rate': 1.873504043376971e-05, 'epoch': 0.37}
 18%|█▊        | 144/780 [1:46:56<7:59:17, 45.22s/it] 19%|█▊        | 145/780 [1:47:37<7:44:59, 43.94s/it]                                                     {'loss': 0.402, 'grad_norm': 0.318359375, 'learning_rate': 1.8714842436272774e-05, 'epoch': 0.37}
 19%|█▊        | 145/780 [1:47:37<7:44:59, 43.94s/it] 19%|█▊        | 146/780 [1:48:21<7:45:59, 44.10s/it]                                                     {'loss': 0.4321, 'grad_norm': 0.296875, 'learning_rate': 1.869449552616367e-05, 'epoch': 0.37}
 19%|█▊        | 146/780 [1:48:21<7:45:59, 44.10s/it] 19%|█▉        | 147/780 [1:49:04<7:41:34, 43.75s/it]                                                     {'loss': 0.4564, 'grad_norm': 0.298828125, 'learning_rate': 1.8674000051114953e-05, 'epoch': 0.38}
 19%|█▉        | 147/780 [1:49:04<7:41:34, 43.75s/it] 19%|█▉        | 148/780 [1:49:48<7:40:09, 43.69s/it]                                                     {'loss': 0.4311, 'grad_norm': 0.283203125, 'learning_rate': 1.8653356361337743e-05, 'epoch': 0.38}
 19%|█▉        | 148/780 [1:49:48<7:40:09, 43.69s/it] 19%|█▉        | 149/780 [1:50:34<7:46:34, 44.36s/it]                                                     {'loss': 0.4036, 'grad_norm': 0.291015625, 'learning_rate': 1.863256480957574e-05, 'epoch': 0.38}
 19%|█▉        | 149/780 [1:50:34<7:46:34, 44.36s/it] 19%|█▉        | 150/780 [1:51:17<7:43:02, 44.10s/it]                                                     {'loss': 0.4247, 'grad_norm': 0.3046875, 'learning_rate': 1.8611625751099197e-05, 'epoch': 0.38}
 19%|█▉        | 150/780 [1:51:17<7:43:02, 44.10s/it] 19%|█▉        | 151/780 [1:52:00<7:39:20, 43.82s/it]                                                     {'loss': 0.4254, 'grad_norm': 0.2890625, 'learning_rate': 1.8590539543698852e-05, 'epoch': 0.39}
 19%|█▉        | 151/780 [1:52:00<7:39:20, 43.82s/it] 19%|█▉        | 152/780 [1:52:45<7:39:54, 43.94s/it]                                                     {'loss': 0.4055, 'grad_norm': 0.279296875, 'learning_rate': 1.856930654767981e-05, 'epoch': 0.39}
 19%|█▉        | 152/780 [1:52:45<7:39:54, 43.94s/it] 20%|█▉        | 153/780 [1:53:29<7:40:20, 44.05s/it]                                                     {'loss': 0.4233, 'grad_norm': 0.322265625, 'learning_rate': 1.854792712585539e-05, 'epoch': 0.39}
 20%|█▉        | 153/780 [1:53:29<7:40:20, 44.05s/it] 20%|█▉        | 154/780 [1:54:13<7:40:54, 44.18s/it]                                                     {'loss': 0.4352, 'grad_norm': 0.296875, 'learning_rate': 1.8526401643540924e-05, 'epoch': 0.39}
 20%|█▉        | 154/780 [1:54:13<7:40:54, 44.18s/it] 20%|█▉        | 155/780 [1:54:56<7:35:57, 43.77s/it]                                                     {'loss': 0.4205, 'grad_norm': 0.314453125, 'learning_rate': 1.8504730468547508e-05, 'epoch': 0.4}
 20%|█▉        | 155/780 [1:54:56<7:35:57, 43.77s/it] 20%|██        | 156/780 [1:55:42<7:40:25, 44.27s/it]                                                     {'loss': 0.4102, 'grad_norm': 0.330078125, 'learning_rate': 1.8482913971175737e-05, 'epoch': 0.4}
 20%|██        | 156/780 [1:55:42<7:40:25, 44.27s/it] 20%|██        | 157/780 [1:56:25<7:37:02, 44.02s/it]                                                     {'loss': 0.4229, 'grad_norm': 0.306640625, 'learning_rate': 1.8460952524209355e-05, 'epoch': 0.4}
 20%|██        | 157/780 [1:56:25<7:37:02, 44.02s/it] 20%|██        | 158/780 [1:57:09<7:35:45, 43.96s/it]                                                     {'loss': 0.4009, 'grad_norm': 0.3125, 'learning_rate': 1.8438846502908895e-05, 'epoch': 0.4}
 20%|██        | 158/780 [1:57:09<7:35:45, 43.96s/it] 20%|██        | 159/780 [1:57:54<7:37:46, 44.23s/it]                                                     {'loss': 0.4259, 'grad_norm': 0.30859375, 'learning_rate': 1.8416596285005274e-05, 'epoch': 0.41}
 20%|██        | 159/780 [1:57:54<7:37:46, 44.23s/it] 21%|██        | 160/780 [1:58:40<7:44:58, 45.00s/it]                                                     {'loss': 0.385, 'grad_norm': 0.408203125, 'learning_rate': 1.8394202250693315e-05, 'epoch': 0.41}
 21%|██        | 160/780 [1:58:41<7:44:58, 45.00s/it] 21%|██        | 161/780 [1:59:21<7:30:24, 43.66s/it]                                                     {'loss': 0.45, 'grad_norm': 0.296875, 'learning_rate': 1.8371664782625287e-05, 'epoch': 0.41}
 21%|██        | 161/780 [1:59:21<7:30:24, 43.66s/it] 21%|██        | 162/780 [2:00:06<7:35:04, 44.18s/it]                                                     {'loss': 0.4108, 'grad_norm': 0.294921875, 'learning_rate': 1.8348984265904333e-05, 'epoch': 0.41}
 21%|██        | 162/780 [2:00:06<7:35:04, 44.18s/it] 21%|██        | 163/780 [2:00:51<7:35:36, 44.31s/it]                                                     {'loss': 0.3883, 'grad_norm': 0.279296875, 'learning_rate': 1.8326161088077905e-05, 'epoch': 0.42}
 21%|██        | 163/780 [2:00:51<7:35:36, 44.31s/it] 21%|██        | 164/780 [2:01:33<7:27:21, 43.57s/it]                                                     {'loss': 0.4014, 'grad_norm': 0.87890625, 'learning_rate': 1.830319563913114e-05, 'epoch': 0.42}
 21%|██        | 164/780 [2:01:33<7:27:21, 43.57s/it] 21%|██        | 165/780 [2:02:18<7:30:02, 43.91s/it]                                                     {'loss': 0.4073, 'grad_norm': 0.2890625, 'learning_rate': 1.8280088311480203e-05, 'epoch': 0.42}
 21%|██        | 165/780 [2:02:18<7:30:02, 43.91s/it] 21%|██▏       | 166/780 [2:03:02<7:31:17, 44.10s/it]                                                     {'loss': 0.4155, 'grad_norm': 0.28125, 'learning_rate': 1.825683949996556e-05, 'epoch': 0.42}
 21%|██▏       | 166/780 [2:03:02<7:31:17, 44.10s/it] 21%|██▏       | 167/780 [2:03:45<7:27:38, 43.82s/it]                                                     {'loss': 0.4172, 'grad_norm': 0.294921875, 'learning_rate': 1.823344960184526e-05, 'epoch': 0.43}
 21%|██▏       | 167/780 [2:03:45<7:27:38, 43.82s/it] 22%|██▏       | 168/780 [2:04:29<7:27:56, 43.92s/it]                                                     {'loss': 0.4368, 'grad_norm': 0.30078125, 'learning_rate': 1.8209919016788124e-05, 'epoch': 0.43}
 22%|██▏       | 168/780 [2:04:29<7:27:56, 43.92s/it] 22%|██▏       | 169/780 [2:05:13<7:26:31, 43.85s/it]                                                     {'loss': 0.4167, 'grad_norm': 0.3125, 'learning_rate': 1.8186248146866928e-05, 'epoch': 0.43}
 22%|██▏       | 169/780 [2:05:13<7:26:31, 43.85s/it] 22%|██▏       | 170/780 [2:05:57<7:25:51, 43.85s/it]                                                     {'loss': 0.4233, 'grad_norm': 0.287109375, 'learning_rate': 1.8162437396551527e-05, 'epoch': 0.44}
 22%|██▏       | 170/780 [2:05:57<7:25:51, 43.85s/it] 22%|██▏       | 171/780 [2:06:39<7:19:00, 43.25s/it]                                                     {'loss': 0.3941, 'grad_norm': 0.298828125, 'learning_rate': 1.813848717270195e-05, 'epoch': 0.44}
 22%|██▏       | 171/780 [2:06:39<7:19:00, 43.25s/it] 22%|██▏       | 172/780 [2:07:23<7:19:58, 43.42s/it]                                                     {'loss': 0.3908, 'grad_norm': 0.298828125, 'learning_rate': 1.8114397884561446e-05, 'epoch': 0.44}
 22%|██▏       | 172/780 [2:07:23<7:19:58, 43.42s/it] 22%|██▏       | 173/780 [2:08:07<7:23:13, 43.81s/it]                                                     {'loss': 0.433, 'grad_norm': 0.302734375, 'learning_rate': 1.8090169943749477e-05, 'epoch': 0.44}
 22%|██▏       | 173/780 [2:08:07<7:23:13, 43.81s/it] 22%|██▏       | 174/780 [2:08:50<7:18:13, 43.39s/it]                                                     {'loss': 0.4182, 'grad_norm': 0.330078125, 'learning_rate': 1.806580376425471e-05, 'epoch': 0.45}
 22%|██▏       | 174/780 [2:08:50<7:18:13, 43.39s/it] 22%|██▏       | 175/780 [2:09:33<7:16:46, 43.32s/it]                                                     {'loss': 0.4281, 'grad_norm': 0.328125, 'learning_rate': 1.804129976242792e-05, 'epoch': 0.45}
 22%|██▏       | 175/780 [2:09:33<7:16:46, 43.32s/it] 23%|██▎       | 176/780 [2:10:17<7:19:46, 43.69s/it]                                                     {'loss': 0.4181, 'grad_norm': 0.31640625, 'learning_rate': 1.8016658356974885e-05, 'epoch': 0.45}
 23%|██▎       | 176/780 [2:10:17<7:19:46, 43.69s/it] 23%|██▎       | 177/780 [2:11:01<7:18:15, 43.61s/it]                                                     {'loss': 0.4548, 'grad_norm': 0.326171875, 'learning_rate': 1.7991879968949248e-05, 'epoch': 0.45}
 23%|██▎       | 177/780 [2:11:01<7:18:15, 43.61s/it] 23%|██▎       | 178/780 [2:11:44<7:17:30, 43.61s/it]                                                     {'loss': 0.3949, 'grad_norm': 0.3359375, 'learning_rate': 1.796696502174529e-05, 'epoch': 0.46}
 23%|██▎       | 178/780 [2:11:45<7:17:30, 43.61s/it] 23%|██▎       | 179/780 [2:12:30<7:22:18, 44.16s/it]                                                     {'loss': 0.4248, 'grad_norm': 0.2890625, 'learning_rate': 1.7941913941090712e-05, 'epoch': 0.46}
 23%|██▎       | 179/780 [2:12:30<7:22:18, 44.16s/it] 23%|██▎       | 180/780 [2:13:13<7:17:25, 43.74s/it]                                                     {'loss': 0.4122, 'grad_norm': 0.3203125, 'learning_rate': 1.7916727155039367e-05, 'epoch': 0.46}
 23%|██▎       | 180/780 [2:13:13<7:17:25, 43.74s/it] 23%|██▎       | 181/780 [2:13:57<7:19:07, 43.99s/it]                                                     {'loss': 0.4308, 'grad_norm': 0.30859375, 'learning_rate': 1.789140509396394e-05, 'epoch': 0.46}
 23%|██▎       | 181/780 [2:13:57<7:19:07, 43.99s/it] 23%|██▎       | 182/780 [2:14:42<7:20:45, 44.22s/it]                                                     {'loss': 0.4093, 'grad_norm': 0.30078125, 'learning_rate': 1.786594819054858e-05, 'epoch': 0.47}
 23%|██▎       | 182/780 [2:14:42<7:20:45, 44.22s/it] 23%|██▎       | 183/780 [2:15:24<7:12:56, 43.51s/it]                                                     {'loss': 0.413, 'grad_norm': 0.30859375, 'learning_rate': 1.784035687978153e-05, 'epoch': 0.47}
 23%|██▎       | 183/780 [2:15:24<7:12:56, 43.51s/it] 24%|██▎       | 184/780 [2:16:11<7:24:19, 44.73s/it]                                                     {'loss': 0.4126, 'grad_norm': 0.30078125, 'learning_rate': 1.7814631598947692e-05, 'epoch': 0.47}
 24%|██▎       | 184/780 [2:16:11<7:24:19, 44.73s/it] 24%|██▎       | 185/780 [2:16:51<7:08:19, 43.19s/it]                                                     {'loss': 0.4228, 'grad_norm': 0.302734375, 'learning_rate': 1.7788772787621126e-05, 'epoch': 0.47}
 24%|██▎       | 185/780 [2:16:51<7:08:19, 43.19s/it] 24%|██▍       | 186/780 [2:17:38<7:17:38, 44.21s/it]                                                     {'loss': 0.4439, 'grad_norm': 0.3125, 'learning_rate': 1.7762780887657576e-05, 'epoch': 0.48}
 24%|██▍       | 186/780 [2:17:38<7:17:38, 44.21s/it] 24%|██▍       | 187/780 [2:18:26<7:27:59, 45.33s/it]                                                     {'loss': 0.3719, 'grad_norm': 0.326171875, 'learning_rate': 1.7736656343186897e-05, 'epoch': 0.48}
 24%|██▍       | 187/780 [2:18:26<7:27:59, 45.33s/it] 24%|██▍       | 188/780 [2:19:10<7:23:41, 44.97s/it]                                                     {'loss': 0.4212, 'grad_norm': 0.318359375, 'learning_rate': 1.7710399600605472e-05, 'epoch': 0.48}
 24%|██▍       | 188/780 [2:19:10<7:23:41, 44.97s/it] 24%|██▍       | 189/780 [2:19:57<7:29:20, 45.62s/it]                                                     {'loss': 0.4023, 'grad_norm': 0.376953125, 'learning_rate': 1.7684011108568593e-05, 'epoch': 0.48}
 24%|██▍       | 189/780 [2:19:57<7:29:20, 45.62s/it] 24%|██▍       | 190/780 [2:20:44<7:32:11, 45.99s/it]                                                     {'loss': 0.3875, 'grad_norm': 0.34765625, 'learning_rate': 1.7657491317982772e-05, 'epoch': 0.49}
 24%|██▍       | 190/780 [2:20:44<7:32:11, 45.99s/it] 24%|██▍       | 191/780 [2:21:29<7:28:46, 45.72s/it]                                                     {'loss': 0.4351, 'grad_norm': 0.30078125, 'learning_rate': 1.7630840681998068e-05, 'epoch': 0.49}
 24%|██▍       | 191/780 [2:21:29<7:28:46, 45.72s/it] 25%|██▍       | 192/780 [2:22:13<7:22:42, 45.17s/it]                                                     {'loss': 0.3959, 'grad_norm': 0.333984375, 'learning_rate': 1.7604059656000313e-05, 'epoch': 0.49}
 25%|██▍       | 192/780 [2:22:13<7:22:42, 45.17s/it] 25%|██▍       | 193/780 [2:23:00<7:29:22, 45.93s/it]                                                     {'loss': 0.4272, 'grad_norm': 0.330078125, 'learning_rate': 1.757714869760335e-05, 'epoch': 0.49}
 25%|██▍       | 193/780 [2:23:00<7:29:22, 45.93s/it] 25%|██▍       | 194/780 [2:23:48<7:32:57, 46.38s/it]                                                     {'loss': 0.4096, 'grad_norm': 0.30859375, 'learning_rate': 1.7550108266641207e-05, 'epoch': 0.5}
 25%|██▍       | 194/780 [2:23:48<7:32:57, 46.38s/it] 25%|██▌       | 195/780 [2:24:33<7:28:35, 46.01s/it]                                                     {'loss': 0.3878, 'grad_norm': 0.283203125, 'learning_rate': 1.752293882516025e-05, 'epoch': 0.5}
 25%|██▌       | 195/780 [2:24:33<7:28:35, 46.01s/it] 25%|██▌       | 196/780 [2:25:17<7:21:31, 45.36s/it]                                                     {'loss': 0.4121, 'grad_norm': 0.38671875, 'learning_rate': 1.7495640837411265e-05, 'epoch': 0.5}
 25%|██▌       | 196/780 [2:25:17<7:21:31, 45.36s/it] 25%|██▌       | 197/780 [2:26:01<7:16:21, 44.91s/it]                                                     {'loss': 0.4283, 'grad_norm': 0.302734375, 'learning_rate': 1.7468214769841542e-05, 'epoch': 0.5}
 25%|██▌       | 197/780 [2:26:01<7:16:21, 44.91s/it] 25%|██▌       | 198/780 [2:26:43<7:09:11, 44.25s/it]                                                     {'loss': 0.4084, 'grad_norm': 0.31640625, 'learning_rate': 1.7440661091086908e-05, 'epoch': 0.51}
 25%|██▌       | 198/780 [2:26:43<7:09:11, 44.25s/it] 26%|██▌       | 199/780 [2:27:32<7:22:37, 45.71s/it]                                                     {'loss': 0.378, 'grad_norm': 0.294921875, 'learning_rate': 1.7412980271963712e-05, 'epoch': 0.51}
 26%|██▌       | 199/780 [2:27:33<7:22:37, 45.71s/it] 26%|██▌       | 200/780 [2:28:15<7:12:04, 44.70s/it]                                                     {'loss': 0.4198, 'grad_norm': 0.353515625, 'learning_rate': 1.7385172785460775e-05, 'epoch': 0.51}
 26%|██▌       | 200/780 [2:28:15<7:12:04, 44.70s/it] 26%|██▌       | 201/780 [2:29:01<7:14:24, 45.02s/it]                                                     {'loss': 0.4235, 'grad_norm': 0.47265625, 'learning_rate': 1.735723910673132e-05, 'epoch': 0.51}
 26%|██▌       | 201/780 [2:29:01<7:14:24, 45.02s/it] 26%|██▌       | 202/780 [2:29:45<7:11:47, 44.82s/it]                                                     {'loss': 0.4378, 'grad_norm': 0.296875, 'learning_rate': 1.732917971308484e-05, 'epoch': 0.52}
 26%|██▌       | 202/780 [2:29:45<7:11:47, 44.82s/it] 26%|██▌       | 203/780 [2:30:31<7:13:52, 45.12s/it]                                                     {'loss': 0.419, 'grad_norm': 0.341796875, 'learning_rate': 1.7300995083978965e-05, 'epoch': 0.52}
 26%|██▌       | 203/780 [2:30:31<7:13:52, 45.12s/it] 26%|██▌       | 204/780 [2:31:14<7:07:46, 44.56s/it]                                                     {'loss': 0.3975, 'grad_norm': 0.28515625, 'learning_rate': 1.727268570101123e-05, 'epoch': 0.52}
 26%|██▌       | 204/780 [2:31:14<7:07:46, 44.56s/it] 26%|██▋       | 205/780 [2:32:00<7:09:49, 44.85s/it]                                                     {'loss': 0.4336, 'grad_norm': 0.283203125, 'learning_rate': 1.7244252047910893e-05, 'epoch': 0.52}
 26%|██▋       | 205/780 [2:32:00<7:09:49, 44.85s/it] 26%|██▋       | 206/780 [2:32:44<7:08:50, 44.83s/it]                                                     {'loss': 0.3703, 'grad_norm': 0.291015625, 'learning_rate': 1.7215694610530624e-05, 'epoch': 0.53}
 26%|██▋       | 206/780 [2:32:44<7:08:50, 44.83s/it] 27%|██▋       | 207/780 [2:33:27<7:02:31, 44.24s/it]                                                     {'loss': 0.3984, 'grad_norm': 0.376953125, 'learning_rate': 1.718701387683824e-05, 'epoch': 0.53}
 27%|██▋       | 207/780 [2:33:27<7:02:31, 44.24s/it] 27%|██▋       | 208/780 [2:34:13<7:07:19, 44.82s/it]                                                     {'loss': 0.3817, 'grad_norm': 0.291015625, 'learning_rate': 1.7158210336908346e-05, 'epoch': 0.53}
 27%|██▋       | 208/780 [2:34:13<7:07:19, 44.82s/it] 27%|██▋       | 209/780 [2:34:57<7:04:26, 44.60s/it]                                                     {'loss': 0.4318, 'grad_norm': 0.318359375, 'learning_rate': 1.7129284482913973e-05, 'epoch': 0.54}
 27%|██▋       | 209/780 [2:34:57<7:04:26, 44.60s/it] 27%|██▋       | 210/780 [2:35:39<6:55:03, 43.69s/it]                                                     {'loss': 0.3964, 'grad_norm': 0.291015625, 'learning_rate': 1.7100236809118148e-05, 'epoch': 0.54}
 27%|██▋       | 210/780 [2:35:39<6:55:03, 43.69s/it] 27%|██▋       | 211/780 [2:36:23<6:53:52, 43.64s/it]                                                     {'loss': 0.3984, 'grad_norm': 0.30078125, 'learning_rate': 1.7071067811865477e-05, 'epoch': 0.54}
 27%|██▋       | 211/780 [2:36:23<6:53:52, 43.64s/it] 27%|██▋       | 212/780 [2:37:09<7:01:23, 44.51s/it]                                                     {'loss': 0.4123, 'grad_norm': 0.296875, 'learning_rate': 1.704177798957364e-05, 'epoch': 0.54}
 27%|██▋       | 212/780 [2:37:09<7:01:23, 44.51s/it] 27%|██▋       | 213/780 [2:37:54<7:02:30, 44.71s/it]                                                     {'loss': 0.4325, 'grad_norm': 0.32421875, 'learning_rate': 1.7012367842724887e-05, 'epoch': 0.55}
 27%|██▋       | 213/780 [2:37:54<7:02:30, 44.71s/it] 27%|██▋       | 214/780 [2:38:38<6:58:22, 44.35s/it]                                                     {'loss': 0.3857, 'grad_norm': 0.330078125, 'learning_rate': 1.6982837873857485e-05, 'epoch': 0.55}
 27%|██▋       | 214/780 [2:38:38<6:58:22, 44.35s/it] 28%|██▊       | 215/780 [2:39:21<6:53:58, 43.96s/it]                                                     {'loss': 0.4046, 'grad_norm': 0.318359375, 'learning_rate': 1.6953188587557122e-05, 'epoch': 0.55}
 28%|██▊       | 215/780 [2:39:21<6:53:58, 43.96s/it] 28%|██▊       | 216/780 [2:40:09<7:04:46, 45.19s/it]                                                     {'loss': 0.4105, 'grad_norm': 0.310546875, 'learning_rate': 1.6923420490448298e-05, 'epoch': 0.55}
 28%|██▊       | 216/780 [2:40:09<7:04:46, 45.19s/it] 28%|██▊       | 217/780 [2:40:52<6:58:26, 44.59s/it]                                                     {'loss': 0.4289, 'grad_norm': 0.322265625, 'learning_rate': 1.6893534091185658e-05, 'epoch': 0.56}
 28%|██▊       | 217/780 [2:40:52<6:58:26, 44.59s/it] 28%|██▊       | 218/780 [2:41:37<6:59:49, 44.82s/it]                                                     {'loss': 0.3807, 'grad_norm': 0.2890625, 'learning_rate': 1.686352990044531e-05, 'epoch': 0.56}
 28%|██▊       | 218/780 [2:41:37<6:59:49, 44.82s/it] 28%|██▊       | 219/780 [2:42:22<6:57:48, 44.69s/it]                                                     {'loss': 0.4127, 'grad_norm': 0.302734375, 'learning_rate': 1.6833408430916085e-05, 'epoch': 0.56}
 28%|██▊       | 219/780 [2:42:22<6:57:48, 44.69s/it] 28%|██▊       | 220/780 [2:43:07<6:57:40, 44.75s/it]                                                     {'loss': 0.4009, 'grad_norm': 0.298828125, 'learning_rate': 1.6803170197290792e-05, 'epoch': 0.56}
 28%|██▊       | 220/780 [2:43:07<6:57:40, 44.75s/it] 28%|██▊       | 221/780 [2:43:50<6:51:42, 44.19s/it]                                                     {'loss': 0.412, 'grad_norm': 0.294921875, 'learning_rate': 1.6772815716257414e-05, 'epoch': 0.57}
 28%|██▊       | 221/780 [2:43:50<6:51:42, 44.19s/it] 28%|██▊       | 222/780 [2:44:33<6:48:26, 43.92s/it]                                                     {'loss': 0.4351, 'grad_norm': 0.357421875, 'learning_rate': 1.6742345506490277e-05, 'epoch': 0.57}
 28%|██▊       | 222/780 [2:44:33<6:48:26, 43.92s/it] 29%|██▊       | 223/780 [2:45:18<6:50:30, 44.22s/it]                                                     {'loss': 0.3921, 'grad_norm': 0.328125, 'learning_rate': 1.6711760088641197e-05, 'epoch': 0.57}
 29%|██▊       | 223/780 [2:45:18<6:50:30, 44.22s/it] 29%|██▊       | 224/780 [2:46:03<6:53:11, 44.59s/it]                                                     {'loss': 0.4168, 'grad_norm': 0.306640625, 'learning_rate': 1.6681059985330578e-05, 'epoch': 0.57}
 29%|██▊       | 224/780 [2:46:03<6:53:11, 44.59s/it] 29%|██▉       | 225/780 [2:46:45<6:44:14, 43.70s/it]                                                     {'loss': 0.4088, 'grad_norm': 0.318359375, 'learning_rate': 1.6650245721138483e-05, 'epoch': 0.58}
 29%|██▉       | 225/780 [2:46:45<6:44:14, 43.70s/it] 29%|██▉       | 226/780 [2:47:30<6:47:06, 44.09s/it]                                                     {'loss': 0.4086, 'grad_norm': 0.322265625, 'learning_rate': 1.6619317822595666e-05, 'epoch': 0.58}
 29%|██▉       | 226/780 [2:47:30<6:47:06, 44.09s/it] 29%|██▉       | 227/780 [2:48:15<6:50:29, 44.54s/it]                                                     {'loss': 0.4116, 'grad_norm': 0.337890625, 'learning_rate': 1.658827681817458e-05, 'epoch': 0.58}
 29%|██▉       | 227/780 [2:48:16<6:50:29, 44.54s/it] 29%|██▉       | 228/780 [2:49:01<6:52:38, 44.85s/it]                                                     {'loss': 0.4263, 'grad_norm': 0.34765625, 'learning_rate': 1.6557123238280347e-05, 'epoch': 0.58}
 29%|██▉       | 228/780 [2:49:01<6:52:38, 44.85s/it] 29%|██▉       | 229/780 [2:49:46<6:51:27, 44.81s/it]                                                     {'loss': 0.3916, 'grad_norm': 0.310546875, 'learning_rate': 1.6525857615241686e-05, 'epoch': 0.59}
 29%|██▉       | 229/780 [2:49:46<6:51:27, 44.81s/it] 29%|██▉       | 230/780 [2:50:29<6:45:11, 44.20s/it]                                                     {'loss': 0.3868, 'grad_norm': 0.318359375, 'learning_rate': 1.6494480483301836e-05, 'epoch': 0.59}
 29%|██▉       | 230/780 [2:50:29<6:45:11, 44.20s/it] 30%|██▉       | 231/780 [2:51:13<6:45:08, 44.28s/it]                                                     {'loss': 0.3874, 'grad_norm': 0.291015625, 'learning_rate': 1.646299237860941e-05, 'epoch': 0.59}
 30%|██▉       | 231/780 [2:51:13<6:45:08, 44.28s/it] 30%|██▉       | 232/780 [2:51:55<6:38:07, 43.59s/it]                                                     {'loss': 0.4164, 'grad_norm': 0.380859375, 'learning_rate': 1.6431393839209237e-05, 'epoch': 0.59}
 30%|██▉       | 232/780 [2:51:55<6:38:07, 43.59s/it] 30%|██▉       | 233/780 [2:52:38<6:35:55, 43.43s/it]                                                     {'loss': 0.3944, 'grad_norm': 0.337890625, 'learning_rate': 1.6399685405033168e-05, 'epoch': 0.6}
 30%|██▉       | 233/780 [2:52:38<6:35:55, 43.43s/it] 30%|███       | 234/780 [2:53:24<6:42:55, 44.28s/it]                                                     {'loss': 0.4059, 'grad_norm': 0.318359375, 'learning_rate': 1.636786761789086e-05, 'epoch': 0.6}
 30%|███       | 234/780 [2:53:24<6:42:55, 44.28s/it] 30%|███       | 235/780 [2:54:09<6:44:23, 44.52s/it]                                                     {'loss': 0.4237, 'grad_norm': 0.314453125, 'learning_rate': 1.6335941021460507e-05, 'epoch': 0.6}
 30%|███       | 235/780 [2:54:09<6:44:23, 44.52s/it] 30%|███       | 236/780 [2:54:51<6:36:50, 43.77s/it]                                                     {'loss': 0.4128, 'grad_norm': 0.36328125, 'learning_rate': 1.6303906161279554e-05, 'epoch': 0.6}
 30%|███       | 236/780 [2:54:51<6:36:50, 43.77s/it] 30%|███       | 237/780 [2:55:38<6:43:28, 44.58s/it]                                                     {'loss': 0.4229, 'grad_norm': 0.31640625, 'learning_rate': 1.6271763584735373e-05, 'epoch': 0.61}
 30%|███       | 237/780 [2:55:38<6:43:28, 44.58s/it] 31%|███       | 238/780 [2:56:22<6:41:09, 44.41s/it]                                                     {'loss': 0.4159, 'grad_norm': 0.31640625, 'learning_rate': 1.623951384105591e-05, 'epoch': 0.61}
 31%|███       | 238/780 [2:56:22<6:41:09, 44.41s/it] 31%|███       | 239/780 [2:57:07<6:42:49, 44.68s/it]                                                     {'loss': 0.3924, 'grad_norm': 0.291015625, 'learning_rate': 1.6207157481300315e-05, 'epoch': 0.61}
 31%|███       | 239/780 [2:57:07<6:42:49, 44.68s/it] 31%|███       | 240/780 [2:57:48<6:32:08, 43.57s/it]                                                     {'loss': 0.4125, 'grad_norm': 0.349609375, 'learning_rate': 1.6174695058349487e-05, 'epoch': 0.61}
 31%|███       | 240/780 [2:57:48<6:32:08, 43.57s/it] 31%|███       | 241/780 [2:58:35<6:39:34, 44.48s/it]                                                     {'loss': 0.3634, 'grad_norm': 0.294921875, 'learning_rate': 1.6142127126896682e-05, 'epoch': 0.62}
 31%|███       | 241/780 [2:58:35<6:39:34, 44.48s/it] 31%|███       | 242/780 [2:59:21<6:43:31, 45.00s/it]                                                     {'loss': 0.4123, 'grad_norm': 0.306640625, 'learning_rate': 1.6109454243437977e-05, 'epoch': 0.62}
 31%|███       | 242/780 [2:59:21<6:43:31, 45.00s/it] 31%|███       | 243/780 [3:00:06<6:41:32, 44.87s/it]                                                     {'loss': 0.4492, 'grad_norm': 0.337890625, 'learning_rate': 1.6076676966262815e-05, 'epoch': 0.62}
 31%|███       | 243/780 [3:00:06<6:41:32, 44.87s/it] 31%|███▏      | 244/780 [3:00:48<6:35:30, 44.27s/it]                                                     {'loss': 0.3922, 'grad_norm': 0.28515625, 'learning_rate': 1.6043795855444418e-05, 'epoch': 0.62}
 31%|███▏      | 244/780 [3:00:48<6:35:30, 44.27s/it] 31%|███▏      | 245/780 [3:01:33<6:35:55, 44.40s/it]                                                     {'loss': 0.3948, 'grad_norm': 0.326171875, 'learning_rate': 1.6010811472830253e-05, 'epoch': 0.63}
 31%|███▏      | 245/780 [3:01:33<6:35:55, 44.40s/it] 32%|███▏      | 246/780 [3:02:17<6:32:40, 44.12s/it]                                                     {'loss': 0.4254, 'grad_norm': 0.3125, 'learning_rate': 1.597772438203241e-05, 'epoch': 0.63}
 32%|███▏      | 246/780 [3:02:17<6:32:40, 44.12s/it] 32%|███▏      | 247/780 [3:03:01<6:31:27, 44.07s/it]                                                     {'loss': 0.395, 'grad_norm': 0.302734375, 'learning_rate': 1.5944535148417982e-05, 'epoch': 0.63}
 32%|███▏      | 247/780 [3:03:01<6:31:27, 44.07s/it] 32%|███▏      | 248/780 [3:03:45<6:30:40, 44.06s/it]                                                     {'loss': 0.4331, 'grad_norm': 0.31640625, 'learning_rate': 1.5911244339099393e-05, 'epoch': 0.63}
 32%|███▏      | 248/780 [3:03:45<6:30:40, 44.06s/it] 32%|███▏      | 249/780 [3:04:28<6:28:48, 43.93s/it]                                                     {'loss': 0.403, 'grad_norm': 0.314453125, 'learning_rate': 1.5877852522924733e-05, 'epoch': 0.64}
 32%|███▏      | 249/780 [3:04:28<6:28:48, 43.93s/it] 32%|███▏      | 250/780 [3:05:13<6:29:41, 44.12s/it]                                                     {'loss': 0.4188, 'grad_norm': 0.296875, 'learning_rate': 1.5844360270468e-05, 'epoch': 0.64}
 32%|███▏      | 250/780 [3:05:13<6:29:41, 44.12s/it] 32%|███▏      | 251/780 [3:05:57<6:30:23, 44.28s/it]                                                     {'loss': 0.3854, 'grad_norm': 0.30078125, 'learning_rate': 1.5810768154019386e-05, 'epoch': 0.64}
 32%|███▏      | 251/780 [3:05:57<6:30:23, 44.28s/it] 32%|███▏      | 252/780 [3:06:41<6:28:04, 44.10s/it]                                                     {'loss': 0.3821, 'grad_norm': 0.302734375, 'learning_rate': 1.577707674757547e-05, 'epoch': 0.65}
 32%|███▏      | 252/780 [3:06:41<6:28:04, 44.10s/it] 32%|███▏      | 253/780 [3:07:25<6:27:29, 44.12s/it]                                                     {'loss': 0.3757, 'grad_norm': 0.279296875, 'learning_rate': 1.5743286626829437e-05, 'epoch': 0.65}
 32%|███▏      | 253/780 [3:07:25<6:27:29, 44.12s/it] 33%|███▎      | 254/780 [3:08:14<6:39:54, 45.62s/it]                                                     {'loss': 0.4016, 'grad_norm': 0.341796875, 'learning_rate': 1.570939836916122e-05, 'epoch': 0.65}
 33%|███▎      | 254/780 [3:08:14<6:39:54, 45.62s/it] 33%|███▎      | 255/780 [3:09:00<6:38:24, 45.53s/it]                                                     {'loss': 0.4007, 'grad_norm': 0.32421875, 'learning_rate': 1.5675412553627638e-05, 'epoch': 0.65}
 33%|███▎      | 255/780 [3:09:00<6:38:24, 45.53s/it] 33%|███▎      | 256/780 [3:09:46<6:40:19, 45.84s/it]                                                     {'loss': 0.4145, 'grad_norm': 0.396484375, 'learning_rate': 1.5641329760952514e-05, 'epoch': 0.66}
 33%|███▎      | 256/780 [3:09:46<6:40:19, 45.84s/it] 33%|███▎      | 257/780 [3:10:30<6:33:52, 45.19s/it]                                                     {'loss': 0.4082, 'grad_norm': 0.31640625, 'learning_rate': 1.560715057351673e-05, 'epoch': 0.66}
 33%|███▎      | 257/780 [3:10:30<6:33:52, 45.19s/it] 33%|███▎      | 258/780 [3:11:15<6:31:37, 45.01s/it]                                                     {'loss': 0.3944, 'grad_norm': 0.2890625, 'learning_rate': 1.5572875575348298e-05, 'epoch': 0.66}
 33%|███▎      | 258/780 [3:11:15<6:31:37, 45.01s/it] 33%|███▎      | 259/780 [3:11:58<6:27:12, 44.59s/it]                                                     {'loss': 0.3933, 'grad_norm': 0.31640625, 'learning_rate': 1.5538505352112373e-05, 'epoch': 0.66}
 33%|███▎      | 259/780 [3:11:58<6:27:12, 44.59s/it] 33%|███▎      | 260/780 [3:12:43<6:26:29, 44.60s/it]                                                     {'loss': 0.3909, 'grad_norm': 0.318359375, 'learning_rate': 1.5504040491101235e-05, 'epoch': 0.67}
 33%|███▎      | 260/780 [3:12:43<6:26:29, 44.60s/it] 33%|███▎      | 261/780 [3:13:26<6:21:32, 44.11s/it]                                                     {'loss': 0.3896, 'grad_norm': 0.302734375, 'learning_rate': 1.5469481581224274e-05, 'epoch': 0.67}
 33%|███▎      | 261/780 [3:13:26<6:21:32, 44.11s/it] 34%|███▎      | 262/780 [3:14:14<6:31:42, 45.37s/it]                                                     {'loss': 0.3961, 'grad_norm': 0.3125, 'learning_rate': 1.5434829212997896e-05, 'epoch': 0.67}
 34%|███▎      | 262/780 [3:14:14<6:31:42, 45.37s/it] 34%|███▎      | 263/780 [3:15:01<6:34:05, 45.74s/it]                                                     {'loss': 0.3891, 'grad_norm': 0.298828125, 'learning_rate': 1.5400083978535475e-05, 'epoch': 0.67}
 34%|███▎      | 263/780 [3:15:01<6:34:05, 45.74s/it] 34%|███▍      | 264/780 [3:15:42<6:21:36, 44.37s/it]                                                     {'loss': 0.3961, 'grad_norm': 0.31640625, 'learning_rate': 1.5365246471537196e-05, 'epoch': 0.68}
 34%|███▍      | 264/780 [3:15:42<6:21:36, 44.37s/it] 34%|███▍      | 265/780 [3:16:23<6:13:44, 43.54s/it]                                                     {'loss': 0.395, 'grad_norm': 0.310546875, 'learning_rate': 1.533031728727994e-05, 'epoch': 0.68}
 34%|███▍      | 265/780 [3:16:23<6:13:44, 43.54s/it] 34%|███▍      | 266/780 [3:17:08<6:14:55, 43.77s/it]                                                     {'loss': 0.3856, 'grad_norm': 0.3046875, 'learning_rate': 1.529529702260709e-05, 'epoch': 0.68}
 34%|███▍      | 266/780 [3:17:08<6:14:55, 43.77s/it] 34%|███▍      | 267/780 [3:17:55<6:22:14, 44.71s/it]                                                     {'loss': 0.3911, 'grad_norm': 0.28515625, 'learning_rate': 1.526018627591834e-05, 'epoch': 0.68}
 34%|███▍      | 267/780 [3:17:55<6:22:14, 44.71s/it] 34%|███▍      | 268/780 [3:18:38<6:16:57, 44.17s/it]                                                     {'loss': 0.3717, 'grad_norm': 0.30078125, 'learning_rate': 1.5224985647159489e-05, 'epoch': 0.69}
 34%|███▍      | 268/780 [3:18:38<6:16:57, 44.17s/it] 34%|███▍      | 269/780 [3:19:21<6:15:07, 44.05s/it]                                                     {'loss': 0.3943, 'grad_norm': 0.28515625, 'learning_rate': 1.5189695737812153e-05, 'epoch': 0.69}
 34%|███▍      | 269/780 [3:19:21<6:15:07, 44.05s/it] 35%|███▍      | 270/780 [3:20:05<6:12:41, 43.85s/it]                                                     {'loss': 0.4542, 'grad_norm': 0.326171875, 'learning_rate': 1.5154317150883513e-05, 'epoch': 0.69}
 35%|███▍      | 270/780 [3:20:05<6:12:41, 43.85s/it] 35%|███▍      | 271/780 [3:20:46<6:05:38, 43.10s/it]                                                     {'loss': 0.4239, 'grad_norm': 0.328125, 'learning_rate': 1.5118850490896012e-05, 'epoch': 0.69}
 35%|███▍      | 271/780 [3:20:46<6:05:38, 43.10s/it] 35%|███▍      | 272/780 [3:21:31<6:09:54, 43.69s/it]                                                     {'loss': 0.4063, 'grad_norm': 0.310546875, 'learning_rate': 1.5083296363877007e-05, 'epoch': 0.7}
 35%|███▍      | 272/780 [3:21:31<6:09:54, 43.69s/it] 35%|███▌      | 273/780 [3:22:19<6:18:50, 44.83s/it]                                                     {'loss': 0.394, 'grad_norm': 0.310546875, 'learning_rate': 1.504765537734844e-05, 'epoch': 0.7}
 35%|███▌      | 273/780 [3:22:19<6:18:50, 44.83s/it] 35%|███▌      | 274/780 [3:23:03<6:17:41, 44.79s/it]                                                     {'loss': 0.3745, 'grad_norm': 0.30078125, 'learning_rate': 1.5011928140316428e-05, 'epoch': 0.7}
 35%|███▌      | 274/780 [3:23:03<6:17:41, 44.79s/it] 35%|███▌      | 275/780 [3:23:48<6:18:01, 44.91s/it]                                                     {'loss': 0.4037, 'grad_norm': 0.318359375, 'learning_rate': 1.4976115263260876e-05, 'epoch': 0.7}
 35%|███▌      | 275/780 [3:23:49<6:18:01, 44.91s/it] 35%|███▌      | 276/780 [3:24:34<6:17:53, 44.99s/it]                                                     {'loss': 0.3906, 'grad_norm': 0.32421875, 'learning_rate': 1.4940217358125042e-05, 'epoch': 0.71}
 35%|███▌      | 276/780 [3:24:34<6:17:53, 44.99s/it] 36%|███▌      | 277/780 [3:25:17<6:13:49, 44.59s/it]                                                     {'loss': 0.3882, 'grad_norm': 0.29296875, 'learning_rate': 1.4904235038305084e-05, 'epoch': 0.71}
 36%|███▌      | 277/780 [3:25:17<6:13:49, 44.59s/it] 36%|███▌      | 278/780 [3:26:01<6:09:37, 44.18s/it]                                                     {'loss': 0.3606, 'grad_norm': 0.32421875, 'learning_rate': 1.4868168918639564e-05, 'epoch': 0.71}
 36%|███▌      | 278/780 [3:26:01<6:09:37, 44.18s/it] 36%|███▌      | 279/780 [3:26:46<6:13:17, 44.70s/it]                                                     {'loss': 0.4141, 'grad_norm': 0.408203125, 'learning_rate': 1.4832019615398962e-05, 'epoch': 0.71}
 36%|███▌      | 279/780 [3:26:47<6:13:17, 44.70s/it] 36%|███▌      | 280/780 [3:27:30<6:10:38, 44.48s/it]                                                     {'loss': 0.398, 'grad_norm': 0.30859375, 'learning_rate': 1.4795787746275128e-05, 'epoch': 0.72}
 36%|███▌      | 280/780 [3:27:30<6:10:38, 44.48s/it] 36%|███▌      | 281/780 [3:28:13<6:05:42, 43.97s/it]                                                     {'loss': 0.4241, 'grad_norm': 0.294921875, 'learning_rate': 1.4759473930370738e-05, 'epoch': 0.72}
 36%|███▌      | 281/780 [3:28:13<6:05:42, 43.97s/it] 36%|███▌      | 282/780 [3:28:58<6:06:57, 44.21s/it]                                                     {'loss': 0.3991, 'grad_norm': 0.310546875, 'learning_rate': 1.4723078788188714e-05, 'epoch': 0.72}
 36%|███▌      | 282/780 [3:28:58<6:06:57, 44.21s/it] 36%|███▋      | 283/780 [3:29:43<6:09:16, 44.58s/it]                                                     {'loss': 0.3989, 'grad_norm': 0.3125, 'learning_rate': 1.4686602941621618e-05, 'epoch': 0.72}
 36%|███▋      | 283/780 [3:29:43<6:09:16, 44.58s/it] 36%|███▋      | 284/780 [3:30:27<6:07:06, 44.41s/it]                                                     {'loss': 0.392, 'grad_norm': 0.310546875, 'learning_rate': 1.4650047013941024e-05, 'epoch': 0.73}
 36%|███▋      | 284/780 [3:30:27<6:07:06, 44.41s/it] 37%|███▋      | 285/780 [3:31:11<6:04:29, 44.18s/it]                                                     {'loss': 0.3911, 'grad_norm': 0.30078125, 'learning_rate': 1.461341162978688e-05, 'epoch': 0.73}
 37%|███▋      | 285/780 [3:31:11<6:04:29, 44.18s/it] 37%|███▋      | 286/780 [3:31:55<6:02:38, 44.05s/it]                                                     {'loss': 0.4426, 'grad_norm': 0.328125, 'learning_rate': 1.4576697415156818e-05, 'epoch': 0.73}
 37%|███▋      | 286/780 [3:31:55<6:02:38, 44.05s/it] 37%|███▋      | 287/780 [3:32:41<6:06:43, 44.63s/it]                                                     {'loss': 0.3957, 'grad_norm': 0.2890625, 'learning_rate': 1.4539904997395468e-05, 'epoch': 0.73}
 37%|███▋      | 287/780 [3:32:41<6:06:43, 44.63s/it] 37%|███▋      | 288/780 [3:33:26<6:08:18, 44.92s/it]                                                     {'loss': 0.3963, 'grad_norm': 0.283203125, 'learning_rate': 1.4503035005183739e-05, 'epoch': 0.74}
 37%|███▋      | 288/780 [3:33:26<6:08:18, 44.92s/it] 37%|███▋      | 289/780 [3:34:14<6:13:02, 45.58s/it]                                                     {'loss': 0.3845, 'grad_norm': 0.31640625, 'learning_rate': 1.4466088068528068e-05, 'epoch': 0.74}
 37%|███▋      | 289/780 [3:34:14<6:13:02, 45.58s/it] 37%|███▋      | 290/780 [3:34:57<6:08:16, 45.10s/it]                                                     {'loss': 0.434, 'grad_norm': 0.314453125, 'learning_rate': 1.4429064818749659e-05, 'epoch': 0.74}
 37%|███▋      | 290/780 [3:34:58<6:08:16, 45.10s/it] 37%|███▋      | 291/780 [3:35:41<6:04:32, 44.73s/it]                                                     {'loss': 0.404, 'grad_norm': 0.361328125, 'learning_rate': 1.4391965888473705e-05, 'epoch': 0.74}
 37%|███▋      | 291/780 [3:35:41<6:04:32, 44.73s/it] 37%|███▋      | 292/780 [3:36:27<6:06:23, 45.05s/it]                                                     {'loss': 0.3766, 'grad_norm': 0.3046875, 'learning_rate': 1.4354791911618561e-05, 'epoch': 0.75}
 37%|███▋      | 292/780 [3:36:27<6:06:23, 45.05s/it] 38%|███▊      | 293/780 [3:37:11<6:02:17, 44.63s/it]                                                     {'loss': 0.3885, 'grad_norm': 0.296875, 'learning_rate': 1.4317543523384928e-05, 'epoch': 0.75}
 38%|███▊      | 293/780 [3:37:11<6:02:17, 44.63s/it] 38%|███▊      | 294/780 [3:37:55<5:59:54, 44.43s/it]                                                     {'loss': 0.4132, 'grad_norm': 0.3203125, 'learning_rate': 1.4280221360244993e-05, 'epoch': 0.75}
 38%|███▊      | 294/780 [3:37:55<5:59:54, 44.43s/it] 38%|███▊      | 295/780 [3:38:39<5:58:30, 44.35s/it]                                                     {'loss': 0.3889, 'grad_norm': 0.30859375, 'learning_rate': 1.4242826059931538e-05, 'epoch': 0.76}
 38%|███▊      | 295/780 [3:38:39<5:58:30, 44.35s/it] 38%|███▊      | 296/780 [3:39:24<6:00:28, 44.69s/it]                                                     {'loss': 0.3899, 'grad_norm': 0.302734375, 'learning_rate': 1.4205358261427076e-05, 'epoch': 0.76}
 38%|███▊      | 296/780 [3:39:24<6:00:28, 44.69s/it] 38%|███▊      | 297/780 [3:40:10<6:00:56, 44.84s/it]                                                     {'loss': 0.413, 'grad_norm': 0.349609375, 'learning_rate': 1.4167818604952906e-05, 'epoch': 0.76}
 38%|███▊      | 297/780 [3:40:10<6:00:56, 44.84s/it] 38%|███▊      | 298/780 [3:40:53<5:56:39, 44.40s/it]                                                     {'loss': 0.3909, 'grad_norm': 0.3046875, 'learning_rate': 1.4130207731958176e-05, 'epoch': 0.76}
 38%|███▊      | 298/780 [3:40:53<5:56:39, 44.40s/it] 38%|███▊      | 299/780 [3:41:36<5:53:49, 44.14s/it]                                                     {'loss': 0.3808, 'grad_norm': 0.3203125, 'learning_rate': 1.409252628510894e-05, 'epoch': 0.77}
 38%|███▊      | 299/780 [3:41:37<5:53:49, 44.14s/it] 38%|███▊      | 300/780 [3:42:18<5:47:18, 43.41s/it]                                                     {'loss': 0.4017, 'grad_norm': 0.31640625, 'learning_rate': 1.4054774908277158e-05, 'epoch': 0.77}
 38%|███▊      | 300/780 [3:42:18<5:47:18, 43.41s/it] 39%|███▊      | 301/780 [3:43:01<5:45:17, 43.25s/it]                                                     {'loss': 0.4267, 'grad_norm': 0.30078125, 'learning_rate': 1.4016954246529697e-05, 'epoch': 0.77}
 39%|███▊      | 301/780 [3:43:01<5:45:17, 43.25s/it] 39%|███▊      | 302/780 [3:43:44<5:44:34, 43.25s/it]                                                     {'loss': 0.3873, 'grad_norm': 0.3046875, 'learning_rate': 1.3979064946117316e-05, 'epoch': 0.77}
 39%|███▊      | 302/780 [3:43:44<5:44:34, 43.25s/it] 39%|███▉      | 303/780 [3:44:27<5:42:59, 43.14s/it]                                                     {'loss': 0.4013, 'grad_norm': 0.3125, 'learning_rate': 1.3941107654463619e-05, 'epoch': 0.78}
 39%|███▉      | 303/780 [3:44:27<5:42:59, 43.14s/it] 39%|███▉      | 304/780 [3:45:09<5:39:45, 42.83s/it]                                                     {'loss': 0.404, 'grad_norm': 0.333984375, 'learning_rate': 1.3903083020153991e-05, 'epoch': 0.78}
 39%|███▉      | 304/780 [3:45:09<5:39:45, 42.83s/it] 39%|███▉      | 305/780 [3:45:54<5:42:57, 43.32s/it]                                                     {'loss': 0.4142, 'grad_norm': 0.326171875, 'learning_rate': 1.3864991692924524e-05, 'epoch': 0.78}
 39%|███▉      | 305/780 [3:45:54<5:42:57, 43.32s/it] 39%|███▉      | 306/780 [3:46:36<5:40:08, 43.06s/it]                                                     {'loss': 0.3856, 'grad_norm': 0.333984375, 'learning_rate': 1.3826834323650899e-05, 'epoch': 0.78}
 39%|███▉      | 306/780 [3:46:36<5:40:08, 43.06s/it] 39%|███▉      | 307/780 [3:47:22<5:44:52, 43.75s/it]                                                     {'loss': 0.4256, 'grad_norm': 0.33984375, 'learning_rate': 1.3788611564337277e-05, 'epoch': 0.79}
 39%|███▉      | 307/780 [3:47:22<5:44:52, 43.75s/it] 39%|███▉      | 308/780 [3:48:04<5:40:25, 43.27s/it]                                                     {'loss': 0.4176, 'grad_norm': 0.318359375, 'learning_rate': 1.3750324068105156e-05, 'epoch': 0.79}
 39%|███▉      | 308/780 [3:48:04<5:40:25, 43.27s/it] 40%|███▉      | 309/780 [3:48:50<5:47:47, 44.30s/it]                                                     {'loss': 0.3778, 'grad_norm': 0.29296875, 'learning_rate': 1.3711972489182208e-05, 'epoch': 0.79}
 40%|███▉      | 309/780 [3:48:51<5:47:47, 44.30s/it] 40%|███▉      | 310/780 [3:49:38<5:54:49, 45.30s/it]                                                     {'loss': 0.3841, 'grad_norm': 0.326171875, 'learning_rate': 1.36735574828911e-05, 'epoch': 0.79}
 40%|███▉      | 310/780 [3:49:38<5:54:49, 45.30s/it] 40%|███▉      | 311/780 [3:50:23<5:53:44, 45.26s/it]                                                     {'loss': 0.3998, 'grad_norm': 0.330078125, 'learning_rate': 1.3635079705638298e-05, 'epoch': 0.8}
 40%|███▉      | 311/780 [3:50:23<5:53:44, 45.26s/it] 40%|████      | 312/780 [3:51:06<5:47:29, 44.55s/it]                                                     {'loss': 0.4248, 'grad_norm': 0.306640625, 'learning_rate': 1.3596539814902856e-05, 'epoch': 0.8}
 40%|████      | 312/780 [3:51:06<5:47:29, 44.55s/it] 40%|████      | 313/780 [3:51:52<5:50:31, 45.04s/it]                                                     {'loss': 0.3575, 'grad_norm': 0.34375, 'learning_rate': 1.3557938469225167e-05, 'epoch': 0.8}
 40%|████      | 313/780 [3:51:52<5:50:31, 45.04s/it] 40%|████      | 314/780 [3:52:32<5:37:23, 43.44s/it]                                                     {'loss': 0.4054, 'grad_norm': 0.31640625, 'learning_rate': 1.3519276328195725e-05, 'epoch': 0.8}
 40%|████      | 314/780 [3:52:32<5:37:23, 43.44s/it] 40%|████      | 315/780 [3:53:17<5:41:02, 44.00s/it]                                                     {'loss': 0.4257, 'grad_norm': 0.33203125, 'learning_rate': 1.3480554052443847e-05, 'epoch': 0.81}
 40%|████      | 315/780 [3:53:17<5:41:02, 44.00s/it] 41%|████      | 316/780 [3:54:03<5:43:54, 44.47s/it]                                                     {'loss': 0.4096, 'grad_norm': 0.283203125, 'learning_rate': 1.3441772303626387e-05, 'epoch': 0.81}
 41%|████      | 316/780 [3:54:03<5:43:54, 44.47s/it] 41%|████      | 317/780 [3:54:47<5:41:56, 44.31s/it]                                                     {'loss': 0.3978, 'grad_norm': 0.291015625, 'learning_rate': 1.3402931744416432e-05, 'epoch': 0.81}
 41%|████      | 317/780 [3:54:47<5:41:56, 44.31s/it] 41%|████      | 318/780 [3:55:32<5:42:14, 44.45s/it]                                                     {'loss': 0.3927, 'grad_norm': 0.30859375, 'learning_rate': 1.3364033038491972e-05, 'epoch': 0.81}
 41%|████      | 318/780 [3:55:32<5:42:14, 44.45s/it] 41%|████      | 319/780 [3:56:16<5:41:06, 44.40s/it]                                                     {'loss': 0.4096, 'grad_norm': 0.333984375, 'learning_rate': 1.332507685052457e-05, 'epoch': 0.82}
 41%|████      | 319/780 [3:56:16<5:41:06, 44.40s/it] 41%|████      | 320/780 [3:57:02<5:43:33, 44.81s/it]                                                     {'loss': 0.3955, 'grad_norm': 0.2734375, 'learning_rate': 1.328606384616799e-05, 'epoch': 0.82}
 41%|████      | 320/780 [3:57:02<5:43:33, 44.81s/it] 41%|████      | 321/780 [3:57:47<5:43:09, 44.86s/it]                                                     {'loss': 0.3721, 'grad_norm': 0.302734375, 'learning_rate': 1.3246994692046837e-05, 'epoch': 0.82}
 41%|████      | 321/780 [3:57:47<5:43:09, 44.86s/it] 41%|████▏     | 322/780 [3:58:32<5:43:49, 45.04s/it]                                                     {'loss': 0.4165, 'grad_norm': 0.29296875, 'learning_rate': 1.320787005574516e-05, 'epoch': 0.82}
 41%|████▏     | 322/780 [3:58:32<5:43:49, 45.04s/it] 41%|████▏     | 323/780 [3:59:16<5:40:35, 44.72s/it]                                                     {'loss': 0.3551, 'grad_norm': 0.3203125, 'learning_rate': 1.3168690605795044e-05, 'epoch': 0.83}
 41%|████▏     | 323/780 [3:59:16<5:40:35, 44.72s/it] 42%|████▏     | 324/780 [4:00:00<5:37:53, 44.46s/it]                                                     {'loss': 0.4062, 'grad_norm': 0.32421875, 'learning_rate': 1.3129457011665191e-05, 'epoch': 0.83}
 42%|████▏     | 324/780 [4:00:00<5:37:53, 44.46s/it] 42%|████▏     | 325/780 [4:00:47<5:42:12, 45.13s/it]                                                     {'loss': 0.4028, 'grad_norm': 0.275390625, 'learning_rate': 1.3090169943749475e-05, 'epoch': 0.83}
 42%|████▏     | 325/780 [4:00:47<5:42:12, 45.13s/it] 42%|████▏     | 326/780 [4:01:32<5:43:03, 45.34s/it]                                                     {'loss': 0.3945, 'grad_norm': 0.283203125, 'learning_rate': 1.305083007335549e-05, 'epoch': 0.83}
 42%|████▏     | 326/780 [4:01:32<5:43:03, 45.34s/it] 42%|████▏     | 327/780 [4:02:16<5:37:34, 44.71s/it]                                                     {'loss': 0.3928, 'grad_norm': 0.32421875, 'learning_rate': 1.3011438072693077e-05, 'epoch': 0.84}
 42%|████▏     | 327/780 [4:02:16<5:37:34, 44.71s/it] 42%|████▏     | 328/780 [4:03:02<5:39:32, 45.07s/it]                                                     {'loss': 0.3897, 'grad_norm': 0.328125, 'learning_rate': 1.297199461486284e-05, 'epoch': 0.84}
 42%|████▏     | 328/780 [4:03:02<5:39:32, 45.07s/it] 42%|████▏     | 329/780 [4:03:46<5:37:02, 44.84s/it]                                                     {'loss': 0.3944, 'grad_norm': 0.296875, 'learning_rate': 1.293250037384465e-05, 'epoch': 0.84}
 42%|████▏     | 329/780 [4:03:46<5:37:02, 44.84s/it] 42%|████▏     | 330/780 [4:04:30<5:35:06, 44.68s/it]                                                     {'loss': 0.4364, 'grad_norm': 0.341796875, 'learning_rate': 1.2892956024486111e-05, 'epoch': 0.84}
 42%|████▏     | 330/780 [4:04:30<5:35:06, 44.68s/it] 42%|████▏     | 331/780 [4:05:16<5:37:11, 45.06s/it]                                                     {'loss': 0.3673, 'grad_norm': 0.328125, 'learning_rate': 1.2853362242491054e-05, 'epoch': 0.85}
 42%|████▏     | 331/780 [4:05:16<5:37:11, 45.06s/it] 43%|████▎     | 332/780 [4:05:59<5:30:33, 44.27s/it]                                                     {'loss': 0.3957, 'grad_norm': 0.3046875, 'learning_rate': 1.2813719704407965e-05, 'epoch': 0.85}
 43%|████▎     | 332/780 [4:05:59<5:30:33, 44.27s/it] 43%|████▎     | 333/780 [4:06:42<5:28:29, 44.09s/it]                                                     {'loss': 0.3694, 'grad_norm': 0.291015625, 'learning_rate': 1.2774029087618448e-05, 'epoch': 0.85}
 43%|████▎     | 333/780 [4:06:42<5:28:29, 44.09s/it] 43%|████▎     | 334/780 [4:07:25<5:25:31, 43.79s/it]                                                     {'loss': 0.387, 'grad_norm': 0.29296875, 'learning_rate': 1.2734291070325627e-05, 'epoch': 0.86}
 43%|████▎     | 334/780 [4:07:25<5:25:31, 43.79s/it] 43%|████▎     | 335/780 [4:08:09<5:24:45, 43.79s/it]                                                     {'loss': 0.4313, 'grad_norm': 0.31640625, 'learning_rate': 1.269450633154258e-05, 'epoch': 0.86}
 43%|████▎     | 335/780 [4:08:09<5:24:45, 43.79s/it] 43%|████▎     | 336/780 [4:08:55<5:27:52, 44.31s/it]                                                     {'loss': 0.383, 'grad_norm': 0.31640625, 'learning_rate': 1.2654675551080724e-05, 'epoch': 0.86}
 43%|████▎     | 336/780 [4:08:55<5:27:52, 44.31s/it] 43%|████▎     | 337/780 [4:09:40<5:29:12, 44.59s/it]                                                     {'loss': 0.386, 'grad_norm': 0.302734375, 'learning_rate': 1.26147994095382e-05, 'epoch': 0.86}
 43%|████▎     | 337/780 [4:09:40<5:29:12, 44.59s/it] 43%|████▎     | 338/780 [4:10:23<5:25:57, 44.25s/it]                                                     {'loss': 0.396, 'grad_norm': 0.34765625, 'learning_rate': 1.257487858828824e-05, 'epoch': 0.87}
 43%|████▎     | 338/780 [4:10:23<5:25:57, 44.25s/it] 43%|████▎     | 339/780 [4:11:09<5:27:22, 44.54s/it]                                                     {'loss': 0.3975, 'grad_norm': 0.3203125, 'learning_rate': 1.253491376946754e-05, 'epoch': 0.87}
 43%|████▎     | 339/780 [4:11:09<5:27:22, 44.54s/it] 44%|████▎     | 340/780 [4:11:53<5:27:29, 44.66s/it]                                                     {'loss': 0.4065, 'grad_norm': 0.353515625, 'learning_rate': 1.2494905635964587e-05, 'epoch': 0.87}
 44%|████▎     | 340/780 [4:11:54<5:27:29, 44.66s/it] 44%|████▎     | 341/780 [4:12:40<5:31:04, 45.25s/it]                                                     {'loss': 0.4018, 'grad_norm': 0.341796875, 'learning_rate': 1.2454854871407993e-05, 'epoch': 0.87}
 44%|████▎     | 341/780 [4:12:40<5:31:04, 45.25s/it] 44%|████▍     | 342/780 [4:13:23<5:26:03, 44.67s/it]                                                     {'loss': 0.4031, 'grad_norm': 0.31640625, 'learning_rate': 1.241476216015482e-05, 'epoch': 0.88}
 44%|████▍     | 342/780 [4:13:23<5:26:03, 44.67s/it] 44%|████▍     | 343/780 [4:14:08<5:24:44, 44.59s/it]                                                     {'loss': 0.4147, 'grad_norm': 0.322265625, 'learning_rate': 1.2374628187278888e-05, 'epoch': 0.88}
 44%|████▍     | 343/780 [4:14:08<5:24:44, 44.59s/it] 44%|████▍     | 344/780 [4:14:50<5:19:10, 43.92s/it]                                                     {'loss': 0.382, 'grad_norm': 0.3203125, 'learning_rate': 1.2334453638559057e-05, 'epoch': 0.88}
 44%|████▍     | 344/780 [4:14:50<5:19:10, 43.92s/it] 44%|████▍     | 345/780 [4:15:35<5:21:21, 44.33s/it]                                                     {'loss': 0.3752, 'grad_norm': 0.3125, 'learning_rate': 1.2294239200467516e-05, 'epoch': 0.88}
 44%|████▍     | 345/780 [4:15:36<5:21:21, 44.33s/it] 44%|████▍     | 346/780 [4:16:19<5:19:28, 44.17s/it]                                                     {'loss': 0.4052, 'grad_norm': 0.310546875, 'learning_rate': 1.2253985560158064e-05, 'epoch': 0.89}
 44%|████▍     | 346/780 [4:16:19<5:19:28, 44.17s/it] 44%|████▍     | 347/780 [4:17:03<5:16:50, 43.90s/it]                                                     {'loss': 0.3725, 'grad_norm': 0.326171875, 'learning_rate': 1.2213693405454345e-05, 'epoch': 0.89}
 44%|████▍     | 347/780 [4:17:03<5:16:50, 43.90s/it] 45%|████▍     | 348/780 [4:17:50<5:23:33, 44.94s/it]                                                     {'loss': 0.3998, 'grad_norm': 0.310546875, 'learning_rate': 1.2173363424838116e-05, 'epoch': 0.89}
 45%|████▍     | 348/780 [4:17:50<5:23:33, 44.94s/it] 45%|████▍     | 349/780 [4:18:34<5:20:34, 44.63s/it]                                                     {'loss': 0.4014, 'grad_norm': 0.306640625, 'learning_rate': 1.213299630743747e-05, 'epoch': 0.89}
 45%|████▍     | 349/780 [4:18:34<5:20:34, 44.63s/it] 45%|████▍     | 350/780 [4:19:17<5:16:29, 44.16s/it]                                                     {'loss': 0.3606, 'grad_norm': 0.294921875, 'learning_rate': 1.2092592743015065e-05, 'epoch': 0.9}
 45%|████▍     | 350/780 [4:19:17<5:16:29, 44.16s/it] 45%|████▌     | 351/780 [4:20:02<5:18:15, 44.51s/it]                                                     {'loss': 0.3637, 'grad_norm': 0.302734375, 'learning_rate': 1.2052153421956343e-05, 'epoch': 0.9}
 45%|████▌     | 351/780 [4:20:02<5:18:15, 44.51s/it] 45%|████▌     | 352/780 [4:20:49<5:22:00, 45.14s/it]                                                     {'loss': 0.439, 'grad_norm': 0.484375, 'learning_rate': 1.2011679035257724e-05, 'epoch': 0.9}
 45%|████▌     | 352/780 [4:20:49<5:22:00, 45.14s/it] 45%|████▌     | 353/780 [4:21:32<5:16:59, 44.54s/it]                                                     {'loss': 0.3728, 'grad_norm': 0.30078125, 'learning_rate': 1.1971170274514802e-05, 'epoch': 0.9}
 45%|████▌     | 353/780 [4:21:32<5:16:59, 44.54s/it] 45%|████▌     | 354/780 [4:22:17<5:16:38, 44.60s/it]                                                     {'loss': 0.4085, 'grad_norm': 0.318359375, 'learning_rate': 1.1930627831910537e-05, 'epoch': 0.91}
 45%|████▌     | 354/780 [4:22:17<5:16:38, 44.60s/it] 46%|████▌     | 355/780 [4:23:00<5:12:31, 44.12s/it]                                                     {'loss': 0.3763, 'grad_norm': 0.3046875, 'learning_rate': 1.1890052400203405e-05, 'epoch': 0.91}
 46%|████▌     | 355/780 [4:23:00<5:12:31, 44.12s/it] 46%|████▌     | 356/780 [4:23:44<5:13:01, 44.30s/it]                                                     {'loss': 0.3913, 'grad_norm': 0.337890625, 'learning_rate': 1.1849444672715587e-05, 'epoch': 0.91}
 46%|████▌     | 356/780 [4:23:44<5:13:01, 44.30s/it] 46%|████▌     | 357/780 [4:24:30<5:15:30, 44.75s/it]                                                     {'loss': 0.3877, 'grad_norm': 0.361328125, 'learning_rate': 1.1808805343321102e-05, 'epoch': 0.91}
 46%|████▌     | 357/780 [4:24:30<5:15:30, 44.75s/it] 46%|████▌     | 358/780 [4:25:17<5:18:16, 45.25s/it]                                                     {'loss': 0.3974, 'grad_norm': 0.3046875, 'learning_rate': 1.1768135106433961e-05, 'epoch': 0.92}
 46%|████▌     | 358/780 [4:25:17<5:18:16, 45.25s/it] 46%|████▌     | 359/780 [4:26:03<5:19:23, 45.52s/it]                                                     {'loss': 0.4002, 'grad_norm': 0.3125, 'learning_rate': 1.1727434656996306e-05, 'epoch': 0.92}
 46%|████▌     | 359/780 [4:26:03<5:19:23, 45.52s/it] 46%|████▌     | 360/780 [4:26:47<5:16:02, 45.15s/it]                                                     {'loss': 0.3752, 'grad_norm': 0.326171875, 'learning_rate': 1.1686704690466515e-05, 'epoch': 0.92}
 46%|████▌     | 360/780 [4:26:47<5:16:02, 45.15s/it] 46%|████▋     | 361/780 [4:27:33<5:17:23, 45.45s/it]                                                     {'loss': 0.3777, 'grad_norm': 0.318359375, 'learning_rate': 1.164594590280734e-05, 'epoch': 0.92}
 46%|████▋     | 361/780 [4:27:33<5:17:23, 45.45s/it] 46%|████▋     | 362/780 [4:28:17<5:12:54, 44.92s/it]                                                     {'loss': 0.3676, 'grad_norm': 0.30859375, 'learning_rate': 1.1605158990474008e-05, 'epoch': 0.93}
 46%|████▋     | 362/780 [4:28:17<5:12:54, 44.92s/it] 47%|████▋     | 363/780 [4:29:01<5:09:49, 44.58s/it]                                                     {'loss': 0.3814, 'grad_norm': 0.30859375, 'learning_rate': 1.156434465040231e-05, 'epoch': 0.93}
 47%|████▋     | 363/780 [4:29:01<5:09:49, 44.58s/it] 47%|████▋     | 364/780 [4:29:47<5:13:23, 45.20s/it]                                                     {'loss': 0.3986, 'grad_norm': 0.3203125, 'learning_rate': 1.152350357999671e-05, 'epoch': 0.93}
 47%|████▋     | 364/780 [4:29:47<5:13:23, 45.20s/it] 47%|████▋     | 365/780 [4:30:32<5:12:02, 45.12s/it]                                                     {'loss': 0.3787, 'grad_norm': 0.310546875, 'learning_rate': 1.148263647711842e-05, 'epoch': 0.93}
 47%|████▋     | 365/780 [4:30:32<5:12:02, 45.12s/it] 47%|████▋     | 366/780 [4:31:16<5:07:44, 44.60s/it]                                                     {'loss': 0.415, 'grad_norm': 0.34375, 'learning_rate': 1.1441744040073469e-05, 'epoch': 0.94}
 47%|████▋     | 366/780 [4:31:16<5:07:44, 44.60s/it] 47%|████▋     | 367/780 [4:31:59<5:03:23, 44.08s/it]                                                     {'loss': 0.3931, 'grad_norm': 0.31640625, 'learning_rate': 1.140082696760078e-05, 'epoch': 0.94}
 47%|████▋     | 367/780 [4:31:59<5:03:23, 44.08s/it] 47%|████▋     | 368/780 [4:32:45<5:07:18, 44.75s/it]                                                     {'loss': 0.3797, 'grad_norm': 0.32421875, 'learning_rate': 1.1359885958860228e-05, 'epoch': 0.94}
 47%|████▋     | 368/780 [4:32:45<5:07:18, 44.75s/it] 47%|████▋     | 369/780 [4:33:30<5:08:14, 45.00s/it]                                                     {'loss': 0.3865, 'grad_norm': 0.29296875, 'learning_rate': 1.1318921713420691e-05, 'epoch': 0.94}
 47%|████▋     | 369/780 [4:33:30<5:08:14, 45.00s/it] 47%|████▋     | 370/780 [4:34:16<5:09:36, 45.31s/it]                                                     {'loss': 0.4072, 'grad_norm': 0.41796875, 'learning_rate': 1.1277934931248103e-05, 'epoch': 0.95}
 47%|████▋     | 370/780 [4:34:17<5:09:36, 45.31s/it] 48%|████▊     | 371/780 [4:35:04<5:13:06, 45.93s/it]                                                     {'loss': 0.406, 'grad_norm': 0.435546875, 'learning_rate': 1.123692631269348e-05, 'epoch': 0.95}
 48%|████▊     | 371/780 [4:35:04<5:13:06, 45.93s/it] 48%|████▊     | 372/780 [4:35:47<5:06:42, 45.10s/it]                                                     {'loss': 0.3793, 'grad_norm': 0.365234375, 'learning_rate': 1.1195896558480967e-05, 'epoch': 0.95}
 48%|████▊     | 372/780 [4:35:47<5:06:42, 45.10s/it] 48%|████▊     | 373/780 [4:36:33<5:07:03, 45.27s/it]                                                     {'loss': 0.4279, 'grad_norm': 0.314453125, 'learning_rate': 1.1154846369695864e-05, 'epoch': 0.95}
 48%|████▊     | 373/780 [4:36:33<5:07:03, 45.27s/it] 48%|████▊     | 374/780 [4:37:19<5:08:40, 45.62s/it]                                                     {'loss': 0.3685, 'grad_norm': 0.30859375, 'learning_rate': 1.111377644777263e-05, 'epoch': 0.96}
 48%|████▊     | 374/780 [4:37:19<5:08:40, 45.62s/it] 48%|████▊     | 375/780 [4:38:07<5:11:34, 46.16s/it]                                                     {'loss': 0.3889, 'grad_norm': 0.302734375, 'learning_rate': 1.107268749448292e-05, 'epoch': 0.96}
 48%|████▊     | 375/780 [4:38:07<5:11:34, 46.16s/it] 48%|████▊     | 376/780 [4:38:50<5:05:17, 45.34s/it]                                                     {'loss': 0.3877, 'grad_norm': 0.30859375, 'learning_rate': 1.103158021192357e-05, 'epoch': 0.96}
 48%|████▊     | 376/780 [4:38:50<5:05:17, 45.34s/it] 48%|████▊     | 377/780 [4:39:34<5:02:17, 45.01s/it]                                                     {'loss': 0.3972, 'grad_norm': 0.3046875, 'learning_rate': 1.099045530250463e-05, 'epoch': 0.97}
 48%|████▊     | 377/780 [4:39:34<5:02:17, 45.01s/it] 48%|████▊     | 378/780 [4:40:17<4:56:28, 44.25s/it]                                                     {'loss': 0.3968, 'grad_norm': 0.326171875, 'learning_rate': 1.0949313468937325e-05, 'epoch': 0.97}
 48%|████▊     | 378/780 [4:40:17<4:56:28, 44.25s/it] 49%|████▊     | 379/780 [4:40:58<4:49:01, 43.25s/it]                                                     {'loss': 0.3956, 'grad_norm': 0.3125, 'learning_rate': 1.0908155414222083e-05, 'epoch': 0.97}
 49%|████▊     | 379/780 [4:40:58<4:49:01, 43.25s/it] 49%|████▊     | 380/780 [4:41:41<4:48:56, 43.34s/it]                                                     {'loss': 0.3711, 'grad_norm': 0.38671875, 'learning_rate': 1.08669818416365e-05, 'epoch': 0.97}
 49%|████▊     | 380/780 [4:41:41<4:48:56, 43.34s/it] 49%|████▉     | 381/780 [4:42:26<4:51:11, 43.79s/it]                                                     {'loss': 0.3963, 'grad_norm': 0.345703125, 'learning_rate': 1.0825793454723325e-05, 'epoch': 0.98}
 49%|████▉     | 381/780 [4:42:26<4:51:11, 43.79s/it] 49%|████▉     | 382/780 [4:43:09<4:49:48, 43.69s/it]                                                     {'loss': 0.411, 'grad_norm': 0.3671875, 'learning_rate': 1.0784590957278452e-05, 'epoch': 0.98}
 49%|████▉     | 382/780 [4:43:09<4:49:48, 43.69s/it] 49%|████▉     | 383/780 [4:43:54<4:50:18, 43.88s/it]                                                     {'loss': 0.3867, 'grad_norm': 0.28125, 'learning_rate': 1.0743375053338879e-05, 'epoch': 0.98}
 49%|████▉     | 383/780 [4:43:54<4:50:18, 43.88s/it] 49%|████▉     | 384/780 [4:44:39<4:52:02, 44.25s/it]                                                     {'loss': 0.3997, 'grad_norm': 0.306640625, 'learning_rate': 1.0702146447170683e-05, 'epoch': 0.98}
 49%|████▉     | 384/780 [4:44:39<4:52:02, 44.25s/it] 49%|████▉     | 385/780 [4:45:22<4:49:23, 43.96s/it]                                                     {'loss': 0.3763, 'grad_norm': 0.322265625, 'learning_rate': 1.0660905843256995e-05, 'epoch': 0.99}
 49%|████▉     | 385/780 [4:45:22<4:49:23, 43.96s/it] 49%|████▉     | 386/780 [4:46:03<4:42:44, 43.06s/it]                                                     {'loss': 0.3785, 'grad_norm': 0.3046875, 'learning_rate': 1.0619653946285948e-05, 'epoch': 0.99}
 49%|████▉     | 386/780 [4:46:03<4:42:44, 43.06s/it] 50%|████▉     | 387/780 [4:46:43<4:36:49, 42.26s/it]                                                     {'loss': 0.3902, 'grad_norm': 0.33984375, 'learning_rate': 1.0578391461138642e-05, 'epoch': 0.99}
 50%|████▉     | 387/780 [4:46:44<4:36:49, 42.26s/it] 50%|████▉     | 388/780 [4:47:28<4:40:10, 42.88s/it]                                                     {'loss': 0.3709, 'grad_norm': 0.353515625, 'learning_rate': 1.05371190928771e-05, 'epoch': 0.99}
 50%|████▉     | 388/780 [4:47:28<4:40:10, 42.88s/it] 50%|████▉     | 389/780 [4:48:13<4:42:59, 43.43s/it]                                                     {'loss': 0.3925, 'grad_norm': 0.31640625, 'learning_rate': 1.0495837546732224e-05, 'epoch': 1.0}
 50%|████▉     | 389/780 [4:48:13<4:42:59, 43.43s/it] 50%|█████     | 390/780 [4:48:53<4:37:14, 42.65s/it]                                                     {'loss': 0.4082, 'grad_norm': 0.314453125, 'learning_rate': 1.0454547528091737e-05, 'epoch': 1.0}
 50%|█████     | 390/780 [4:48:53<4:37:14, 42.65s/it] 50%|█████     | 391/780 [4:49:22<4:10:01, 38.56s/it]                                                     {'loss': 0.3775, 'grad_norm': 0.423828125, 'learning_rate': 1.0413249742488132e-05, 'epoch': 1.0}
 50%|█████     | 391/780 [4:49:22<4:10:01, 38.56s/it] 50%|█████     | 392/780 [4:50:06<4:20:06, 40.22s/it]                                                     {'loss': 0.391, 'grad_norm': 0.34765625, 'learning_rate': 1.0371944895586626e-05, 'epoch': 1.0}
 50%|█████     | 392/780 [4:50:07<4:20:06, 40.22s/it] 50%|█████     | 393/780 [4:50:49<4:24:39, 41.03s/it]                                                     {'loss': 0.3796, 'grad_norm': 0.294921875, 'learning_rate': 1.0330633693173083e-05, 'epoch': 1.01}
 50%|█████     | 393/780 [4:50:49<4:24:39, 41.03s/it] 51%|█████     | 394/780 [4:51:32<4:26:03, 41.36s/it]                                                     {'loss': 0.352, 'grad_norm': 0.314453125, 'learning_rate': 1.0289316841141972e-05, 'epoch': 1.01}
 51%|█████     | 394/780 [4:51:32<4:26:03, 41.36s/it] 51%|█████     | 395/780 [4:52:14<4:26:48, 41.58s/it]                                                     {'loss': 0.3436, 'grad_norm': 0.275390625, 'learning_rate': 1.0247995045484303e-05, 'epoch': 1.01}
 51%|█████     | 395/780 [4:52:14<4:26:48, 41.58s/it] 51%|█████     | 396/780 [4:52:57<4:29:06, 42.05s/it]                                                     {'loss': 0.3515, 'grad_norm': 0.28125, 'learning_rate': 1.0206669012275546e-05, 'epoch': 1.01}
 51%|█████     | 396/780 [4:52:57<4:29:06, 42.05s/it] 51%|█████     | 397/780 [4:53:43<4:36:46, 43.36s/it]                                                     {'loss': 0.3981, 'grad_norm': 0.3046875, 'learning_rate': 1.0165339447663586e-05, 'epoch': 1.02}
 51%|█████     | 397/780 [4:53:43<4:36:46, 43.36s/it] 51%|█████     | 398/780 [4:54:28<4:38:55, 43.81s/it]                                                     {'loss': 0.3827, 'grad_norm': 0.2890625, 'learning_rate': 1.0124007057856656e-05, 'epoch': 1.02}
 51%|█████     | 398/780 [4:54:28<4:38:55, 43.81s/it] 51%|█████     | 399/780 [4:55:11<4:36:45, 43.59s/it]                                                     {'loss': 0.3692, 'grad_norm': 0.298828125, 'learning_rate': 1.008267254911125e-05, 'epoch': 1.02}
 51%|█████     | 399/780 [4:55:11<4:36:45, 43.59s/it] 51%|█████▏    | 400/780 [4:55:55<4:36:05, 43.59s/it]                                                     {'loss': 0.4023, 'grad_norm': 0.2890625, 'learning_rate': 1.0041336627720085e-05, 'epoch': 1.02}
 51%|█████▏    | 400/780 [4:55:55<4:36:05, 43.59s/it] 51%|█████▏    | 401/780 [4:56:40<4:38:57, 44.16s/it]                                                     {'loss': 0.3552, 'grad_norm': 0.29296875, 'learning_rate': 1e-05, 'epoch': 1.03}
 51%|█████▏    | 401/780 [4:56:40<4:38:57, 44.16s/it] 52%|█████▏    | 402/780 [4:57:26<4:40:30, 44.53s/it]                                                     {'loss': 0.3811, 'grad_norm': 0.42578125, 'learning_rate': 9.95866337227992e-06, 'epoch': 1.03}
 52%|█████▏    | 402/780 [4:57:26<4:40:30, 44.53s/it] 52%|█████▏    | 403/780 [4:58:11<4:40:54, 44.71s/it]                                                     {'loss': 0.3835, 'grad_norm': 0.3125, 'learning_rate': 9.917327450888751e-06, 'epoch': 1.03}
 52%|█████▏    | 403/780 [4:58:11<4:40:54, 44.71s/it] 52%|█████▏    | 404/780 [4:58:55<4:39:49, 44.65s/it]                                                     {'loss': 0.3862, 'grad_norm': 0.318359375, 'learning_rate': 9.875992942143351e-06, 'epoch': 1.03}
 52%|█████▏    | 404/780 [4:58:55<4:39:49, 44.65s/it] 52%|█████▏    | 405/780 [4:59:42<4:42:28, 45.20s/it]                                                     {'loss': 0.3836, 'grad_norm': 0.302734375, 'learning_rate': 9.834660552336415e-06, 'epoch': 1.04}
 52%|█████▏    | 405/780 [4:59:42<4:42:28, 45.20s/it] 52%|█████▏    | 406/780 [5:00:26<4:39:51, 44.90s/it]                                                     {'loss': 0.3808, 'grad_norm': 0.287109375, 'learning_rate': 9.79333098772446e-06, 'epoch': 1.04}
 52%|█████▏    | 406/780 [5:00:26<4:39:51, 44.90s/it] 52%|█████▏    | 407/780 [5:01:13<4:42:37, 45.46s/it]                                                     {'loss': 0.3882, 'grad_norm': 0.34375, 'learning_rate': 9.7520049545157e-06, 'epoch': 1.04}
 52%|█████▏    | 407/780 [5:01:13<4:42:37, 45.46s/it] 52%|█████▏    | 408/780 [5:01:55<4:35:47, 44.48s/it]                                                     {'loss': 0.3503, 'grad_norm': 0.294921875, 'learning_rate': 9.71068315885803e-06, 'epoch': 1.04}
 52%|█████▏    | 408/780 [5:01:55<4:35:47, 44.48s/it] 52%|█████▏    | 409/780 [5:02:38<4:32:41, 44.10s/it]                                                     {'loss': 0.3893, 'grad_norm': 0.2890625, 'learning_rate': 9.669366306826919e-06, 'epoch': 1.05}
 52%|█████▏    | 409/780 [5:02:38<4:32:41, 44.10s/it] 53%|█████▎    | 410/780 [5:03:23<4:32:51, 44.25s/it]                                                     {'loss': 0.3809, 'grad_norm': 0.2890625, 'learning_rate': 9.628055104413379e-06, 'epoch': 1.05}
 53%|█████▎    | 410/780 [5:03:23<4:32:51, 44.25s/it] 53%|█████▎    | 411/780 [5:04:03<4:24:37, 43.03s/it]                                                     {'loss': 0.3906, 'grad_norm': 0.306640625, 'learning_rate': 9.586750257511868e-06, 'epoch': 1.05}
 53%|█████▎    | 411/780 [5:04:03<4:24:37, 43.03s/it] 53%|█████▎    | 412/780 [5:04:48<4:26:59, 43.53s/it]                                                     {'loss': 0.3794, 'grad_norm': 0.3203125, 'learning_rate': 9.545452471908266e-06, 'epoch': 1.05}
 53%|█████▎    | 412/780 [5:04:48<4:26:59, 43.53s/it] 53%|█████▎    | 413/780 [5:05:30<4:23:37, 43.10s/it]                                                     {'loss': 0.4061, 'grad_norm': 0.37890625, 'learning_rate': 9.504162453267776e-06, 'epoch': 1.06}
 53%|█████▎    | 413/780 [5:05:30<4:23:37, 43.10s/it] 53%|█████▎    | 414/780 [5:06:13<4:22:47, 43.08s/it]                                                     {'loss': 0.3655, 'grad_norm': 0.296875, 'learning_rate': 9.462880907122904e-06, 'epoch': 1.06}
 53%|█████▎    | 414/780 [5:06:13<4:22:47, 43.08s/it] 53%|█████▎    | 415/780 [5:06:56<4:22:07, 43.09s/it]                                                     {'loss': 0.3623, 'grad_norm': 0.30859375, 'learning_rate': 9.421608538861361e-06, 'epoch': 1.06}
 53%|█████▎    | 415/780 [5:06:56<4:22:07, 43.09s/it] 53%|█████▎    | 416/780 [5:07:38<4:20:27, 42.93s/it]                                                     {'loss': 0.3558, 'grad_norm': 0.30078125, 'learning_rate': 9.380346053714055e-06, 'epoch': 1.06}
 53%|█████▎    | 416/780 [5:07:38<4:20:27, 42.93s/it] 53%|█████▎    | 417/780 [5:08:23<4:22:06, 43.32s/it]                                                     {'loss': 0.3783, 'grad_norm': 0.34375, 'learning_rate': 9.339094156743007e-06, 'epoch': 1.07}
 53%|█████▎    | 417/780 [5:08:23<4:22:06, 43.32s/it] 54%|█████▎    | 418/780 [5:09:07<4:24:11, 43.79s/it]                                                     {'loss': 0.3678, 'grad_norm': 0.294921875, 'learning_rate': 9.297853552829319e-06, 'epoch': 1.07}
 54%|█████▎    | 418/780 [5:09:08<4:24:11, 43.79s/it] 54%|█████▎    | 419/780 [5:09:51<4:22:52, 43.69s/it]                                                     {'loss': 0.3798, 'grad_norm': 0.275390625, 'learning_rate': 9.256624946661126e-06, 'epoch': 1.07}
 54%|█████▎    | 419/780 [5:09:51<4:22:52, 43.69s/it] 54%|█████▍    | 420/780 [5:10:34<4:20:45, 43.46s/it]                                                     {'loss': 0.3732, 'grad_norm': 0.30859375, 'learning_rate': 9.215409042721553e-06, 'epoch': 1.07}
 54%|█████▍    | 420/780 [5:10:34<4:20:45, 43.46s/it] 54%|█████▍    | 421/780 [5:11:19<4:23:47, 44.09s/it]                                                     {'loss': 0.3813, 'grad_norm': 0.302734375, 'learning_rate': 9.174206545276678e-06, 'epoch': 1.08}
 54%|█████▍    | 421/780 [5:11:19<4:23:47, 44.09s/it] 54%|█████▍    | 422/780 [5:12:03<4:22:23, 43.98s/it]                                                     {'loss': 0.3674, 'grad_norm': 0.287109375, 'learning_rate': 9.133018158363504e-06, 'epoch': 1.08}
 54%|█████▍    | 422/780 [5:12:03<4:22:23, 43.98s/it] 54%|█████▍    | 423/780 [5:12:49<4:25:03, 44.55s/it]                                                     {'loss': 0.394, 'grad_norm': 0.314453125, 'learning_rate': 9.091844585777919e-06, 'epoch': 1.08}
 54%|█████▍    | 423/780 [5:12:49<4:25:03, 44.55s/it] 54%|█████▍    | 424/780 [5:13:33<4:22:33, 44.25s/it]                                                     {'loss': 0.348, 'grad_norm': 0.376953125, 'learning_rate': 9.050686531062676e-06, 'epoch': 1.08}
 54%|█████▍    | 424/780 [5:13:33<4:22:33, 44.25s/it] 54%|█████▍    | 425/780 [5:14:14<4:16:05, 43.28s/it]                                                     {'loss': 0.3699, 'grad_norm': 0.30859375, 'learning_rate': 9.009544697495373e-06, 'epoch': 1.09}
 54%|█████▍    | 425/780 [5:14:14<4:16:05, 43.28s/it] 55%|█████▍    | 426/780 [5:14:57<4:15:58, 43.39s/it]                                                     {'loss': 0.3989, 'grad_norm': 0.3046875, 'learning_rate': 8.968419788076431e-06, 'epoch': 1.09}
 55%|█████▍    | 426/780 [5:14:57<4:15:58, 43.39s/it] 55%|█████▍    | 427/780 [5:15:43<4:18:44, 43.98s/it]                                                     {'loss': 0.3656, 'grad_norm': 0.2890625, 'learning_rate': 8.927312505517086e-06, 'epoch': 1.09}
 55%|█████▍    | 427/780 [5:15:43<4:18:44, 43.98s/it] 55%|█████▍    | 428/780 [5:16:27<4:19:01, 44.15s/it]                                                     {'loss': 0.3744, 'grad_norm': 0.283203125, 'learning_rate': 8.886223552227373e-06, 'epoch': 1.09}
 55%|█████▍    | 428/780 [5:16:27<4:19:01, 44.15s/it] 55%|█████▌    | 429/780 [5:17:11<4:18:38, 44.21s/it]                                                     {'loss': 0.3802, 'grad_norm': 0.40234375, 'learning_rate': 8.84515363030414e-06, 'epoch': 1.1}
 55%|█████▌    | 429/780 [5:17:12<4:18:38, 44.21s/it] 55%|█████▌    | 430/780 [5:17:57<4:20:36, 44.67s/it]                                                     {'loss': 0.3983, 'grad_norm': 0.294921875, 'learning_rate': 8.804103441519037e-06, 'epoch': 1.1}
 55%|█████▌    | 430/780 [5:17:57<4:20:36, 44.67s/it] 55%|█████▌    | 431/780 [5:18:42<4:20:31, 44.79s/it]                                                     {'loss': 0.3883, 'grad_norm': 0.3046875, 'learning_rate': 8.763073687306523e-06, 'epoch': 1.1}
 55%|█████▌    | 431/780 [5:18:42<4:20:31, 44.79s/it] 55%|█████▌    | 432/780 [5:19:26<4:17:09, 44.34s/it]                                                     {'loss': 0.3714, 'grad_norm': 0.326171875, 'learning_rate': 8.722065068751904e-06, 'epoch': 1.1}
 55%|█████▌    | 432/780 [5:19:26<4:17:09, 44.34s/it] 56%|█████▌    | 433/780 [5:20:08<4:13:21, 43.81s/it]                                                     {'loss': 0.3666, 'grad_norm': 0.392578125, 'learning_rate': 8.68107828657931e-06, 'epoch': 1.11}
 56%|█████▌    | 433/780 [5:20:08<4:13:21, 43.81s/it] 56%|█████▌    | 434/780 [5:20:52<4:12:31, 43.79s/it]                                                     {'loss': 0.3889, 'grad_norm': 0.33203125, 'learning_rate': 8.640114041139776e-06, 'epoch': 1.11}
 56%|█████▌    | 434/780 [5:20:52<4:12:31, 43.79s/it] 56%|█████▌    | 435/780 [5:21:36<4:11:50, 43.80s/it]                                                     {'loss': 0.3746, 'grad_norm': 0.30859375, 'learning_rate': 8.599173032399222e-06, 'epoch': 1.11}
 56%|█████▌    | 435/780 [5:21:36<4:11:50, 43.80s/it] 56%|█████▌    | 436/780 [5:22:21<4:13:24, 44.20s/it]                                                     {'loss': 0.3914, 'grad_norm': 0.310546875, 'learning_rate': 8.558255959926533e-06, 'epoch': 1.12}
 56%|█████▌    | 436/780 [5:22:21<4:13:24, 44.20s/it] 56%|█████▌    | 437/780 [5:23:05<4:13:04, 44.27s/it]                                                     {'loss': 0.3986, 'grad_norm': 0.310546875, 'learning_rate': 8.51736352288158e-06, 'epoch': 1.12}
 56%|█████▌    | 437/780 [5:23:05<4:13:04, 44.27s/it] 56%|█████▌    | 438/780 [5:23:50<4:12:49, 44.36s/it]                                                     {'loss': 0.399, 'grad_norm': 0.291015625, 'learning_rate': 8.476496420003291e-06, 'epoch': 1.12}
 56%|█████▌    | 438/780 [5:23:50<4:12:49, 44.36s/it] 56%|█████▋    | 439/780 [5:24:33<4:09:22, 43.88s/it]                                                     {'loss': 0.4105, 'grad_norm': 0.33984375, 'learning_rate': 8.43565534959769e-06, 'epoch': 1.12}
 56%|█████▋    | 439/780 [5:24:33<4:09:22, 43.88s/it] 56%|█████▋    | 440/780 [5:25:14<4:05:10, 43.27s/it]                                                     {'loss': 0.3708, 'grad_norm': 0.3125, 'learning_rate': 8.394841009525995e-06, 'epoch': 1.13}
 56%|█████▋    | 440/780 [5:25:14<4:05:10, 43.27s/it] 57%|█████▋    | 441/780 [5:25:58<4:05:16, 43.41s/it]                                                     {'loss': 0.3728, 'grad_norm': 0.314453125, 'learning_rate': 8.35405409719266e-06, 'epoch': 1.13}
 57%|█████▋    | 441/780 [5:25:58<4:05:16, 43.41s/it] 57%|█████▋    | 442/780 [5:26:39<4:00:38, 42.72s/it]                                                     {'loss': 0.3778, 'grad_norm': 0.35546875, 'learning_rate': 8.313295309533488e-06, 'epoch': 1.13}
 57%|█████▋    | 442/780 [5:26:39<4:00:38, 42.72s/it] 57%|█████▋    | 443/780 [5:27:20<3:57:18, 42.25s/it]                                                     {'loss': 0.355, 'grad_norm': 0.310546875, 'learning_rate': 8.2725653430037e-06, 'epoch': 1.13}
 57%|█████▋    | 443/780 [5:27:20<3:57:18, 42.25s/it] 57%|█████▋    | 444/780 [5:28:05<4:00:56, 43.03s/it]                                                     {'loss': 0.4085, 'grad_norm': 0.322265625, 'learning_rate': 8.23186489356604e-06, 'epoch': 1.14}
 57%|█████▋    | 444/780 [5:28:05<4:00:56, 43.03s/it] 57%|█████▋    | 445/780 [5:28:51<4:05:32, 43.98s/it]                                                     {'loss': 0.3774, 'grad_norm': 0.29296875, 'learning_rate': 8.191194656678905e-06, 'epoch': 1.14}
 57%|█████▋    | 445/780 [5:28:52<4:05:32, 43.98s/it] 57%|█████▋    | 446/780 [5:29:36<4:06:02, 44.20s/it]                                                     {'loss': 0.3849, 'grad_norm': 0.30859375, 'learning_rate': 8.150555327284417e-06, 'epoch': 1.14}
 57%|█████▋    | 446/780 [5:29:36<4:06:02, 44.20s/it] 57%|█████▋    | 447/780 [5:30:21<4:06:58, 44.50s/it]                                                     {'loss': 0.3936, 'grad_norm': 0.3125, 'learning_rate': 8.109947599796599e-06, 'epoch': 1.14}
 57%|█████▋    | 447/780 [5:30:21<4:06:58, 44.50s/it] 57%|█████▋    | 448/780 [5:31:04<4:03:49, 44.07s/it]                                                     {'loss': 0.4051, 'grad_norm': 0.32421875, 'learning_rate': 8.069372168089466e-06, 'epoch': 1.15}
 57%|█████▋    | 448/780 [5:31:04<4:03:49, 44.07s/it] 58%|█████▊    | 449/780 [5:31:49<4:04:20, 44.29s/it]                                                     {'loss': 0.4191, 'grad_norm': 0.296875, 'learning_rate': 8.0288297254852e-06, 'epoch': 1.15}
 58%|█████▊    | 449/780 [5:31:49<4:04:20, 44.29s/it] 58%|█████▊    | 450/780 [5:32:32<4:01:18, 43.87s/it]                                                     {'loss': 0.3805, 'grad_norm': 0.35546875, 'learning_rate': 7.988320964742276e-06, 'epoch': 1.15}
 58%|█████▊    | 450/780 [5:32:32<4:01:18, 43.87s/it] 58%|█████▊    | 451/780 [5:33:18<4:03:35, 44.42s/it]                                                     {'loss': 0.3949, 'grad_norm': 0.328125, 'learning_rate': 7.947846578043658e-06, 'epoch': 1.15}
 58%|█████▊    | 451/780 [5:33:18<4:03:35, 44.42s/it] 58%|█████▊    | 452/780 [5:34:03<4:03:38, 44.57s/it]                                                     {'loss': 0.3855, 'grad_norm': 0.326171875, 'learning_rate': 7.907407256984935e-06, 'epoch': 1.16}
 58%|█████▊    | 452/780 [5:34:03<4:03:38, 44.57s/it] 58%|█████▊    | 453/780 [5:34:46<4:00:38, 44.15s/it]                                                     {'loss': 0.3998, 'grad_norm': 0.30078125, 'learning_rate': 7.867003692562533e-06, 'epoch': 1.16}
 58%|█████▊    | 453/780 [5:34:46<4:00:38, 44.15s/it] 58%|█████▊    | 454/780 [5:35:27<3:54:36, 43.18s/it]                                                     {'loss': 0.3895, 'grad_norm': 0.328125, 'learning_rate': 7.826636575161884e-06, 'epoch': 1.16}
 58%|█████▊    | 454/780 [5:35:27<3:54:36, 43.18s/it] 58%|█████▊    | 455/780 [5:36:11<3:56:06, 43.59s/it]                                                     {'loss': 0.3763, 'grad_norm': 0.30078125, 'learning_rate': 7.786306594545658e-06, 'epoch': 1.16}
 58%|█████▊    | 455/780 [5:36:11<3:56:06, 43.59s/it] 58%|█████▊    | 456/780 [5:36:56<3:57:43, 44.02s/it]                                                     {'loss': 0.366, 'grad_norm': 0.306640625, 'learning_rate': 7.746014439841941e-06, 'epoch': 1.17}
 58%|█████▊    | 456/780 [5:36:56<3:57:43, 44.02s/it] 59%|█████▊    | 457/780 [5:37:43<4:01:20, 44.83s/it]                                                     {'loss': 0.4013, 'grad_norm': 0.322265625, 'learning_rate': 7.705760799532485e-06, 'epoch': 1.17}
 59%|█████▊    | 457/780 [5:37:43<4:01:20, 44.83s/it] 59%|█████▊    | 458/780 [5:38:28<4:00:44, 44.86s/it]                                                     {'loss': 0.3645, 'grad_norm': 0.306640625, 'learning_rate': 7.66554636144095e-06, 'epoch': 1.17}
 59%|█████▊    | 458/780 [5:38:28<4:00:44, 44.86s/it] 59%|█████▉    | 459/780 [5:39:12<3:59:08, 44.70s/it]                                                     {'loss': 0.3867, 'grad_norm': 0.33203125, 'learning_rate': 7.625371812721115e-06, 'epoch': 1.17}
 59%|█████▉    | 459/780 [5:39:12<3:59:08, 44.70s/it] 59%|█████▉    | 460/780 [5:39:57<3:58:46, 44.77s/it]                                                     {'loss': 0.3866, 'grad_norm': 0.30859375, 'learning_rate': 7.585237839845183e-06, 'epoch': 1.18}
 59%|█████▉    | 460/780 [5:39:57<3:58:46, 44.77s/it] 59%|█████▉    | 461/780 [5:40:42<3:57:06, 44.60s/it]                                                     {'loss': 0.3993, 'grad_norm': 0.29296875, 'learning_rate': 7.545145128592009e-06, 'epoch': 1.18}
 59%|█████▉    | 461/780 [5:40:42<3:57:06, 44.60s/it] 59%|█████▉    | 462/780 [5:41:26<3:56:46, 44.68s/it]                                                     {'loss': 0.3846, 'grad_norm': 0.330078125, 'learning_rate': 7.505094364035417e-06, 'epoch': 1.18}
 59%|█████▉    | 462/780 [5:41:26<3:56:46, 44.68s/it] 59%|█████▉    | 463/780 [5:42:14<4:00:02, 45.43s/it]                                                     {'loss': 0.3767, 'grad_norm': 0.328125, 'learning_rate': 7.46508623053246e-06, 'epoch': 1.18}
 59%|█████▉    | 463/780 [5:42:14<4:00:02, 45.43s/it] 59%|█████▉    | 464/780 [5:42:57<3:56:36, 44.93s/it]                                                     {'loss': 0.3801, 'grad_norm': 0.302734375, 'learning_rate': 7.425121411711762e-06, 'epoch': 1.19}
 59%|█████▉    | 464/780 [5:42:57<3:56:36, 44.93s/it] 60%|█████▉    | 465/780 [5:43:37<3:48:00, 43.43s/it]                                                     {'loss': 0.4057, 'grad_norm': 0.314453125, 'learning_rate': 7.385200590461803e-06, 'epoch': 1.19}
 60%|█████▉    | 465/780 [5:43:37<3:48:00, 43.43s/it] 60%|█████▉    | 466/780 [5:44:22<3:49:35, 43.87s/it]                                                     {'loss': 0.3901, 'grad_norm': 0.3046875, 'learning_rate': 7.34532444891928e-06, 'epoch': 1.19}
 60%|█████▉    | 466/780 [5:44:22<3:49:35, 43.87s/it] 60%|█████▉    | 467/780 [5:45:07<3:50:59, 44.28s/it]                                                     {'loss': 0.3645, 'grad_norm': 0.30859375, 'learning_rate': 7.305493668457421e-06, 'epoch': 1.19}
 60%|█████▉    | 467/780 [5:45:07<3:50:59, 44.28s/it] 60%|██████    | 468/780 [5:45:52<3:50:09, 44.26s/it]                                                     {'loss': 0.3931, 'grad_norm': 0.30078125, 'learning_rate': 7.2657089296743766e-06, 'epoch': 1.2}
 60%|██████    | 468/780 [5:45:52<3:50:09, 44.26s/it] 60%|██████    | 469/780 [5:46:33<3:44:30, 43.31s/it]                                                     {'loss': 0.4084, 'grad_norm': 0.3203125, 'learning_rate': 7.225970912381557e-06, 'epoch': 1.2}
 60%|██████    | 469/780 [5:46:33<3:44:30, 43.31s/it] 60%|██████    | 470/780 [5:47:18<3:47:19, 44.00s/it]                                                     {'loss': 0.4012, 'grad_norm': 0.310546875, 'learning_rate': 7.1862802955920365e-06, 'epoch': 1.2}
 60%|██████    | 470/780 [5:47:18<3:47:19, 44.00s/it] 60%|██████    | 471/780 [5:48:03<3:48:21, 44.34s/it]                                                     {'loss': 0.3928, 'grad_norm': 0.318359375, 'learning_rate': 7.14663775750895e-06, 'epoch': 1.2}
 60%|██████    | 471/780 [5:48:04<3:48:21, 44.34s/it] 61%|██████    | 472/780 [5:48:49<3:49:23, 44.69s/it]                                                     {'loss': 0.376, 'grad_norm': 0.45703125, 'learning_rate': 7.1070439755138905e-06, 'epoch': 1.21}
 61%|██████    | 472/780 [5:48:49<3:49:23, 44.69s/it] 61%|██████    | 473/780 [5:49:30<3:43:08, 43.61s/it]                                                     {'loss': 0.3966, 'grad_norm': 0.287109375, 'learning_rate': 7.067499626155354e-06, 'epoch': 1.21}
 61%|██████    | 473/780 [5:49:30<3:43:08, 43.61s/it] 61%|██████    | 474/780 [5:50:16<3:45:37, 44.24s/it]                                                     {'loss': 0.3818, 'grad_norm': 0.345703125, 'learning_rate': 7.028005385137162e-06, 'epoch': 1.21}
 61%|██████    | 474/780 [5:50:16<3:45:37, 44.24s/it] 61%|██████    | 475/780 [5:51:02<3:47:47, 44.81s/it]                                                     {'loss': 0.3564, 'grad_norm': 0.318359375, 'learning_rate': 6.988561927306927e-06, 'epoch': 1.22}
 61%|██████    | 475/780 [5:51:02<3:47:47, 44.81s/it] 61%|██████    | 476/780 [5:51:50<3:52:11, 45.83s/it]                                                     {'loss': 0.3627, 'grad_norm': 0.291015625, 'learning_rate': 6.949169926644513e-06, 'epoch': 1.22}
 61%|██████    | 476/780 [5:51:50<3:52:11, 45.83s/it] 61%|██████    | 477/780 [5:52:33<3:46:55, 44.93s/it]                                                     {'loss': 0.3773, 'grad_norm': 0.314453125, 'learning_rate': 6.909830056250527e-06, 'epoch': 1.22}
 61%|██████    | 477/780 [5:52:33<3:46:55, 44.93s/it] 61%|██████▏   | 478/780 [5:53:17<3:45:31, 44.81s/it]                                                     {'loss': 0.3794, 'grad_norm': 0.29296875, 'learning_rate': 6.8705429883348095e-06, 'epoch': 1.22}
 61%|██████▏   | 478/780 [5:53:18<3:45:31, 44.81s/it] 61%|██████▏   | 479/780 [5:54:01<3:42:53, 44.43s/it]                                                     {'loss': 0.3634, 'grad_norm': 0.322265625, 'learning_rate': 6.831309394204957e-06, 'epoch': 1.23}
 61%|██████▏   | 479/780 [5:54:01<3:42:53, 44.43s/it] 62%|██████▏   | 480/780 [5:54:47<3:43:52, 44.78s/it]                                                     {'loss': 0.3617, 'grad_norm': 0.302734375, 'learning_rate': 6.7921299442548425e-06, 'epoch': 1.23}
 62%|██████▏   | 480/780 [5:54:47<3:43:52, 44.78s/it] 62%|██████▏   | 481/780 [5:55:29<3:39:46, 44.10s/it]                                                     {'loss': 0.3881, 'grad_norm': 0.3046875, 'learning_rate': 6.7530053079531664e-06, 'epoch': 1.23}
 62%|██████▏   | 481/780 [5:55:29<3:39:46, 44.10s/it] 62%|██████▏   | 482/780 [5:56:15<3:41:21, 44.57s/it]                                                     {'loss': 0.3739, 'grad_norm': 0.287109375, 'learning_rate': 6.713936153832012e-06, 'epoch': 1.23}
 62%|██████▏   | 482/780 [5:56:15<3:41:21, 44.57s/it] 62%|██████▏   | 483/780 [5:56:55<3:34:15, 43.28s/it]                                                     {'loss': 0.372, 'grad_norm': 0.310546875, 'learning_rate': 6.674923149475433e-06, 'epoch': 1.24}
 62%|██████▏   | 483/780 [5:56:55<3:34:15, 43.28s/it] 62%|██████▏   | 484/780 [5:57:41<3:37:34, 44.10s/it]                                                     {'loss': 0.3645, 'grad_norm': 0.314453125, 'learning_rate': 6.635966961508031e-06, 'epoch': 1.24}
 62%|██████▏   | 484/780 [5:57:41<3:37:34, 44.10s/it] 62%|██████▏   | 485/780 [5:58:22<3:32:36, 43.24s/it]                                                     {'loss': 0.3965, 'grad_norm': 0.328125, 'learning_rate': 6.59706825558357e-06, 'epoch': 1.24}
 62%|██████▏   | 485/780 [5:58:22<3:32:36, 43.24s/it] 62%|██████▏   | 486/780 [5:59:07<3:34:09, 43.70s/it]                                                     {'loss': 0.3863, 'grad_norm': 0.296875, 'learning_rate': 6.558227696373617e-06, 'epoch': 1.24}
 62%|██████▏   | 486/780 [5:59:07<3:34:09, 43.70s/it] 62%|██████▏   | 487/780 [5:59:50<3:32:24, 43.50s/it]                                                     {'loss': 0.3938, 'grad_norm': 0.3125, 'learning_rate': 6.519445947556156e-06, 'epoch': 1.25}
 62%|██████▏   | 487/780 [5:59:50<3:32:24, 43.50s/it] 63%|██████▎   | 488/780 [6:00:33<3:31:21, 43.43s/it]                                                     {'loss': 0.4065, 'grad_norm': 0.29296875, 'learning_rate': 6.480723671804281e-06, 'epoch': 1.25}
 63%|██████▎   | 488/780 [6:00:33<3:31:21, 43.43s/it] 63%|██████▎   | 489/780 [6:01:19<3:34:26, 44.22s/it]                                                     {'loss': 0.3571, 'grad_norm': 0.310546875, 'learning_rate': 6.442061530774835e-06, 'epoch': 1.25}
 63%|██████▎   | 489/780 [6:01:20<3:34:26, 44.22s/it] 63%|██████▎   | 490/780 [6:02:06<3:37:23, 44.98s/it]                                                     {'loss': 0.3421, 'grad_norm': 0.28515625, 'learning_rate': 6.4034601850971475e-06, 'epoch': 1.25}
 63%|██████▎   | 490/780 [6:02:06<3:37:23, 44.98s/it] 63%|██████▎   | 491/780 [6:02:50<3:35:21, 44.71s/it]                                                     {'loss': 0.3597, 'grad_norm': 0.298828125, 'learning_rate': 6.364920294361701e-06, 'epoch': 1.26}
 63%|██████▎   | 491/780 [6:02:50<3:35:21, 44.71s/it] 63%|██████▎   | 492/780 [6:03:37<3:38:02, 45.43s/it]                                                     {'loss': 0.3839, 'grad_norm': 0.3125, 'learning_rate': 6.326442517108901e-06, 'epoch': 1.26}
 63%|██████▎   | 492/780 [6:03:37<3:38:02, 45.43s/it] 63%|██████▎   | 493/780 [6:04:23<3:37:22, 45.44s/it]                                                     {'loss': 0.3912, 'grad_norm': 0.29296875, 'learning_rate': 6.2880275108177915e-06, 'epoch': 1.26}
 63%|██████▎   | 493/780 [6:04:23<3:37:22, 45.44s/it] 63%|██████▎   | 494/780 [6:05:08<3:35:39, 45.24s/it]                                                     {'loss': 0.3703, 'grad_norm': 0.306640625, 'learning_rate': 6.249675931894845e-06, 'epoch': 1.26}
 63%|██████▎   | 494/780 [6:05:08<3:35:39, 45.24s/it] 63%|██████▎   | 495/780 [6:05:53<3:35:13, 45.31s/it]                                                     {'loss': 0.3625, 'grad_norm': 0.30859375, 'learning_rate': 6.211388435662722e-06, 'epoch': 1.27}
 63%|██████▎   | 495/780 [6:05:53<3:35:13, 45.31s/it] 64%|██████▎   | 496/780 [6:06:40<3:36:17, 45.69s/it]                                                     {'loss': 0.3983, 'grad_norm': 0.3125, 'learning_rate': 6.173165676349103e-06, 'epoch': 1.27}
 64%|██████▎   | 496/780 [6:06:40<3:36:17, 45.69s/it] 64%|██████▎   | 497/780 [6:07:21<3:29:50, 44.49s/it]                                                     {'loss': 0.3661, 'grad_norm': 0.3046875, 'learning_rate': 6.13500830707548e-06, 'epoch': 1.27}
 64%|██████▎   | 497/780 [6:07:21<3:29:50, 44.49s/it] 64%|██████▍   | 498/780 [6:08:06<3:28:57, 44.46s/it]                                                     {'loss': 0.3623, 'grad_norm': 0.302734375, 'learning_rate': 6.0969169798460105e-06, 'epoch': 1.27}
 64%|██████▍   | 498/780 [6:08:06<3:28:57, 44.46s/it] 64%|██████▍   | 499/780 [6:08:51<3:29:04, 44.64s/it]                                                     {'loss': 0.3649, 'grad_norm': 0.291015625, 'learning_rate': 6.058892345536387e-06, 'epoch': 1.28}
 64%|██████▍   | 499/780 [6:08:51<3:29:04, 44.64s/it] 64%|██████▍   | 500/780 [6:09:38<3:32:12, 45.47s/it]                                                     {'loss': 0.3494, 'grad_norm': 0.283203125, 'learning_rate': 6.020935053882688e-06, 'epoch': 1.28}
 64%|██████▍   | 500/780 [6:09:38<3:32:12, 45.47s/it] 64%|██████▍   | 501/780 [6:10:22<3:29:23, 45.03s/it]                                                     {'loss': 0.3797, 'grad_norm': 0.35546875, 'learning_rate': 5.983045753470308e-06, 'epoch': 1.28}
 64%|██████▍   | 501/780 [6:10:22<3:29:23, 45.03s/it] 64%|██████▍   | 502/780 [6:11:07<3:28:30, 45.00s/it]                                                     {'loss': 0.3904, 'grad_norm': 0.306640625, 'learning_rate': 5.9452250917228434e-06, 'epoch': 1.28}
 64%|██████▍   | 502/780 [6:11:07<3:28:30, 45.00s/it] 64%|██████▍   | 503/780 [6:11:55<3:30:57, 45.70s/it]                                                     {'loss': 0.3892, 'grad_norm': 0.29296875, 'learning_rate': 5.907473714891061e-06, 'epoch': 1.29}
 64%|██████▍   | 503/780 [6:11:55<3:30:57, 45.70s/it] 65%|██████▍   | 504/780 [6:12:40<3:30:33, 45.77s/it]                                                     {'loss': 0.38, 'grad_norm': 0.30859375, 'learning_rate': 5.869792268041824e-06, 'epoch': 1.29}
 65%|██████▍   | 504/780 [6:12:41<3:30:33, 45.77s/it] 65%|██████▍   | 505/780 [6:13:23<3:25:30, 44.84s/it]                                                     {'loss': 0.3535, 'grad_norm': 0.3125, 'learning_rate': 5.832181395047099e-06, 'epoch': 1.29}
 65%|██████▍   | 505/780 [6:13:23<3:25:30, 44.84s/it] 65%|██████▍   | 506/780 [6:14:08<3:25:03, 44.90s/it]                                                     {'loss': 0.3712, 'grad_norm': 0.30859375, 'learning_rate': 5.794641738572925e-06, 'epoch': 1.29}
 65%|██████▍   | 506/780 [6:14:08<3:25:03, 44.90s/it] 65%|██████▌   | 507/780 [6:14:50<3:19:55, 43.94s/it]                                                     {'loss': 0.3615, 'grad_norm': 0.306640625, 'learning_rate': 5.7571739400684644e-06, 'epoch': 1.3}
 65%|██████▌   | 507/780 [6:14:50<3:19:55, 43.94s/it] 65%|██████▌   | 508/780 [6:15:35<3:21:16, 44.40s/it]                                                     {'loss': 0.4058, 'grad_norm': 0.31640625, 'learning_rate': 5.7197786397550096e-06, 'epoch': 1.3}
 65%|██████▌   | 508/780 [6:15:35<3:21:16, 44.40s/it] 65%|██████▌   | 509/780 [6:16:19<3:19:57, 44.27s/it]                                                     {'loss': 0.408, 'grad_norm': 0.326171875, 'learning_rate': 5.6824564766150724e-06, 'epoch': 1.3}
 65%|██████▌   | 509/780 [6:16:19<3:19:57, 44.27s/it] 65%|██████▌   | 510/780 [6:17:05<3:20:40, 44.60s/it]                                                     {'loss': 0.3889, 'grad_norm': 0.30859375, 'learning_rate': 5.645208088381442e-06, 'epoch': 1.3}
 65%|██████▌   | 510/780 [6:17:05<3:20:40, 44.60s/it] 66%|██████▌   | 511/780 [6:17:48<3:17:42, 44.10s/it]                                                     {'loss': 0.3934, 'grad_norm': 0.33203125, 'learning_rate': 5.608034111526298e-06, 'epoch': 1.31}
 66%|██████▌   | 511/780 [6:17:48<3:17:42, 44.10s/it] 66%|██████▌   | 512/780 [6:18:29<3:13:44, 43.37s/it]                                                     {'loss': 0.3796, 'grad_norm': 0.3125, 'learning_rate': 5.570935181250346e-06, 'epoch': 1.31}
 66%|██████▌   | 512/780 [6:18:29<3:13:44, 43.37s/it] 66%|██████▌   | 513/780 [6:19:13<3:13:36, 43.51s/it]                                                     {'loss': 0.3708, 'grad_norm': 0.330078125, 'learning_rate': 5.533911931471936e-06, 'epoch': 1.31}
 66%|██████▌   | 513/780 [6:19:13<3:13:36, 43.51s/it] 66%|██████▌   | 514/780 [6:20:01<3:18:41, 44.82s/it]                                                     {'loss': 0.363, 'grad_norm': 0.3125, 'learning_rate': 5.496964994816265e-06, 'epoch': 1.31}
 66%|██████▌   | 514/780 [6:20:01<3:18:41, 44.82s/it] 66%|██████▌   | 515/780 [6:20:45<3:16:58, 44.60s/it]                                                     {'loss': 0.3779, 'grad_norm': 0.314453125, 'learning_rate': 5.460095002604533e-06, 'epoch': 1.32}
 66%|██████▌   | 515/780 [6:20:45<3:16:58, 44.60s/it] 66%|██████▌   | 516/780 [6:21:27<3:13:16, 43.93s/it]                                                     {'loss': 0.3731, 'grad_norm': 0.302734375, 'learning_rate': 5.423302584843186e-06, 'epoch': 1.32}
 66%|██████▌   | 516/780 [6:21:27<3:13:16, 43.93s/it] 66%|██████▋   | 517/780 [6:22:10<3:11:18, 43.64s/it]                                                     {'loss': 0.3829, 'grad_norm': 0.328125, 'learning_rate': 5.386588370213124e-06, 'epoch': 1.32}
 66%|██████▋   | 517/780 [6:22:10<3:11:18, 43.64s/it] 66%|██████▋   | 518/780 [6:22:57<3:13:55, 44.41s/it]                                                     {'loss': 0.353, 'grad_norm': 0.287109375, 'learning_rate': 5.349952986058981e-06, 'epoch': 1.33}
 66%|██████▋   | 518/780 [6:22:57<3:13:55, 44.41s/it] 67%|██████▋   | 519/780 [6:23:43<3:15:07, 44.86s/it]                                                     {'loss': 0.4008, 'grad_norm': 0.306640625, 'learning_rate': 5.3133970583783865e-06, 'epoch': 1.33}
 67%|██████▋   | 519/780 [6:23:43<3:15:07, 44.86s/it] 67%|██████▋   | 520/780 [6:24:27<3:13:23, 44.63s/it]                                                     {'loss': 0.3653, 'grad_norm': 0.306640625, 'learning_rate': 5.276921211811293e-06, 'epoch': 1.33}
 67%|██████▋   | 520/780 [6:24:27<3:13:23, 44.63s/it] 67%|██████▋   | 521/780 [6:25:13<3:15:26, 45.28s/it]                                                     {'loss': 0.4061, 'grad_norm': 0.3203125, 'learning_rate': 5.240526069629265e-06, 'epoch': 1.33}
 67%|██████▋   | 521/780 [6:25:13<3:15:26, 45.28s/it] 67%|██████▋   | 522/780 [6:25:57<3:12:50, 44.85s/it]                                                     {'loss': 0.3839, 'grad_norm': 0.361328125, 'learning_rate': 5.204212253724876e-06, 'epoch': 1.34}
 67%|██████▋   | 522/780 [6:25:57<3:12:50, 44.85s/it] 67%|██████▋   | 523/780 [6:26:43<3:12:48, 45.01s/it]                                                     {'loss': 0.3811, 'grad_norm': 0.328125, 'learning_rate': 5.167980384601041e-06, 'epoch': 1.34}
 67%|██████▋   | 523/780 [6:26:43<3:12:48, 45.01s/it] 67%|██████▋   | 524/780 [6:27:27<3:11:26, 44.87s/it]                                                     {'loss': 0.4146, 'grad_norm': 0.3203125, 'learning_rate': 5.131831081360439e-06, 'epoch': 1.34}
 67%|██████▋   | 524/780 [6:27:27<3:11:26, 44.87s/it] 67%|██████▋   | 525/780 [6:28:09<3:07:07, 44.03s/it]                                                     {'loss': 0.3773, 'grad_norm': 0.4375, 'learning_rate': 5.095764961694923e-06, 'epoch': 1.34}
 67%|██████▋   | 525/780 [6:28:09<3:07:07, 44.03s/it] 67%|██████▋   | 526/780 [6:28:54<3:07:39, 44.33s/it]                                                     {'loss': 0.3859, 'grad_norm': 0.3125, 'learning_rate': 5.059782641874962e-06, 'epoch': 1.35}
 67%|██████▋   | 526/780 [6:28:54<3:07:39, 44.33s/it] 68%|██████▊   | 527/780 [6:29:39<3:07:41, 44.51s/it]                                                     {'loss': 0.3744, 'grad_norm': 0.30859375, 'learning_rate': 5.023884736739132e-06, 'epoch': 1.35}
 68%|██████▊   | 527/780 [6:29:39<3:07:41, 44.51s/it] 68%|██████▊   | 528/780 [6:30:22<3:04:19, 43.89s/it]                                                     {'loss': 0.3884, 'grad_norm': 0.388671875, 'learning_rate': 4.988071859683579e-06, 'epoch': 1.35}
 68%|██████▊   | 528/780 [6:30:22<3:04:19, 43.89s/it] 68%|██████▊   | 529/780 [6:31:06<3:04:43, 44.16s/it]                                                     {'loss': 0.3698, 'grad_norm': 0.27734375, 'learning_rate': 4.952344622651566e-06, 'epoch': 1.35}
 68%|██████▊   | 529/780 [6:31:06<3:04:43, 44.16s/it] 68%|██████▊   | 530/780 [6:31:50<3:02:42, 43.85s/it]                                                     {'loss': 0.3914, 'grad_norm': 0.3125, 'learning_rate': 4.916703636122995e-06, 'epoch': 1.36}
 68%|██████▊   | 530/780 [6:31:50<3:02:42, 43.85s/it] 68%|██████▊   | 531/780 [6:32:34<3:03:19, 44.17s/it]                                                     {'loss': 0.3904, 'grad_norm': 0.345703125, 'learning_rate': 4.881149509103993e-06, 'epoch': 1.36}
 68%|██████▊   | 531/780 [6:32:35<3:03:19, 44.17s/it] 68%|██████▊   | 532/780 [6:33:19<3:02:50, 44.23s/it]                                                     {'loss': 0.3744, 'grad_norm': 0.328125, 'learning_rate': 4.845682849116489e-06, 'epoch': 1.36}
 68%|██████▊   | 532/780 [6:33:19<3:02:50, 44.23s/it] 68%|██████▊   | 533/780 [6:34:02<3:01:02, 43.98s/it]                                                     {'loss': 0.3757, 'grad_norm': 0.30859375, 'learning_rate': 4.8103042621878515e-06, 'epoch': 1.36}
 68%|██████▊   | 533/780 [6:34:02<3:01:02, 43.98s/it] 68%|██████▊   | 534/780 [6:34:46<3:00:00, 43.90s/it]                                                     {'loss': 0.4233, 'grad_norm': 0.337890625, 'learning_rate': 4.775014352840512e-06, 'epoch': 1.37}
 68%|██████▊   | 534/780 [6:34:46<3:00:00, 43.90s/it] 69%|██████▊   | 535/780 [6:35:25<2:52:53, 42.34s/it]                                                     {'loss': 0.4046, 'grad_norm': 0.333984375, 'learning_rate': 4.739813724081661e-06, 'epoch': 1.37}
 69%|██████▊   | 535/780 [6:35:25<2:52:53, 42.34s/it] 69%|██████▊   | 536/780 [6:36:13<2:59:43, 44.19s/it]                                                     {'loss': 0.4028, 'grad_norm': 0.31640625, 'learning_rate': 4.704702977392914e-06, 'epoch': 1.37}
 69%|██████▊   | 536/780 [6:36:13<2:59:43, 44.19s/it] 69%|██████▉   | 537/780 [6:36:58<2:59:27, 44.31s/it]                                                     {'loss': 0.393, 'grad_norm': 0.29296875, 'learning_rate': 4.669682712720065e-06, 'epoch': 1.37}
 69%|██████▉   | 537/780 [6:36:58<2:59:27, 44.31s/it] 69%|██████▉   | 538/780 [6:37:42<2:58:13, 44.19s/it]                                                     {'loss': 0.3901, 'grad_norm': 0.318359375, 'learning_rate': 4.634753528462806e-06, 'epoch': 1.38}
 69%|██████▉   | 538/780 [6:37:42<2:58:13, 44.19s/it] 69%|██████▉   | 539/780 [6:38:26<2:58:13, 44.37s/it]                                                     {'loss': 0.4075, 'grad_norm': 0.306640625, 'learning_rate': 4.599916021464531e-06, 'epoch': 1.38}
 69%|██████▉   | 539/780 [6:38:27<2:58:13, 44.37s/it] 69%|██████▉   | 540/780 [6:39:11<2:57:20, 44.33s/it]                                                     {'loss': 0.3845, 'grad_norm': 0.31640625, 'learning_rate': 4.565170787002108e-06, 'epoch': 1.38}
 69%|██████▉   | 540/780 [6:39:11<2:57:20, 44.33s/it] 69%|██████▉   | 541/780 [6:39:54<2:55:06, 43.96s/it]                                                     {'loss': 0.3842, 'grad_norm': 0.310546875, 'learning_rate': 4.530518418775734e-06, 'epoch': 1.38}
 69%|██████▉   | 541/780 [6:39:54<2:55:06, 43.96s/it] 69%|██████▉   | 542/780 [6:40:37<2:53:07, 43.65s/it]                                                     {'loss': 0.3465, 'grad_norm': 0.302734375, 'learning_rate': 4.495959508898766e-06, 'epoch': 1.39}
 69%|██████▉   | 542/780 [6:40:37<2:53:07, 43.65s/it] 70%|██████▉   | 543/780 [6:41:19<2:50:39, 43.20s/it]                                                     {'loss': 0.398, 'grad_norm': 0.306640625, 'learning_rate': 4.4614946478876305e-06, 'epoch': 1.39}
 70%|██████▉   | 543/780 [6:41:19<2:50:39, 43.20s/it] 70%|██████▉   | 544/780 [6:42:03<2:51:28, 43.60s/it]                                                     {'loss': 0.3897, 'grad_norm': 0.302734375, 'learning_rate': 4.427124424651703e-06, 'epoch': 1.39}
 70%|██████▉   | 544/780 [6:42:03<2:51:28, 43.60s/it] 70%|██████▉   | 545/780 [6:42:48<2:52:09, 43.96s/it]                                                     {'loss': 0.3807, 'grad_norm': 0.341796875, 'learning_rate': 4.392849426483275e-06, 'epoch': 1.39}
 70%|██████▉   | 545/780 [6:42:48<2:52:09, 43.96s/it] 70%|███████   | 546/780 [6:43:34<2:53:50, 44.58s/it]                                                     {'loss': 0.375, 'grad_norm': 0.9609375, 'learning_rate': 4.35867023904749e-06, 'epoch': 1.4}
 70%|███████   | 546/780 [6:43:34<2:53:50, 44.58s/it] 70%|███████   | 547/780 [6:44:15<2:49:11, 43.57s/it]                                                     {'loss': 0.3935, 'grad_norm': 0.328125, 'learning_rate': 4.324587446372365e-06, 'epoch': 1.4}
 70%|███████   | 547/780 [6:44:16<2:49:11, 43.57s/it] 70%|███████   | 548/780 [6:45:01<2:50:16, 44.04s/it]                                                     {'loss': 0.3727, 'grad_norm': 0.30078125, 'learning_rate': 4.290601630838781e-06, 'epoch': 1.4}
 70%|███████   | 548/780 [6:45:01<2:50:16, 44.04s/it] 70%|███████   | 549/780 [6:45:45<2:50:20, 44.24s/it]                                                     {'loss': 0.3624, 'grad_norm': 0.298828125, 'learning_rate': 4.256713373170565e-06, 'epoch': 1.4}
 70%|███████   | 549/780 [6:45:45<2:50:20, 44.24s/it] 71%|███████   | 550/780 [6:46:31<2:50:43, 44.54s/it]                                                     {'loss': 0.3753, 'grad_norm': 0.298828125, 'learning_rate': 4.22292325242453e-06, 'epoch': 1.41}
 71%|███████   | 550/780 [6:46:31<2:50:43, 44.54s/it] 71%|███████   | 551/780 [6:47:16<2:50:57, 44.79s/it]                                                     {'loss': 0.3917, 'grad_norm': 0.310546875, 'learning_rate': 4.189231845980618e-06, 'epoch': 1.41}
 71%|███████   | 551/780 [6:47:16<2:50:57, 44.79s/it] 71%|███████   | 552/780 [6:48:00<2:49:33, 44.62s/it]                                                     {'loss': 0.3759, 'grad_norm': 0.29296875, 'learning_rate': 4.155639729532e-06, 'epoch': 1.41}
 71%|███████   | 552/780 [6:48:00<2:49:33, 44.62s/it] 71%|███████   | 553/780 [6:48:46<2:50:44, 45.13s/it]                                                     {'loss': 0.3415, 'grad_norm': 0.349609375, 'learning_rate': 4.12214747707527e-06, 'epoch': 1.41}
 71%|███████   | 553/780 [6:48:47<2:50:44, 45.13s/it] 71%|███████   | 554/780 [6:49:31<2:49:37, 45.03s/it]                                                     {'loss': 0.381, 'grad_norm': 0.3046875, 'learning_rate': 4.0887556609006055e-06, 'epoch': 1.42}
 71%|███████   | 554/780 [6:49:31<2:49:37, 45.03s/it] 71%|███████   | 555/780 [6:50:17<2:49:21, 45.16s/it]                                                     {'loss': 0.3851, 'grad_norm': 0.322265625, 'learning_rate': 4.055464851582022e-06, 'epoch': 1.42}
 71%|███████   | 555/780 [6:50:17<2:49:21, 45.16s/it] 71%|███████▏  | 556/780 [6:51:02<2:48:13, 45.06s/it]                                                     {'loss': 0.3732, 'grad_norm': 0.33203125, 'learning_rate': 4.0222756179675915e-06, 'epoch': 1.42}
 71%|███████▏  | 556/780 [6:51:02<2:48:13, 45.06s/it] 71%|███████▏  | 557/780 [6:51:44<2:44:10, 44.17s/it]                                                     {'loss': 0.3887, 'grad_norm': 0.30859375, 'learning_rate': 3.989188527169749e-06, 'epoch': 1.42}
 71%|███████▏  | 557/780 [6:51:44<2:44:10, 44.17s/it] 72%|███████▏  | 558/780 [6:52:27<2:42:14, 43.85s/it]                                                     {'loss': 0.378, 'grad_norm': 0.328125, 'learning_rate': 3.956204144555582e-06, 'epoch': 1.43}
 72%|███████▏  | 558/780 [6:52:27<2:42:14, 43.85s/it] 72%|███████▏  | 559/780 [6:53:10<2:40:27, 43.56s/it]                                                     {'loss': 0.388, 'grad_norm': 0.31640625, 'learning_rate': 3.923323033737188e-06, 'epoch': 1.43}
 72%|███████▏  | 559/780 [6:53:10<2:40:27, 43.56s/it] 72%|███████▏  | 560/780 [6:53:52<2:37:59, 43.09s/it]                                                     {'loss': 0.3799, 'grad_norm': 0.298828125, 'learning_rate': 3.890545756562022e-06, 'epoch': 1.43}
 72%|███████▏  | 560/780 [6:53:52<2:37:59, 43.09s/it] 72%|███████▏  | 561/780 [6:54:40<2:42:34, 44.54s/it]                                                     {'loss': 0.3796, 'grad_norm': 0.322265625, 'learning_rate': 3.857872873103322e-06, 'epoch': 1.44}
 72%|███████▏  | 561/780 [6:54:40<2:42:34, 44.54s/it] 72%|███████▏  | 562/780 [6:55:24<2:41:18, 44.40s/it]                                                     {'loss': 0.3721, 'grad_norm': 0.30078125, 'learning_rate': 3.825304941650512e-06, 'epoch': 1.44}
 72%|███████▏  | 562/780 [6:55:24<2:41:18, 44.40s/it] 72%|███████▏  | 563/780 [6:56:09<2:41:58, 44.78s/it]                                                     {'loss': 0.3677, 'grad_norm': 0.30078125, 'learning_rate': 3.792842518699689e-06, 'epoch': 1.44}
 72%|███████▏  | 563/780 [6:56:09<2:41:58, 44.78s/it] 72%|███████▏  | 564/780 [6:56:53<2:40:31, 44.59s/it]                                                     {'loss': 0.3805, 'grad_norm': 0.314453125, 'learning_rate': 3.7604861589440913e-06, 'epoch': 1.44}
 72%|███████▏  | 564/780 [6:56:53<2:40:31, 44.59s/it] 72%|███████▏  | 565/780 [6:57:39<2:40:30, 44.79s/it]                                                     {'loss': 0.3624, 'grad_norm': 0.33203125, 'learning_rate': 3.72823641526463e-06, 'epoch': 1.45}
 72%|███████▏  | 565/780 [6:57:39<2:40:30, 44.79s/it] 73%|███████▎  | 566/780 [6:58:22<2:38:31, 44.45s/it]                                                     {'loss': 0.3601, 'grad_norm': 0.31640625, 'learning_rate': 3.69609383872045e-06, 'epoch': 1.45}
 73%|███████▎  | 566/780 [6:58:22<2:38:31, 44.45s/it] 73%|███████▎  | 567/780 [6:59:08<2:39:19, 44.88s/it]                                                     {'loss': 0.3289, 'grad_norm': 0.310546875, 'learning_rate': 3.6640589785394955e-06, 'epoch': 1.45}
 73%|███████▎  | 567/780 [6:59:08<2:39:19, 44.88s/it] 73%|███████▎  | 568/780 [6:59:51<2:36:41, 44.35s/it]                                                     {'loss': 0.3875, 'grad_norm': 0.306640625, 'learning_rate': 3.6321323821091434e-06, 'epoch': 1.45}
 73%|███████▎  | 568/780 [6:59:51<2:36:41, 44.35s/it] 73%|███████▎  | 569/780 [7:00:36<2:36:23, 44.47s/it]                                                     {'loss': 0.3692, 'grad_norm': 0.34765625, 'learning_rate': 3.6003145949668338e-06, 'epoch': 1.46}
 73%|███████▎  | 569/780 [7:00:36<2:36:23, 44.47s/it] 73%|███████▎  | 570/780 [7:01:22<2:36:41, 44.77s/it]                                                     {'loss': 0.3539, 'grad_norm': 0.31640625, 'learning_rate': 3.5686061607907674e-06, 'epoch': 1.46}
 73%|███████▎  | 570/780 [7:01:22<2:36:41, 44.77s/it] 73%|███████▎  | 571/780 [7:02:03<2:32:29, 43.78s/it]                                                     {'loss': 0.3557, 'grad_norm': 0.298828125, 'learning_rate': 3.5370076213905904e-06, 'epoch': 1.46}
 73%|███████▎  | 571/780 [7:02:03<2:32:29, 43.78s/it] 73%|███████▎  | 572/780 [7:02:47<2:31:45, 43.77s/it]                                                     {'loss': 0.3707, 'grad_norm': 0.32421875, 'learning_rate': 3.505519516698165e-06, 'epoch': 1.46}
 73%|███████▎  | 572/780 [7:02:47<2:31:45, 43.77s/it] 73%|███████▎  | 573/780 [7:03:29<2:29:10, 43.24s/it]                                                     {'loss': 0.365, 'grad_norm': 0.31640625, 'learning_rate': 3.4741423847583134e-06, 'epoch': 1.47}
 73%|███████▎  | 573/780 [7:03:29<2:29:10, 43.24s/it] 74%|███████▎  | 574/780 [7:04:13<2:29:20, 43.50s/it]                                                     {'loss': 0.3607, 'grad_norm': 0.291015625, 'learning_rate': 3.442876761719657e-06, 'epoch': 1.47}
 74%|███████▎  | 574/780 [7:04:13<2:29:20, 43.50s/it] 74%|███████▎  | 575/780 [7:04:56<2:28:02, 43.33s/it]                                                     {'loss': 0.3752, 'grad_norm': 0.31640625, 'learning_rate': 3.4117231818254205e-06, 'epoch': 1.47}
 74%|███████▎  | 575/780 [7:04:56<2:28:02, 43.33s/it] 74%|███████▍  | 576/780 [7:05:42<2:29:51, 44.08s/it]                                                     {'loss': 0.4006, 'grad_norm': 0.3203125, 'learning_rate': 3.380682177404335e-06, 'epoch': 1.47}
 74%|███████▍  | 576/780 [7:05:42<2:29:51, 44.08s/it] 74%|███████▍  | 577/780 [7:06:26<2:29:40, 44.24s/it]                                                     {'loss': 0.3807, 'grad_norm': 0.318359375, 'learning_rate': 3.349754278861517e-06, 'epoch': 1.48}
 74%|███████▍  | 577/780 [7:06:26<2:29:40, 44.24s/it] 74%|███████▍  | 578/780 [7:07:11<2:29:54, 44.53s/it]                                                     {'loss': 0.3686, 'grad_norm': 0.294921875, 'learning_rate': 3.318940014669423e-06, 'epoch': 1.48}
 74%|███████▍  | 578/780 [7:07:12<2:29:54, 44.53s/it] 74%|███████▍  | 579/780 [7:07:57<2:30:05, 44.80s/it]                                                     {'loss': 0.3586, 'grad_norm': 0.32421875, 'learning_rate': 3.288239911358807e-06, 'epoch': 1.48}
 74%|███████▍  | 579/780 [7:07:57<2:30:05, 44.80s/it] 74%|███████▍  | 580/780 [7:08:43<2:30:37, 45.19s/it]                                                     {'loss': 0.3687, 'grad_norm': 0.283203125, 'learning_rate': 3.2576544935097264e-06, 'epoch': 1.48}
 74%|███████▍  | 580/780 [7:08:43<2:30:37, 45.19s/it] 74%|███████▍  | 581/780 [7:09:25<2:26:14, 44.09s/it]                                                     {'loss': 0.3886, 'grad_norm': 0.306640625, 'learning_rate': 3.2271842837425917e-06, 'epoch': 1.49}
 74%|███████▍  | 581/780 [7:09:25<2:26:14, 44.09s/it] 75%|███████▍  | 582/780 [7:10:09<2:25:41, 44.15s/it]                                                     {'loss': 0.3817, 'grad_norm': 0.3046875, 'learning_rate': 3.196829802709209e-06, 'epoch': 1.49}
 75%|███████▍  | 582/780 [7:10:09<2:25:41, 44.15s/it] 75%|███████▍  | 583/780 [7:10:54<2:26:19, 44.56s/it]                                                     {'loss': 0.3764, 'grad_norm': 0.40234375, 'learning_rate': 3.1665915690839165e-06, 'epoch': 1.49}
 75%|███████▍  | 583/780 [7:10:54<2:26:19, 44.56s/it] 75%|███████▍  | 584/780 [7:11:40<2:26:29, 44.85s/it]                                                     {'loss': 0.3611, 'grad_norm': 0.302734375, 'learning_rate': 3.1364700995546906e-06, 'epoch': 1.49}
 75%|███████▍  | 584/780 [7:11:40<2:26:29, 44.85s/it] 75%|███████▌  | 585/780 [7:12:27<2:28:08, 45.58s/it]                                                     {'loss': 0.3533, 'grad_norm': 0.30078125, 'learning_rate': 3.1064659088143424e-06, 'epoch': 1.5}
 75%|███████▌  | 585/780 [7:12:27<2:28:08, 45.58s/it] 75%|███████▌  | 586/780 [7:13:10<2:24:52, 44.81s/it]                                                     {'loss': 0.3734, 'grad_norm': 0.302734375, 'learning_rate': 3.0765795095517026e-06, 'epoch': 1.5}
 75%|███████▌  | 586/780 [7:13:10<2:24:52, 44.81s/it] 75%|███████▌  | 587/780 [7:13:57<2:26:15, 45.47s/it]                                                     {'loss': 0.4024, 'grad_norm': 0.337890625, 'learning_rate': 3.0468114124428806e-06, 'epoch': 1.5}
 75%|███████▌  | 587/780 [7:13:57<2:26:15, 45.47s/it] 75%|███████▌  | 588/780 [7:14:43<2:26:07, 45.67s/it]                                                     {'loss': 0.41, 'grad_norm': 0.296875, 'learning_rate': 3.0171621261425164e-06, 'epoch': 1.5}
 75%|███████▌  | 588/780 [7:14:43<2:26:07, 45.67s/it] 76%|███████▌  | 589/780 [7:15:28<2:24:03, 45.25s/it]                                                     {'loss': 0.3819, 'grad_norm': 0.333984375, 'learning_rate': 2.9876321572751143e-06, 'epoch': 1.51}
 76%|███████▌  | 589/780 [7:15:28<2:24:03, 45.25s/it] 76%|███████▌  | 590/780 [7:16:14<2:24:05, 45.50s/it]                                                     {'loss': 0.3406, 'grad_norm': 0.279296875, 'learning_rate': 2.9582220104263603e-06, 'epoch': 1.51}
 76%|███████▌  | 590/780 [7:16:14<2:24:05, 45.50s/it] 76%|███████▌  | 591/780 [7:16:59<2:23:30, 45.56s/it]                                                     {'loss': 0.371, 'grad_norm': 0.35546875, 'learning_rate': 2.9289321881345257e-06, 'epoch': 1.51}
 76%|███████▌  | 591/780 [7:16:59<2:23:30, 45.56s/it] 76%|███████▌  | 592/780 [7:17:41<2:19:24, 44.49s/it]                                                     {'loss': 0.355, 'grad_norm': 0.333984375, 'learning_rate': 2.8997631908818556e-06, 'epoch': 1.51}
 76%|███████▌  | 592/780 [7:17:41<2:19:24, 44.49s/it] 76%|███████▌  | 593/780 [7:18:27<2:20:11, 44.98s/it]                                                     {'loss': 0.3826, 'grad_norm': 0.51171875, 'learning_rate': 2.8707155170860303e-06, 'epoch': 1.52}
 76%|███████▌  | 593/780 [7:18:28<2:20:11, 44.98s/it] 76%|███████▌  | 594/780 [7:19:13<2:20:19, 45.27s/it]                                                     {'loss': 0.3547, 'grad_norm': 0.31640625, 'learning_rate': 2.8417896630916552e-06, 'epoch': 1.52}
 76%|███████▌  | 594/780 [7:19:13<2:20:19, 45.27s/it] 76%|███████▋  | 595/780 [7:19:57<2:18:03, 44.78s/it]                                                     {'loss': 0.4101, 'grad_norm': 0.31640625, 'learning_rate': 2.812986123161762e-06, 'epoch': 1.52}
 76%|███████▋  | 595/780 [7:19:57<2:18:03, 44.78s/it] 76%|███████▋  | 596/780 [7:20:42<2:17:38, 44.88s/it]                                                     {'loss': 0.3722, 'grad_norm': 0.314453125, 'learning_rate': 2.7843053894693805e-06, 'epoch': 1.52}
 76%|███████▋  | 596/780 [7:20:42<2:17:38, 44.88s/it] 77%|███████▋  | 597/780 [7:21:29<2:18:46, 45.50s/it]                                                     {'loss': 0.3534, 'grad_norm': 0.35546875, 'learning_rate': 2.7557479520891104e-06, 'epoch': 1.53}
 77%|███████▋  | 597/780 [7:21:29<2:18:46, 45.50s/it] 77%|███████▋  | 598/780 [7:22:14<2:17:24, 45.30s/it]                                                     {'loss': 0.4037, 'grad_norm': 0.330078125, 'learning_rate': 2.7273142989887726e-06, 'epoch': 1.53}
 77%|███████▋  | 598/780 [7:22:14<2:17:24, 45.30s/it] 77%|███████▋  | 599/780 [7:22:56<2:14:02, 44.43s/it]                                                     {'loss': 0.3918, 'grad_norm': 0.310546875, 'learning_rate': 2.6990049160210386e-06, 'epoch': 1.53}
 77%|███████▋  | 599/780 [7:22:56<2:14:02, 44.43s/it] 77%|███████▋  | 600/780 [7:23:42<2:14:12, 44.73s/it]                                                     {'loss': 0.3812, 'grad_norm': 0.48828125, 'learning_rate': 2.670820286915161e-06, 'epoch': 1.54}
 77%|███████▋  | 600/780 [7:23:42<2:14:12, 44.73s/it] 77%|███████▋  | 601/780 [7:24:29<2:15:43, 45.50s/it]                                                     {'loss': 0.4248, 'grad_norm': 0.314453125, 'learning_rate': 2.642760893268684e-06, 'epoch': 1.54}
 77%|███████▋  | 601/780 [7:24:29<2:15:43, 45.50s/it] 77%|███████▋  | 602/780 [7:25:14<2:14:16, 45.26s/it]                                                     {'loss': 0.3783, 'grad_norm': 0.314453125, 'learning_rate': 2.6148272145392294e-06, 'epoch': 1.54}
 77%|███████▋  | 602/780 [7:25:14<2:14:16, 45.26s/it] 77%|███████▋  | 603/780 [7:25:58<2:12:59, 45.08s/it]                                                     {'loss': 0.3809, 'grad_norm': 0.326171875, 'learning_rate': 2.587019728036292e-06, 'epoch': 1.54}
 77%|███████▋  | 603/780 [7:25:58<2:12:59, 45.08s/it] 77%|███████▋  | 604/780 [7:26:43<2:11:30, 44.83s/it]                                                     {'loss': 0.3623, 'grad_norm': 0.333984375, 'learning_rate': 2.559338908913096e-06, 'epoch': 1.55}
 77%|███████▋  | 604/780 [7:26:43<2:11:30, 44.83s/it] 78%|███████▊  | 605/780 [7:27:28<2:10:56, 44.89s/it]                                                     {'loss': 0.383, 'grad_norm': 0.3125, 'learning_rate': 2.5317852301584642e-06, 'epoch': 1.55}
 78%|███████▊  | 605/780 [7:27:28<2:10:56, 44.89s/it] 78%|███████▊  | 606/780 [7:28:13<2:10:51, 45.13s/it]                                                     {'loss': 0.3826, 'grad_norm': 0.3046875, 'learning_rate': 2.504359162588741e-06, 'epoch': 1.55}
 78%|███████▊  | 606/780 [7:28:13<2:10:51, 45.13s/it] 78%|███████▊  | 607/780 [7:28:58<2:09:24, 44.88s/it]                                                     {'loss': 0.3638, 'grad_norm': 0.3046875, 'learning_rate': 2.4770611748397556e-06, 'epoch': 1.55}
 78%|███████▊  | 607/780 [7:28:58<2:09:24, 44.88s/it] 78%|███████▊  | 608/780 [7:29:42<2:08:25, 44.80s/it]                                                     {'loss': 0.3946, 'grad_norm': 0.37890625, 'learning_rate': 2.4498917333587934e-06, 'epoch': 1.56}
 78%|███████▊  | 608/780 [7:29:42<2:08:25, 44.80s/it] 78%|███████▊  | 609/780 [7:30:29<2:08:52, 45.22s/it]                                                     {'loss': 0.3594, 'grad_norm': 0.357421875, 'learning_rate': 2.422851302396655e-06, 'epoch': 1.56}
 78%|███████▊  | 609/780 [7:30:29<2:08:52, 45.22s/it] 78%|███████▊  | 610/780 [7:31:09<2:04:22, 43.90s/it]                                                     {'loss': 0.386, 'grad_norm': 0.30859375, 'learning_rate': 2.395940343999691e-06, 'epoch': 1.56}
 78%|███████▊  | 610/780 [7:31:09<2:04:22, 43.90s/it] 78%|███████▊  | 611/780 [7:31:56<2:06:14, 44.82s/it]                                                     {'loss': 0.3923, 'grad_norm': 0.302734375, 'learning_rate': 2.369159318001937e-06, 'epoch': 1.56}
 78%|███████▊  | 611/780 [7:31:56<2:06:14, 44.82s/it] 78%|███████▊  | 612/780 [7:32:40<2:04:50, 44.59s/it]                                                     {'loss': 0.3805, 'grad_norm': 0.330078125, 'learning_rate': 2.3425086820172295e-06, 'epoch': 1.57}
 78%|███████▊  | 612/780 [7:32:40<2:04:50, 44.59s/it] 79%|███████▊  | 613/780 [7:33:24<2:03:39, 44.43s/it]                                                     {'loss': 0.3531, 'grad_norm': 0.314453125, 'learning_rate': 2.315988891431412e-06, 'epoch': 1.57}
 79%|███████▊  | 613/780 [7:33:24<2:03:39, 44.43s/it] 79%|███████▊  | 614/780 [7:34:11<2:04:41, 45.07s/it]                                                     {'loss': 0.3697, 'grad_norm': 0.2890625, 'learning_rate': 2.2896003993945292e-06, 'epoch': 1.57}
 79%|███████▊  | 614/780 [7:34:11<2:04:41, 45.07s/it] 79%|███████▉  | 615/780 [7:34:58<2:05:30, 45.64s/it]                                                     {'loss': 0.3713, 'grad_norm': 0.310546875, 'learning_rate': 2.263343656813107e-06, 'epoch': 1.57}
 79%|███████▉  | 615/780 [7:34:58<2:05:30, 45.64s/it] 79%|███████▉  | 616/780 [7:35:43<2:03:55, 45.34s/it]                                                     {'loss': 0.3975, 'grad_norm': 0.30859375, 'learning_rate': 2.237219112342426e-06, 'epoch': 1.58}
 79%|███████▉  | 616/780 [7:35:43<2:03:55, 45.34s/it] 79%|███████▉  | 617/780 [7:36:32<2:06:12, 46.46s/it]                                                     {'loss': 0.3575, 'grad_norm': 0.29296875, 'learning_rate': 2.211227212378877e-06, 'epoch': 1.58}
 79%|███████▉  | 617/780 [7:36:32<2:06:12, 46.46s/it] 79%|███████▉  | 618/780 [7:37:19<2:05:51, 46.62s/it]                                                     {'loss': 0.3636, 'grad_norm': 0.318359375, 'learning_rate': 2.18536840105231e-06, 'epoch': 1.58}
 79%|███████▉  | 618/780 [7:37:19<2:05:51, 46.62s/it] 79%|███████▉  | 619/780 [7:38:04<2:03:44, 46.12s/it]                                                     {'loss': 0.3549, 'grad_norm': 0.291015625, 'learning_rate': 2.1596431202184707e-06, 'epoch': 1.58}
 79%|███████▉  | 619/780 [7:38:04<2:03:44, 46.12s/it] 79%|███████▉  | 620/780 [7:38:51<2:04:09, 46.56s/it]                                                     {'loss': 0.3901, 'grad_norm': 0.298828125, 'learning_rate': 2.1340518094514262e-06, 'epoch': 1.59}
 79%|███████▉  | 620/780 [7:38:51<2:04:09, 46.56s/it] 80%|███████▉  | 621/780 [7:39:36<2:01:56, 46.02s/it]                                                     {'loss': 0.3701, 'grad_norm': 0.296875, 'learning_rate': 2.1085949060360654e-06, 'epoch': 1.59}
 80%|███████▉  | 621/780 [7:39:36<2:01:56, 46.02s/it] 80%|███████▉  | 622/780 [7:40:24<2:03:06, 46.75s/it]                                                     {'loss': 0.3937, 'grad_norm': 0.318359375, 'learning_rate': 2.0832728449606364e-06, 'epoch': 1.59}
 80%|███████▉  | 622/780 [7:40:24<2:03:06, 46.75s/it] 80%|███████▉  | 623/780 [7:41:10<2:01:25, 46.41s/it]                                                     {'loss': 0.3654, 'grad_norm': 0.3359375, 'learning_rate': 2.0580860589092897e-06, 'epoch': 1.59}
 80%|███████▉  | 623/780 [7:41:10<2:01:25, 46.41s/it] 80%|████████  | 624/780 [7:41:55<1:59:24, 45.93s/it]                                                     {'loss': 0.3891, 'grad_norm': 0.318359375, 'learning_rate': 2.033034978254714e-06, 'epoch': 1.6}
 80%|████████  | 624/780 [7:41:55<1:59:24, 45.93s/it] 80%|████████  | 625/780 [7:42:40<1:58:05, 45.71s/it]                                                     {'loss': 0.3678, 'grad_norm': 0.298828125, 'learning_rate': 2.008120031050753e-06, 'epoch': 1.6}
 80%|████████  | 625/780 [7:42:40<1:58:05, 45.71s/it] 80%|████████  | 626/780 [7:43:26<1:57:15, 45.68s/it]                                                     {'loss': 0.4009, 'grad_norm': 0.35546875, 'learning_rate': 1.983341643025117e-06, 'epoch': 1.6}
 80%|████████  | 626/780 [7:43:26<1:57:15, 45.68s/it] 80%|████████  | 627/780 [7:44:11<1:55:53, 45.45s/it]                                                     {'loss': 0.3785, 'grad_norm': 0.3125, 'learning_rate': 1.9587002375720864e-06, 'epoch': 1.6}
 80%|████████  | 627/780 [7:44:11<1:55:53, 45.45s/it] 81%|████████  | 628/780 [7:44:58<1:56:40, 46.06s/it]                                                     {'loss': 0.3933, 'grad_norm': 0.322265625, 'learning_rate': 1.934196235745297e-06, 'epoch': 1.61}
 81%|████████  | 628/780 [7:44:58<1:56:40, 46.06s/it] 81%|████████  | 629/780 [7:45:43<1:54:58, 45.68s/it]                                                     {'loss': 0.3788, 'grad_norm': 0.30859375, 'learning_rate': 1.9098300562505266e-06, 'epoch': 1.61}
 81%|████████  | 629/780 [7:45:43<1:54:58, 45.68s/it] 81%|████████  | 630/780 [7:46:27<1:53:21, 45.35s/it]                                                     {'loss': 0.4004, 'grad_norm': 0.3125, 'learning_rate': 1.8856021154385595e-06, 'epoch': 1.61}
 81%|████████  | 630/780 [7:46:27<1:53:21, 45.35s/it] 81%|████████  | 631/780 [7:47:09<1:49:57, 44.28s/it]                                                     {'loss': 0.3894, 'grad_norm': 0.32421875, 'learning_rate': 1.861512827298051e-06, 'epoch': 1.61}
 81%|████████  | 631/780 [7:47:09<1:49:57, 44.28s/it] 81%|████████  | 632/780 [7:47:55<1:50:30, 44.80s/it]                                                     {'loss': 0.3861, 'grad_norm': 0.3203125, 'learning_rate': 1.8375626034484772e-06, 'epoch': 1.62}
 81%|████████  | 632/780 [7:47:55<1:50:30, 44.80s/it] 81%|████████  | 633/780 [7:48:40<1:49:42, 44.78s/it]                                                     {'loss': 0.4124, 'grad_norm': 0.3125, 'learning_rate': 1.8137518531330768e-06, 'epoch': 1.62}
 81%|████████  | 633/780 [7:48:40<1:49:42, 44.78s/it] 81%|████████▏ | 634/780 [7:49:24<1:48:16, 44.50s/it]                                                     {'loss': 0.3825, 'grad_norm': 0.36328125, 'learning_rate': 1.7900809832118814e-06, 'epoch': 1.62}
 81%|████████▏ | 634/780 [7:49:24<1:48:16, 44.50s/it] 81%|████████▏ | 635/780 [7:50:09<1:47:44, 44.58s/it]                                                     {'loss': 0.3737, 'grad_norm': 0.306640625, 'learning_rate': 1.7665503981547428e-06, 'epoch': 1.62}
 81%|████████▏ | 635/780 [7:50:09<1:47:44, 44.58s/it] 82%|████████▏ | 636/780 [7:50:54<1:47:44, 44.89s/it]                                                     {'loss': 0.3654, 'grad_norm': 0.326171875, 'learning_rate': 1.743160500034443e-06, 'epoch': 1.63}
 82%|████████▏ | 636/780 [7:50:54<1:47:44, 44.89s/it] 82%|████████▏ | 637/780 [7:51:38<1:46:08, 44.54s/it]                                                     {'loss': 0.3889, 'grad_norm': 0.333984375, 'learning_rate': 1.7199116885197996e-06, 'epoch': 1.63}
 82%|████████▏ | 637/780 [7:51:38<1:46:08, 44.54s/it] 82%|████████▏ | 638/780 [7:52:23<1:45:38, 44.64s/it]                                                     {'loss': 0.3812, 'grad_norm': 0.306640625, 'learning_rate': 1.6968043608688611e-06, 'epoch': 1.63}
 82%|████████▏ | 638/780 [7:52:23<1:45:38, 44.64s/it] 82%|████████▏ | 639/780 [7:53:08<1:45:35, 44.93s/it]                                                     {'loss': 0.3737, 'grad_norm': 0.30078125, 'learning_rate': 1.6738389119220966e-06, 'epoch': 1.63}
 82%|████████▏ | 639/780 [7:53:08<1:45:35, 44.93s/it] 82%|████████▏ | 640/780 [7:53:52<1:43:42, 44.44s/it]                                                     {'loss': 0.3741, 'grad_norm': 0.302734375, 'learning_rate': 1.65101573409567e-06, 'epoch': 1.64}
 82%|████████▏ | 640/780 [7:53:52<1:43:42, 44.44s/it] 82%|████████▏ | 641/780 [7:54:38<1:44:22, 45.05s/it]                                                     {'loss': 0.3972, 'grad_norm': 0.322265625, 'learning_rate': 1.6283352173747148e-06, 'epoch': 1.64}
 82%|████████▏ | 641/780 [7:54:38<1:44:22, 45.05s/it] 82%|████████▏ | 642/780 [7:55:22<1:42:36, 44.61s/it]                                                     {'loss': 0.3977, 'grad_norm': 0.306640625, 'learning_rate': 1.6057977493066868e-06, 'epoch': 1.64}
 82%|████████▏ | 642/780 [7:55:22<1:42:36, 44.61s/it] 82%|████████▏ | 643/780 [7:56:08<1:42:41, 44.97s/it]                                                     {'loss': 0.3775, 'grad_norm': 0.306640625, 'learning_rate': 1.5834037149947291e-06, 'epoch': 1.65}
 82%|████████▏ | 643/780 [7:56:08<1:42:41, 44.97s/it] 83%|████████▎ | 644/780 [7:56:51<1:41:01, 44.57s/it]                                                     {'loss': 0.3766, 'grad_norm': 0.419921875, 'learning_rate': 1.5611534970911058e-06, 'epoch': 1.65}
 83%|████████▎ | 644/780 [7:56:51<1:41:01, 44.57s/it] 83%|████████▎ | 645/780 [7:57:36<1:40:16, 44.57s/it]                                                     {'loss': 0.3868, 'grad_norm': 0.357421875, 'learning_rate': 1.5390474757906449e-06, 'epoch': 1.65}
 83%|████████▎ | 645/780 [7:57:36<1:40:16, 44.57s/it] 83%|████████▎ | 646/780 [7:58:21<1:40:08, 44.84s/it]                                                     {'loss': 0.3844, 'grad_norm': 0.328125, 'learning_rate': 1.5170860288242638e-06, 'epoch': 1.65}
 83%|████████▎ | 646/780 [7:58:21<1:40:08, 44.84s/it] 83%|████████▎ | 647/780 [7:59:05<1:38:39, 44.51s/it]                                                     {'loss': 0.3807, 'grad_norm': 0.32421875, 'learning_rate': 1.4952695314524912e-06, 'epoch': 1.66}
 83%|████████▎ | 647/780 [7:59:05<1:38:39, 44.51s/it] 83%|████████▎ | 648/780 [7:59:51<1:38:51, 44.94s/it]                                                     {'loss': 0.3725, 'grad_norm': 0.318359375, 'learning_rate': 1.4735983564590784e-06, 'epoch': 1.66}
 83%|████████▎ | 648/780 [7:59:51<1:38:51, 44.94s/it] 83%|████████▎ | 649/780 [8:00:36<1:38:34, 45.15s/it]                                                     {'loss': 0.3715, 'grad_norm': 0.302734375, 'learning_rate': 1.4520728741446087e-06, 'epoch': 1.66}
 83%|████████▎ | 649/780 [8:00:37<1:38:34, 45.15s/it] 83%|████████▎ | 650/780 [8:01:20<1:36:52, 44.71s/it]                                                     {'loss': 0.3985, 'grad_norm': 0.322265625, 'learning_rate': 1.4306934523201898e-06, 'epoch': 1.66}
 83%|████████▎ | 650/780 [8:01:20<1:36:52, 44.71s/it] 83%|████████▎ | 651/780 [8:02:03<1:34:58, 44.18s/it]                                                     {'loss': 0.3689, 'grad_norm': 0.3046875, 'learning_rate': 1.409460456301147e-06, 'epoch': 1.67}
 83%|████████▎ | 651/780 [8:02:03<1:34:58, 44.18s/it] 84%|████████▎ | 652/780 [8:02:49<1:35:22, 44.71s/it]                                                     {'loss': 0.3733, 'grad_norm': 0.29296875, 'learning_rate': 1.3883742489008033e-06, 'epoch': 1.67}
 84%|████████▎ | 652/780 [8:02:49<1:35:22, 44.71s/it] 84%|████████▎ | 653/780 [8:03:35<1:35:13, 44.99s/it]                                                     {'loss': 0.3814, 'grad_norm': 0.306640625, 'learning_rate': 1.367435190424261e-06, 'epoch': 1.67}
 84%|████████▎ | 653/780 [8:03:35<1:35:13, 44.99s/it] 84%|████████▍ | 654/780 [8:04:20<1:34:51, 45.17s/it]                                                     {'loss': 0.3829, 'grad_norm': 0.32421875, 'learning_rate': 1.3466436386622583e-06, 'epoch': 1.67}
 84%|████████▍ | 654/780 [8:04:20<1:34:51, 45.17s/it] 84%|████████▍ | 655/780 [8:05:06<1:34:15, 45.24s/it]                                                     {'loss': 0.3632, 'grad_norm': 0.30859375, 'learning_rate': 1.3259999488850473e-06, 'epoch': 1.68}
 84%|████████▍ | 655/780 [8:05:06<1:34:15, 45.24s/it] 84%|████████▍ | 656/780 [8:05:48<1:31:41, 44.37s/it]                                                     {'loss': 0.3932, 'grad_norm': 0.302734375, 'learning_rate': 1.305504473836331e-06, 'epoch': 1.68}
 84%|████████▍ | 656/780 [8:05:48<1:31:41, 44.37s/it] 84%|████████▍ | 657/780 [8:06:30<1:29:22, 43.60s/it]                                                     {'loss': 0.3764, 'grad_norm': 0.283203125, 'learning_rate': 1.2851575637272262e-06, 'epoch': 1.68}
 84%|████████▍ | 657/780 [8:06:30<1:29:22, 43.60s/it] 84%|████████▍ | 658/780 [8:07:15<1:29:36, 44.07s/it]                                                     {'loss': 0.38, 'grad_norm': 0.31640625, 'learning_rate': 1.2649595662302905e-06, 'epoch': 1.68}
 84%|████████▍ | 658/780 [8:07:15<1:29:36, 44.07s/it] 84%|████████▍ | 659/780 [8:07:59<1:28:56, 44.10s/it]                                                     {'loss': 0.3698, 'grad_norm': 0.31640625, 'learning_rate': 1.2449108264735721e-06, 'epoch': 1.69}
 84%|████████▍ | 659/780 [8:07:59<1:28:56, 44.10s/it] 85%|████████▍ | 660/780 [8:08:46<1:29:37, 44.81s/it]                                                     {'loss': 0.3917, 'grad_norm': 0.3125, 'learning_rate': 1.225011687034714e-06, 'epoch': 1.69}
 85%|████████▍ | 660/780 [8:08:46<1:29:37, 44.81s/it] 85%|████████▍ | 661/780 [8:09:30<1:28:53, 44.82s/it]                                                     {'loss': 0.3778, 'grad_norm': 0.330078125, 'learning_rate': 1.2052624879351105e-06, 'epoch': 1.69}
 85%|████████▍ | 661/780 [8:09:31<1:28:53, 44.82s/it] 85%|████████▍ | 662/780 [8:10:17<1:28:54, 45.21s/it]                                                     {'loss': 0.3745, 'grad_norm': 0.33984375, 'learning_rate': 1.1856635666340788e-06, 'epoch': 1.69}
 85%|████████▍ | 662/780 [8:10:17<1:28:54, 45.21s/it] 85%|████████▌ | 663/780 [8:11:00<1:27:04, 44.65s/it]                                                     {'loss': 0.3988, 'grad_norm': 0.3203125, 'learning_rate': 1.1662152580231145e-06, 'epoch': 1.7}
 85%|████████▌ | 663/780 [8:11:00<1:27:04, 44.65s/it] 85%|████████▌ | 664/780 [8:11:44<1:25:48, 44.39s/it]                                                     {'loss': 0.3816, 'grad_norm': 0.3046875, 'learning_rate': 1.1469178944201475e-06, 'epoch': 1.7}
 85%|████████▌ | 664/780 [8:11:44<1:25:48, 44.39s/it] 85%|████████▌ | 665/780 [8:12:27<1:24:19, 44.00s/it]                                                     {'loss': 0.4189, 'grad_norm': 0.298828125, 'learning_rate': 1.127771805563882e-06, 'epoch': 1.7}
 85%|████████▌ | 665/780 [8:12:27<1:24:19, 44.00s/it] 85%|████████▌ | 666/780 [8:13:10<1:23:01, 43.70s/it]                                                     {'loss': 0.3515, 'grad_norm': 0.310546875, 'learning_rate': 1.1087773186081474e-06, 'epoch': 1.7}
 85%|████████▌ | 666/780 [8:13:10<1:23:01, 43.70s/it] 86%|████████▌ | 667/780 [8:13:55<1:23:20, 44.25s/it]                                                     {'loss': 0.4076, 'grad_norm': 0.318359375, 'learning_rate': 1.0899347581163222e-06, 'epoch': 1.71}
 86%|████████▌ | 667/780 [8:13:55<1:23:20, 44.25s/it] 86%|████████▌ | 668/780 [8:14:42<1:23:56, 44.97s/it]                                                     {'loss': 0.3434, 'grad_norm': 0.306640625, 'learning_rate': 1.0712444460557713e-06, 'epoch': 1.71}
 86%|████████▌ | 668/780 [8:14:42<1:23:56, 44.97s/it] 86%|████████▌ | 669/780 [8:15:26<1:22:45, 44.73s/it]                                                     {'loss': 0.3472, 'grad_norm': 0.435546875, 'learning_rate': 1.0527067017923654e-06, 'epoch': 1.71}
 86%|████████▌ | 669/780 [8:15:26<1:22:45, 44.73s/it] 86%|████████▌ | 670/780 [8:16:13<1:22:58, 45.26s/it]                                                     {'loss': 0.3688, 'grad_norm': 0.326171875, 'learning_rate': 1.0343218420850021e-06, 'epoch': 1.71}
 86%|████████▌ | 670/780 [8:16:13<1:22:58, 45.26s/it] 86%|████████▌ | 671/780 [8:16:55<1:20:25, 44.27s/it]                                                     {'loss': 0.3753, 'grad_norm': 0.306640625, 'learning_rate': 1.0160901810802114e-06, 'epoch': 1.72}
 86%|████████▌ | 671/780 [8:16:55<1:20:25, 44.27s/it] 86%|████████▌ | 672/780 [8:17:40<1:20:22, 44.66s/it]                                                     {'loss': 0.4078, 'grad_norm': 0.302734375, 'learning_rate': 9.980120303067742e-07, 'epoch': 1.72}
 86%|████████▌ | 672/780 [8:17:40<1:20:22, 44.66s/it] 86%|████████▋ | 673/780 [8:18:28<1:21:06, 45.48s/it]                                                     {'loss': 0.3518, 'grad_norm': 0.298828125, 'learning_rate': 9.800876986704111e-07, 'epoch': 1.72}
 86%|████████▋ | 673/780 [8:18:28<1:21:06, 45.48s/it] 86%|████████▋ | 674/780 [8:19:11<1:19:15, 44.87s/it]                                                     {'loss': 0.3845, 'grad_norm': 0.30078125, 'learning_rate': 9.623174924484923e-07, 'epoch': 1.72}
 86%|████████▋ | 674/780 [8:19:11<1:19:15, 44.87s/it] 87%|████████▋ | 675/780 [8:19:56<1:18:42, 44.98s/it]                                                     {'loss': 0.3859, 'grad_norm': 0.314453125, 'learning_rate': 9.447017152848126e-07, 'epoch': 1.73}
 87%|████████▋ | 675/780 [8:19:56<1:18:42, 44.98s/it] 87%|████████▋ | 676/780 [8:20:40<1:17:21, 44.63s/it]                                                     {'loss': 0.386, 'grad_norm': 0.298828125, 'learning_rate': 9.272406681844015e-07, 'epoch': 1.73}
 87%|████████▋ | 676/780 [8:20:40<1:17:21, 44.63s/it] 87%|████████▋ | 677/780 [8:21:27<1:17:32, 45.17s/it]                                                     {'loss': 0.39, 'grad_norm': 0.296875, 'learning_rate': 9.09934649508375e-07, 'epoch': 1.73}
 87%|████████▋ | 677/780 [8:21:27<1:17:32, 45.17s/it] 87%|████████▋ | 678/780 [8:22:06<1:14:02, 43.55s/it]                                                     {'loss': 0.3848, 'grad_norm': 0.7265625, 'learning_rate': 8.927839549688466e-07, 'epoch': 1.73}
 87%|████████▋ | 678/780 [8:22:06<1:14:02, 43.55s/it] 87%|████████▋ | 679/780 [8:22:51<1:13:57, 43.94s/it]                                                     {'loss': 0.3767, 'grad_norm': 0.322265625, 'learning_rate': 8.757888776238621e-07, 'epoch': 1.74}
 87%|████████▋ | 679/780 [8:22:51<1:13:57, 43.94s/it] 87%|████████▋ | 680/780 [8:23:36<1:13:51, 44.32s/it]                                                     {'loss': 0.3613, 'grad_norm': 0.30078125, 'learning_rate': 8.589497078724063e-07, 'epoch': 1.74}
 87%|████████▋ | 680/780 [8:23:36<1:13:51, 44.32s/it] 87%|████████▋ | 681/780 [8:24:21<1:13:32, 44.57s/it]                                                     {'loss': 0.3791, 'grad_norm': 0.30859375, 'learning_rate': 8.42266733449425e-07, 'epoch': 1.74}
 87%|████████▋ | 681/780 [8:24:22<1:13:32, 44.57s/it] 87%|████████▋ | 682/780 [8:25:08<1:13:57, 45.28s/it]                                                     {'loss': 0.3582, 'grad_norm': 0.3125, 'learning_rate': 8.257402394209258e-07, 'epoch': 1.74}
 87%|████████▋ | 682/780 [8:25:09<1:13:57, 45.28s/it] 88%|████████▊ | 683/780 [8:25:54<1:13:09, 45.26s/it]                                                     {'loss': 0.3917, 'grad_norm': 0.349609375, 'learning_rate': 8.093705081790892e-07, 'epoch': 1.75}
 88%|████████▊ | 683/780 [8:25:54<1:13:09, 45.26s/it] 88%|████████▊ | 684/780 [8:26:41<1:13:32, 45.96s/it]                                                     {'loss': 0.3896, 'grad_norm': 0.74609375, 'learning_rate': 7.931578194374601e-07, 'epoch': 1.75}
 88%|████████▊ | 684/780 [8:26:41<1:13:32, 45.96s/it] 88%|████████▊ | 685/780 [8:27:23<1:10:56, 44.81s/it]                                                     {'loss': 0.3949, 'grad_norm': 0.3125, 'learning_rate': 7.771024502261526e-07, 'epoch': 1.75}
 88%|████████▊ | 685/780 [8:27:23<1:10:56, 44.81s/it] 88%|████████▊ | 686/780 [8:28:07<1:09:52, 44.60s/it]                                                     {'loss': 0.4089, 'grad_norm': 0.310546875, 'learning_rate': 7.612046748871327e-07, 'epoch': 1.76}
 88%|████████▊ | 686/780 [8:28:08<1:09:52, 44.60s/it] 88%|████████▊ | 687/780 [8:28:55<1:10:30, 45.49s/it]                                                     {'loss': 0.3711, 'grad_norm': 0.31640625, 'learning_rate': 7.454647650695157e-07, 'epoch': 1.76}
 88%|████████▊ | 687/780 [8:28:55<1:10:30, 45.49s/it] 88%|████████▊ | 688/780 [8:29:39<1:08:50, 44.89s/it]                                                     {'loss': 0.3723, 'grad_norm': 0.31640625, 'learning_rate': 7.298829897249304e-07, 'epoch': 1.76}
 88%|████████▊ | 688/780 [8:29:39<1:08:50, 44.89s/it] 88%|████████▊ | 689/780 [8:30:23<1:08:06, 44.90s/it]                                                     {'loss': 0.3714, 'grad_norm': 0.296875, 'learning_rate': 7.144596151029304e-07, 'epoch': 1.76}
 88%|████████▊ | 689/780 [8:30:24<1:08:06, 44.90s/it] 88%|████████▊ | 690/780 [8:31:09<1:07:35, 45.06s/it]                                                     {'loss': 0.3696, 'grad_norm': 0.306640625, 'learning_rate': 6.991949047464286e-07, 'epoch': 1.77}
 88%|████████▊ | 690/780 [8:31:09<1:07:35, 45.06s/it] 89%|████████▊ | 691/780 [8:31:54<1:06:48, 45.03s/it]                                                     {'loss': 0.396, 'grad_norm': 0.337890625, 'learning_rate': 6.840891194872112e-07, 'epoch': 1.77}
 89%|████████▊ | 691/780 [8:31:54<1:06:48, 45.03s/it] 89%|████████▊ | 692/780 [8:32:35<1:04:26, 43.94s/it]                                                     {'loss': 0.3466, 'grad_norm': 0.28515625, 'learning_rate': 6.691425174414679e-07, 'epoch': 1.77}
 89%|████████▊ | 692/780 [8:32:35<1:04:26, 43.94s/it] 89%|████████▉ | 693/780 [8:33:20<1:04:00, 44.15s/it]                                                     {'loss': 0.363, 'grad_norm': 0.33984375, 'learning_rate': 6.543553540053926e-07, 'epoch': 1.77}
 89%|████████▉ | 693/780 [8:33:20<1:04:00, 44.15s/it] 89%|████████▉ | 694/780 [8:34:05<1:03:35, 44.36s/it]                                                     {'loss': 0.3616, 'grad_norm': 0.2890625, 'learning_rate': 6.397278818508035e-07, 'epoch': 1.78}
 89%|████████▉ | 694/780 [8:34:05<1:03:35, 44.36s/it] 89%|████████▉ | 695/780 [8:34:47<1:01:54, 43.70s/it]                                                     {'loss': 0.3981, 'grad_norm': 0.30859375, 'learning_rate': 6.252603509208466e-07, 'epoch': 1.78}
 89%|████████▉ | 695/780 [8:34:47<1:01:54, 43.70s/it] 89%|████████▉ | 696/780 [8:35:33<1:02:22, 44.55s/it]                                                     {'loss': 0.3757, 'grad_norm': 0.28515625, 'learning_rate': 6.109530084257043e-07, 'epoch': 1.78}
 89%|████████▉ | 696/780 [8:35:33<1:02:22, 44.55s/it] 89%|████████▉ | 697/780 [8:36:19<1:02:05, 44.89s/it]                                                     {'loss': 0.3655, 'grad_norm': 0.310546875, 'learning_rate': 5.968060988383884e-07, 'epoch': 1.78}
 89%|████████▉ | 697/780 [8:36:19<1:02:05, 44.89s/it] 89%|████████▉ | 698/780 [8:37:04<1:01:32, 45.03s/it]                                                     {'loss': 0.353, 'grad_norm': 0.3125, 'learning_rate': 5.828198638905458e-07, 'epoch': 1.79}
 89%|████████▉ | 698/780 [8:37:05<1:01:32, 45.03s/it] 90%|████████▉ | 699/780 [8:37:51<1:01:12, 45.34s/it]                                                     {'loss': 0.3812, 'grad_norm': 0.3671875, 'learning_rate': 5.689945425683474e-07, 'epoch': 1.79}
 90%|████████▉ | 699/780 [8:37:51<1:01:12, 45.34s/it] 90%|████████▉ | 700/780 [8:38:37<1:00:55, 45.69s/it]                                                     {'loss': 0.3505, 'grad_norm': 0.28515625, 'learning_rate': 5.55330371108388e-07, 'epoch': 1.79}
 90%|████████▉ | 700/780 [8:38:37<1:00:55, 45.69s/it] 90%|████████▉ | 701/780 [8:39:24<1:00:30, 45.96s/it]                                                     {'loss': 0.4045, 'grad_norm': 0.306640625, 'learning_rate': 5.418275829936537e-07, 'epoch': 1.79}
 90%|████████▉ | 701/780 [8:39:24<1:00:30, 45.96s/it] 90%|█████████ | 702/780 [8:40:07<58:36, 45.08s/it]                                                     {'loss': 0.3772, 'grad_norm': 0.322265625, 'learning_rate': 5.284864089495423e-07, 'epoch': 1.8}
 90%|█████████ | 702/780 [8:40:07<58:36, 45.08s/it] 90%|█████████ | 703/780 [8:40:51<57:40, 44.94s/it]                                                   {'loss': 0.3799, 'grad_norm': 0.3125, 'learning_rate': 5.15307076939906e-07, 'epoch': 1.8}
 90%|█████████ | 703/780 [8:40:51<57:40, 44.94s/it] 90%|█████████ | 704/780 [8:41:34<56:02, 44.25s/it]                                                   {'loss': 0.3947, 'grad_norm': 0.310546875, 'learning_rate': 5.022898121631681e-07, 'epoch': 1.8}
 90%|█████████ | 704/780 [8:41:34<56:02, 44.25s/it] 90%|█████████ | 705/780 [8:42:17<55:02, 44.03s/it]                                                   {'loss': 0.3729, 'grad_norm': 0.310546875, 'learning_rate': 4.894348370484648e-07, 'epoch': 1.8}
 90%|█████████ | 705/780 [8:42:17<55:02, 44.03s/it] 91%|█████████ | 706/780 [8:43:01<54:15, 43.99s/it]                                                   {'loss': 0.3894, 'grad_norm': 0.330078125, 'learning_rate': 4.7674237125185597e-07, 'epoch': 1.81}
 91%|█████████ | 706/780 [8:43:01<54:15, 43.99s/it] 91%|█████████ | 707/780 [8:43:44<52:51, 43.45s/it]                                                   {'loss': 0.3732, 'grad_norm': 0.30859375, 'learning_rate': 4.642126316525586e-07, 'epoch': 1.81}
 91%|█████████ | 707/780 [8:43:44<52:51, 43.45s/it] 91%|█████████ | 708/780 [8:44:29<52:52, 44.06s/it]                                                   {'loss': 0.3825, 'grad_norm': 0.3125, 'learning_rate': 4.518458323492558e-07, 'epoch': 1.81}
 91%|█████████ | 708/780 [8:44:29<52:52, 44.06s/it] 91%|█████████ | 709/780 [8:45:13<51:57, 43.90s/it]                                                   {'loss': 0.3886, 'grad_norm': 0.3125, 'learning_rate': 4.396421846564236e-07, 'epoch': 1.81}
 91%|█████████ | 709/780 [8:45:13<51:57, 43.90s/it] 91%|█████████ | 710/780 [8:45:58<51:38, 44.26s/it]                                                   {'loss': 0.374, 'grad_norm': 0.310546875, 'learning_rate': 4.276018971007323e-07, 'epoch': 1.82}
 91%|█████████ | 710/780 [8:45:58<51:38, 44.26s/it] 91%|█████████ | 711/780 [8:46:42<50:48, 44.19s/it]                                                   {'loss': 0.4006, 'grad_norm': 0.310546875, 'learning_rate': 4.1572517541747294e-07, 'epoch': 1.82}
 91%|█████████ | 711/780 [8:46:42<50:48, 44.19s/it] 91%|█████████▏| 712/780 [8:47:27<50:38, 44.68s/it]                                                   {'loss': 0.3995, 'grad_norm': 0.38671875, 'learning_rate': 4.040122225470533e-07, 'epoch': 1.82}
 91%|█████████▏| 712/780 [8:47:28<50:38, 44.68s/it] 91%|█████████▏| 713/780 [8:48:08<48:38, 43.56s/it]                                                   {'loss': 0.3718, 'grad_norm': 0.322265625, 'learning_rate': 3.924632386315186e-07, 'epoch': 1.82}
 91%|█████████▏| 713/780 [8:48:08<48:38, 43.56s/it] 92%|█████████▏| 714/780 [8:48:51<47:29, 43.18s/it]                                                   {'loss': 0.3997, 'grad_norm': 0.3125, 'learning_rate': 3.8107842101114067e-07, 'epoch': 1.83}
 92%|█████████▏| 714/780 [8:48:51<47:29, 43.18s/it] 92%|█████████▏| 715/780 [8:49:35<47:09, 43.52s/it]                                                   {'loss': 0.3635, 'grad_norm': 0.32421875, 'learning_rate': 3.698579642210398e-07, 'epoch': 1.83}
 92%|█████████▏| 715/780 [8:49:35<47:09, 43.52s/it] 92%|█████████▏| 716/780 [8:50:19<46:32, 43.64s/it]                                                   {'loss': 0.3847, 'grad_norm': 0.322265625, 'learning_rate': 3.588020599878639e-07, 'epoch': 1.83}
 92%|█████████▏| 716/780 [8:50:19<46:32, 43.64s/it] 92%|█████████▏| 717/780 [8:51:06<46:46, 44.55s/it]                                                   {'loss': 0.3753, 'grad_norm': 0.298828125, 'learning_rate': 3.4791089722651437e-07, 'epoch': 1.83}
 92%|█████████▏| 717/780 [8:51:06<46:46, 44.55s/it] 92%|█████████▏| 718/780 [8:51:51<46:11, 44.70s/it]                                                   {'loss': 0.388, 'grad_norm': 0.310546875, 'learning_rate': 3.371846620369101e-07, 'epoch': 1.84}
 92%|█████████▏| 718/780 [8:51:51<46:11, 44.70s/it] 92%|█████████▏| 719/780 [8:52:35<45:21, 44.62s/it]                                                   {'loss': 0.3765, 'grad_norm': 0.37890625, 'learning_rate': 3.2662353770081755e-07, 'epoch': 1.84}
 92%|█████████▏| 719/780 [8:52:35<45:21, 44.62s/it] 92%|█████████▏| 720/780 [8:53:20<44:33, 44.56s/it]                                                   {'loss': 0.3725, 'grad_norm': 0.318359375, 'learning_rate': 3.16227704678711e-07, 'epoch': 1.84}
 92%|█████████▏| 720/780 [8:53:20<44:33, 44.56s/it] 92%|█████████▏| 721/780 [8:54:05<44:06, 44.86s/it]                                                   {'loss': 0.3959, 'grad_norm': 0.310546875, 'learning_rate': 3.059973406066963e-07, 'epoch': 1.84}
 92%|█████████▏| 721/780 [8:54:05<44:06, 44.86s/it] 93%|█████████▎| 722/780 [8:54:52<43:52, 45.38s/it]                                                   {'loss': 0.3858, 'grad_norm': 0.30078125, 'learning_rate': 2.959326202934665e-07, 'epoch': 1.85}
 93%|█████████▎| 722/780 [8:54:52<43:52, 45.38s/it] 93%|█████████▎| 723/780 [8:55:35<42:33, 44.80s/it]                                                   {'loss': 0.3618, 'grad_norm': 0.306640625, 'learning_rate': 2.860337157173243e-07, 'epoch': 1.85}
 93%|█████████▎| 723/780 [8:55:35<42:33, 44.80s/it] 93%|█████████▎| 724/780 [8:56:21<42:10, 45.19s/it]                                                   {'loss': 0.3563, 'grad_norm': 0.32421875, 'learning_rate': 2.7630079602323447e-07, 'epoch': 1.85}
 93%|█████████▎| 724/780 [8:56:21<42:10, 45.19s/it] 93%|█████████▎| 725/780 [8:57:07<41:36, 45.39s/it]                                                   {'loss': 0.3519, 'grad_norm': 0.314453125, 'learning_rate': 2.667340275199426e-07, 'epoch': 1.86}
 93%|█████████▎| 725/780 [8:57:07<41:36, 45.39s/it] 93%|█████████▎| 726/780 [8:57:53<40:54, 45.45s/it]                                                   {'loss': 0.3649, 'grad_norm': 0.3359375, 'learning_rate': 2.573335736771254e-07, 'epoch': 1.86}
 93%|█████████▎| 726/780 [8:57:53<40:54, 45.45s/it] 93%|█████████▎| 727/780 [8:58:39<40:19, 45.66s/it]                                                   {'loss': 0.3736, 'grad_norm': 0.291015625, 'learning_rate': 2.4809959512260285e-07, 'epoch': 1.86}
 93%|█████████▎| 727/780 [8:58:39<40:19, 45.66s/it] 93%|█████████▎| 728/780 [8:59:21<38:45, 44.72s/it]                                                   {'loss': 0.3941, 'grad_norm': 0.474609375, 'learning_rate': 2.390322496395914e-07, 'epoch': 1.86}
 93%|█████████▎| 728/780 [8:59:21<38:45, 44.72s/it] 93%|█████████▎| 729/780 [9:00:07<38:20, 45.12s/it]                                                   {'loss': 0.3924, 'grad_norm': 0.318359375, 'learning_rate': 2.3013169216400732e-07, 'epoch': 1.87}
 93%|█████████▎| 729/780 [9:00:07<38:20, 45.12s/it] 94%|█████████▎| 730/780 [9:00:53<37:39, 45.20s/it]                                                   {'loss': 0.3624, 'grad_norm': 0.34375, 'learning_rate': 2.2139807478182008e-07, 'epoch': 1.87}
 94%|█████████▎| 730/780 [9:00:53<37:39, 45.20s/it] 94%|█████████▎| 731/780 [9:01:37<36:43, 44.97s/it]                                                   {'loss': 0.4181, 'grad_norm': 0.322265625, 'learning_rate': 2.1283154672645522e-07, 'epoch': 1.87}
 94%|█████████▎| 731/780 [9:01:37<36:43, 44.97s/it] 94%|█████████▍| 732/780 [9:02:24<36:20, 45.43s/it]                                                   {'loss': 0.3791, 'grad_norm': 0.283203125, 'learning_rate': 2.0443225437624003e-07, 'epoch': 1.87}
 94%|█████████▍| 732/780 [9:02:24<36:20, 45.43s/it] 94%|█████████▍| 733/780 [9:03:09<35:28, 45.29s/it]                                                   {'loss': 0.3863, 'grad_norm': 0.318359375, 'learning_rate': 1.9620034125190645e-07, 'epoch': 1.88}
 94%|█████████▍| 733/780 [9:03:09<35:28, 45.29s/it] 94%|█████████▍| 734/780 [9:03:54<34:38, 45.18s/it]                                                   {'loss': 0.3562, 'grad_norm': 0.3359375, 'learning_rate': 1.881359480141376e-07, 'epoch': 1.88}
 94%|█████████▍| 734/780 [9:03:54<34:38, 45.18s/it] 94%|█████████▍| 735/780 [9:04:41<34:22, 45.82s/it]                                                   {'loss': 0.3637, 'grad_norm': 0.33203125, 'learning_rate': 1.8023921246116405e-07, 'epoch': 1.88}
 94%|█████████▍| 735/780 [9:04:41<34:22, 45.82s/it] 94%|█████████▍| 736/780 [9:05:24<33:01, 45.03s/it]                                                   {'loss': 0.3871, 'grad_norm': 0.30078125, 'learning_rate': 1.7251026952640583e-07, 'epoch': 1.88}
 94%|█████████▍| 736/780 [9:05:24<33:01, 45.03s/it] 94%|█████████▍| 737/780 [9:06:12<32:47, 45.77s/it]                                                   {'loss': 0.3676, 'grad_norm': 0.294921875, 'learning_rate': 1.6494925127617632e-07, 'epoch': 1.89}
 94%|█████████▍| 737/780 [9:06:12<32:47, 45.77s/it] 95%|█████████▍| 738/780 [9:06:56<31:50, 45.49s/it]                                                   {'loss': 0.387, 'grad_norm': 0.306640625, 'learning_rate': 1.5755628690741432e-07, 'epoch': 1.89}
 95%|█████████▍| 738/780 [9:06:56<31:50, 45.49s/it] 95%|█████████▍| 739/780 [9:07:39<30:24, 44.50s/it]                                                   {'loss': 0.408, 'grad_norm': 0.318359375, 'learning_rate': 1.5033150274548325e-07, 'epoch': 1.89}
 95%|█████████▍| 739/780 [9:07:39<30:24, 44.50s/it] 95%|█████████▍| 740/780 [9:08:23<29:37, 44.44s/it]                                                   {'loss': 0.3801, 'grad_norm': 0.32421875, 'learning_rate': 1.4327502224200874e-07, 'epoch': 1.89}
 95%|█████████▍| 740/780 [9:08:23<29:37, 44.44s/it] 95%|█████████▌| 741/780 [9:09:07<28:50, 44.36s/it]                                                   {'loss': 0.3638, 'grad_norm': 0.326171875, 'learning_rate': 1.3638696597277678e-07, 'epoch': 1.9}
 95%|█████████▌| 741/780 [9:09:07<28:50, 44.36s/it] 95%|█████████▌| 742/780 [9:09:52<28:12, 44.55s/it]                                                   {'loss': 0.3854, 'grad_norm': 0.349609375, 'learning_rate': 1.2966745163566108e-07, 'epoch': 1.9}
 95%|█████████▌| 742/780 [9:09:52<28:12, 44.55s/it] 95%|█████████▌| 743/780 [9:10:38<27:41, 44.90s/it]                                                   {'loss': 0.3587, 'grad_norm': 0.310546875, 'learning_rate': 1.231165940486234e-07, 'epoch': 1.9}
 95%|█████████▌| 743/780 [9:10:38<27:41, 44.90s/it] 95%|█████████▌| 744/780 [9:11:22<26:53, 44.83s/it]                                                   {'loss': 0.3984, 'grad_norm': 0.322265625, 'learning_rate': 1.1673450514774421e-07, 'epoch': 1.9}
 95%|█████████▌| 744/780 [9:11:23<26:53, 44.83s/it] 96%|█████████▌| 745/780 [9:12:05<25:46, 44.17s/it]                                                   {'loss': 0.3853, 'grad_norm': 0.310546875, 'learning_rate': 1.1052129398531508e-07, 'epoch': 1.91}
 96%|█████████▌| 745/780 [9:12:05<25:46, 44.17s/it] 96%|█████████▌| 746/780 [9:12:50<25:13, 44.52s/it]                                                   {'loss': 0.3617, 'grad_norm': 0.3046875, 'learning_rate': 1.0447706672797264e-07, 'epoch': 1.91}
 96%|█████████▌| 746/780 [9:12:51<25:13, 44.52s/it] 96%|█████████▌| 747/780 [9:13:31<23:46, 43.23s/it]                                                   {'loss': 0.38, 'grad_norm': 0.3046875, 'learning_rate': 9.86019266548821e-08, 'epoch': 1.91}
 96%|█████████▌| 747/780 [9:13:31<23:46, 43.23s/it] 96%|█████████▌| 748/780 [9:14:17<23:36, 44.25s/it]                                                   {'loss': 0.3728, 'grad_norm': 0.310546875, 'learning_rate': 9.289597415597873e-08, 'epoch': 1.91}
 96%|█████████▌| 748/780 [9:14:17<23:36, 44.25s/it] 96%|█████████▌| 749/780 [9:15:04<23:14, 44.98s/it]                                                   {'loss': 0.3852, 'grad_norm': 0.28515625, 'learning_rate': 8.735930673024806e-08, 'epoch': 1.92}
 96%|█████████▌| 749/780 [9:15:04<23:14, 44.98s/it] 96%|█████████▌| 750/780 [9:15:50<22:34, 45.16s/it]                                                   {'loss': 0.3695, 'grad_norm': 0.310546875, 'learning_rate': 8.19920189840584e-08, 'epoch': 1.92}
 96%|█████████▌| 750/780 [9:15:50<22:34, 45.16s/it] 96%|█████████▋| 751/780 [9:16:34<21:39, 44.82s/it]                                                   {'loss': 0.3495, 'grad_norm': 0.322265625, 'learning_rate': 7.679420262954984e-08, 'epoch': 1.92}
 96%|█████████▋| 751/780 [9:16:34<21:39, 44.82s/it] 96%|█████████▋| 752/780 [9:17:19<21:02, 45.09s/it]                                                   {'loss': 0.3925, 'grad_norm': 0.3125, 'learning_rate': 7.176594648306113e-08, 'epoch': 1.92}
 96%|█████████▋| 752/780 [9:17:19<21:02, 45.09s/it] 97%|█████████▋| 753/780 [9:18:05<20:19, 45.16s/it]                                                   {'loss': 0.3745, 'grad_norm': 0.310546875, 'learning_rate': 6.690733646361858e-08, 'epoch': 1.93}
 97%|█████████▋| 753/780 [9:18:05<20:19, 45.16s/it] 97%|█████████▋| 754/780 [9:18:44<18:45, 43.28s/it]                                                   {'loss': 0.3808, 'grad_norm': 0.36328125, 'learning_rate': 6.221845559146067e-08, 'epoch': 1.93}
 97%|█████████▋| 754/780 [9:18:44<18:45, 43.28s/it] 97%|█████████▋| 755/780 [9:19:27<18:01, 43.28s/it]                                                   {'loss': 0.3656, 'grad_norm': 0.375, 'learning_rate': 5.769938398662356e-08, 'epoch': 1.93}
 97%|█████████▋| 755/780 [9:19:27<18:01, 43.28s/it] 97%|█████████▋| 756/780 [9:20:10<17:20, 43.34s/it]                                                   {'loss': 0.3803, 'grad_norm': 0.328125, 'learning_rate': 5.3350198867574424e-08, 'epoch': 1.93}
 97%|█████████▋| 756/780 [9:20:10<17:20, 43.34s/it] 97%|█████████▋| 757/780 [9:20:56<16:51, 43.99s/it]                                                   {'loss': 0.3913, 'grad_norm': 4.28125, 'learning_rate': 4.9170974549885844e-08, 'epoch': 1.94}
 97%|█████████▋| 757/780 [9:20:56<16:51, 43.99s/it] 97%|█████████▋| 758/780 [9:21:40<16:08, 44.04s/it]                                                   {'loss': 0.3783, 'grad_norm': 0.294921875, 'learning_rate': 4.516178244497127e-08, 'epoch': 1.94}
 97%|█████████▋| 758/780 [9:21:40<16:08, 44.04s/it] 97%|█████████▋| 759/780 [9:22:24<15:26, 44.13s/it]                                                   {'loss': 0.3788, 'grad_norm': 0.318359375, 'learning_rate': 4.132269105886155e-08, 'epoch': 1.94}
 97%|█████████▋| 759/780 [9:22:24<15:26, 44.13s/it] 97%|█████████▋| 760/780 [9:23:11<15:00, 45.01s/it]                                                   {'loss': 0.3624, 'grad_norm': 0.337890625, 'learning_rate': 3.7653765991035876e-08, 'epoch': 1.94}
 97%|█████████▋| 760/780 [9:23:11<15:00, 45.01s/it] 98%|█████████▊| 761/780 [9:23:56<14:10, 44.75s/it]                                                   {'loss': 0.3546, 'grad_norm': 0.302734375, 'learning_rate': 3.4155069933301535e-08, 'epoch': 1.95}
 98%|█████████▊| 761/780 [9:23:56<14:10, 44.75s/it] 98%|█████████▊| 762/780 [9:24:37<13:08, 43.82s/it]                                                   {'loss': 0.3591, 'grad_norm': 0.30859375, 'learning_rate': 3.082666266872036e-08, 'epoch': 1.95}
 98%|█████████▊| 762/780 [9:24:37<13:08, 43.82s/it] 98%|█████████▊| 763/780 [9:25:23<12:35, 44.46s/it]                                                   {'loss': 0.3667, 'grad_norm': 0.294921875, 'learning_rate': 2.766860107058844e-08, 'epoch': 1.95}
 98%|█████████▊| 763/780 [9:25:23<12:35, 44.46s/it] 98%|█████████▊| 764/780 [9:26:07<11:48, 44.31s/it]                                                   {'loss': 0.3793, 'grad_norm': 0.326171875, 'learning_rate': 2.468093910146685e-08, 'epoch': 1.95}
 98%|█████████▊| 764/780 [9:26:07<11:48, 44.31s/it] 98%|█████████▊| 765/780 [9:26:53<11:09, 44.66s/it]                                                   {'loss': 0.3875, 'grad_norm': 0.29296875, 'learning_rate': 2.1863727812254653e-08, 'epoch': 1.96}
 98%|█████████▊| 765/780 [9:26:53<11:09, 44.66s/it] 98%|█████████▊| 766/780 [9:27:38<10:29, 44.97s/it]                                                   {'loss': 0.3653, 'grad_norm': 0.3125, 'learning_rate': 1.9217015341318478e-08, 'epoch': 1.96}
 98%|█████████▊| 766/780 [9:27:38<10:29, 44.97s/it] 98%|█████████▊| 767/780 [9:28:22<09:38, 44.47s/it]                                                   {'loss': 0.3843, 'grad_norm': 0.357421875, 'learning_rate': 1.674084691367428e-08, 'epoch': 1.96}
 98%|█████████▊| 767/780 [9:28:22<09:38, 44.47s/it] 98%|█████████▊| 768/780 [9:29:04<08:48, 44.01s/it]                                                   {'loss': 0.3969, 'grad_norm': 0.3359375, 'learning_rate': 1.4435264840205742e-08, 'epoch': 1.97}
 98%|█████████▊| 768/780 [9:29:05<08:48, 44.01s/it] 99%|█████████▊| 769/780 [9:29:47<07:58, 43.54s/it]                                                   {'loss': 0.415, 'grad_norm': 0.31640625, 'learning_rate': 1.230030851695263e-08, 'epoch': 1.97}
 99%|█████████▊| 769/780 [9:29:47<07:58, 43.54s/it] 99%|█████████▊| 770/780 [9:30:34<07:24, 44.46s/it]                                                   {'loss': 0.3839, 'grad_norm': 0.3046875, 'learning_rate': 1.0336014424424667e-08, 'epoch': 1.97}
 99%|█████████▊| 770/780 [9:30:34<07:24, 44.46s/it] 99%|█████████▉| 771/780 [9:31:17<06:37, 44.22s/it]                                                   {'loss': 0.3869, 'grad_norm': 0.2890625, 'learning_rate': 8.542416126989805e-09, 'epoch': 1.97}
 99%|█████████▉| 771/780 [9:31:17<06:37, 44.22s/it] 99%|█████████▉| 772/780 [9:32:01<05:53, 44.16s/it]                                                   {'loss': 0.3845, 'grad_norm': 0.314453125, 'learning_rate': 6.919544272293577e-09, 'epoch': 1.98}
 99%|█████████▉| 772/780 [9:32:01<05:53, 44.16s/it] 99%|█████████▉| 773/780 [9:32:48<05:15, 45.07s/it]                                                   {'loss': 0.3355, 'grad_norm': 0.30859375, 'learning_rate': 5.467426590739511e-09, 'epoch': 1.98}
 99%|█████████▉| 773/780 [9:32:48<05:15, 45.07s/it] 99%|█████████▉| 774/780 [9:33:33<04:30, 45.06s/it]                                                   {'loss': 0.3706, 'grad_norm': 0.330078125, 'learning_rate': 4.186087895011737e-09, 'epoch': 1.98}
 99%|█████████▉| 774/780 [9:33:34<04:30, 45.06s/it] 99%|█████████▉| 775/780 [9:34:19<03:45, 45.18s/it]                                                   {'loss': 0.3809, 'grad_norm': 0.353515625, 'learning_rate': 3.0755500796531e-09, 'epoch': 1.98}
 99%|█████████▉| 775/780 [9:34:19<03:45, 45.18s/it] 99%|█████████▉| 776/780 [9:35:02<02:58, 44.70s/it]                                                   {'loss': 0.3714, 'grad_norm': 0.365234375, 'learning_rate': 2.1358321206899067e-09, 'epoch': 1.99}
 99%|█████████▉| 776/780 [9:35:03<02:58, 44.70s/it]100%|█████████▉| 777/780 [9:35:49<02:15, 45.21s/it]                                                   {'loss': 0.3873, 'grad_norm': 0.29296875, 'learning_rate': 1.3669500753099586e-09, 'epoch': 1.99}
100%|█████████▉| 777/780 [9:35:49<02:15, 45.21s/it]100%|█████████▉| 778/780 [9:36:33<01:29, 44.90s/it]                                                   {'loss': 0.3991, 'grad_norm': 0.296875, 'learning_rate': 7.689170815872171e-10, 'epoch': 1.99}
100%|█████████▉| 778/780 [9:36:33<01:29, 44.90s/it]100%|█████████▉| 779/780 [9:37:20<00:45, 45.43s/it]                                                   {'loss': 0.3831, 'grad_norm': 0.90234375, 'learning_rate': 3.4174335825420955e-10, 'epoch': 1.99}
100%|█████████▉| 779/780 [9:37:20<00:45, 45.43s/it]100%|██████████| 780/780 [9:38:03<00:00, 44.81s/it]                                                   {'loss': 0.3785, 'grad_norm': 0.349609375, 'learning_rate': 8.543620453105305e-11, 'epoch': 2.0}
100%|██████████| 780/780 [9:38:03<00:00, 44.81s/it]                                                   {'train_runtime': 34728.0604, 'train_samples_per_second': 5.759, 'train_steps_per_second': 0.022, 'train_loss': 0.40151913945491496, 'epoch': 2.0}
100%|██████████| 780/780 [9:38:48<00:00, 44.81s/it]100%|██████████| 780/780 [9:38:48<00:00, 44.52s/it]
[2025-04-26 19:51:15,136] [INFO] [launch.py:351:main] Process 81340 exits successfully.
