[2025-04-25 21:48:38,247] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-25 21:48:40,018] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0: setting --include=localhost:0
[2025-04-25 21:48:40,018] [INFO] [runner.py:605:main] cmd = /home/staval/anaconda3/envs/llm4decompile/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None finetune.py --model_name_or_path deepseek-ai/deepseek-coder-6.7b-base --data_path /home/staval/LLM4Decompile/train/decompile-asm-llm4decompile-100k-balanced_shuffled.json --output_dir /home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base --num_train_epochs 2 --model_max_length 1024 --per_device_train_batch_size 16 --gradient_accumulation_steps 16 --save_steps 3000 --save_total_limit 100 --learning_rate 2e-5 --max_grad_norm 1.0 --weight_decay 0.1 --warmup_ratio 0.025 --logging_steps 1 --lr_scheduler_type cosine --gradient_checkpointing True --report_to none --fp16 False --bf16 True --fp16_full_eval=False
[2025-04-25 21:48:40,958] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-25 21:48:42,697] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2025-04-25 21:48:42,697] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-04-25 21:48:42,697] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-04-25 21:48:42,697] [INFO] [launch.py:164:main] dist_world_size=1
[2025-04-25 21:48:42,697] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2025-04-25 21:48:42,698] [INFO] [launch.py:256:main] process 75079 spawned with command: ['/home/staval/anaconda3/envs/llm4decompile/bin/python', '-u', 'finetune.py', '--local_rank=0', '--model_name_or_path', 'deepseek-ai/deepseek-coder-6.7b-base', '--data_path', '/home/staval/LLM4Decompile/train/decompile-asm-llm4decompile-100k-balanced_shuffled.json', '--output_dir', '/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base', '--num_train_epochs', '2', '--model_max_length', '1024', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps', '16', '--save_steps', '3000', '--save_total_limit', '100', '--learning_rate', '2e-5', '--max_grad_norm', '1.0', '--weight_decay', '0.1', '--warmup_ratio', '0.025', '--logging_steps', '1', '--lr_scheduler_type', 'cosine', '--gradient_checkpointing', 'True', '--report_to', 'none', '--fp16', 'False', '--bf16', 'True', '--fp16_full_eval=False']
[2025-04-25 21:48:44,539] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
====================================================================================================
TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=16,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base/runs/Apr25_21-48-45_compute03,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
model_max_length=1024,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=2.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=/home/staval/LLM4Decompile/train/output_models/deepseek-coder-6.7b-base,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=3000,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tp_size=0,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.025,
warmup_steps=0,
weight_decay=0.1,
)
PAD Token: <｜end▁of▁sentence｜> 32014
BOS Token <｜begin▁of▁sentence｜> 32013
EOS Token <｜end▁of▁sentence｜> 32014
Load tokenizer from deepseek-ai/deepseek-coder-6.7b-base over.
Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files:  50%|█████     | 1/2 [12:23<12:23, 743.60s/it]Fetching 2 files: 100%|██████████| 2/2 [12:23<00:00, 371.80s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 31.83it/s]
Load model from deepseek-ai/deepseek-coder-6.7b-base over.
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 7809 examples [00:00, 63631.05 examples/s]Generating train split: 18115 examples [00:00, 80445.67 examples/s]Generating train split: 30847 examples [00:00, 89590.40 examples/s]Generating train split: 43861 examples [00:00, 95198.58 examples/s]Generating train split: 56930 examples [00:00, 98490.16 examples/s]Generating train split: 72443 examples [00:00, 100716.18 examples/s]Generating train split: 85290 examples [00:00, 101505.50 examples/s]Generating train split: 100000 examples [00:01, 102478.59 examples/s]Generating train split: 100000 examples [00:01, 97274.20 examples/s] 
Running Encoding (num_proc=32):   0%|          | 0/100000 [00:00<?, ? examples/s]Running Encoding (num_proc=32):   3%|▎         | 3000/100000 [00:21<11:44, 137.70 examples/s]Running Encoding (num_proc=32):   6%|▌         | 6000/100000 [00:21<04:43, 331.96 examples/s]Running Encoding (num_proc=32):   9%|▉         | 9000/100000 [00:22<02:33, 593.69 examples/s]Running Encoding (num_proc=32):  21%|██        | 21000/100000 [00:22<00:38, 2074.32 examples/s]Running Encoding (num_proc=32):  27%|██▋       | 27000/100000 [00:22<00:24, 3034.15 examples/s]Running Encoding (num_proc=32):  33%|███▎      | 33000/100000 [00:22<00:15, 4325.42 examples/s]Running Encoding (num_proc=32):  39%|███▉      | 39000/100000 [00:22<00:10, 6063.38 examples/s]Running Encoding (num_proc=32):  54%|█████▍    | 54125/100000 [00:23<00:03, 12000.00 examples/s]Running Encoding (num_proc=32):  69%|██████▉   | 69250/100000 [00:23<00:01, 19559.83 examples/s]Running Encoding (num_proc=32):  79%|███████▊  | 78625/100000 [00:23<00:00, 22902.84 examples/s]Running Encoding (num_proc=32):  88%|████████▊ | 87875/100000 [00:23<00:00, 27821.76 examples/s]Running Encoding (num_proc=32):  97%|█████████▋| 96875/100000 [00:23<00:00, 32240.40 examples/s]Running Encoding (num_proc=32): 100%|██████████| 100000/100000 [00:25<00:00, 3984.70 examples/s]
Training dataset samples: 100000
Sample 32754 of the training set: [32013, 2, 997, 317, 254, 14664, 2974, 25, 185, 2, 997, 317, 254, 14664, 2974, 25, 185, 27, 897, 7308, 62, 1027, 29, 25, 185, 251, 16, 17, 21, 24, 25, 26435, 18, 207, 15, 69, 207, 16, 68, 3280, 3137, 184, 408, 1645, 21, 19, 207, 185, 251, 16, 17, 21, 67, 25, 184, 20, 20, 1817, 184, 8247, 243, 3018, 15686, 79, 185, 251, 16, 17, 21, 68, 25, 184, 19, 23, 207, 23, 24, 300, 20, 3462, 18299, 872, 315, 3018, 81, 776, 11, 4, 15686, 79, 185, 251, 16, 17, 22, 16, 25, 184, 19, 16, 207, 20, 19, 474, 184, 8247, 243, 3018, 81, 16, 17, 185, 251, 16, 17, 22, 18, 25, 184, 20, 18, 1817, 184, 8247, 243, 3018, 15686, 87, 185, 251, 16, 17, 22, 19, 25, 184, 19, 23, 207, 23, 18, 16174, 207, 17, 15, 3137, 184, 1580, 6128, 15, 87, 17, 15, 11, 4, 81, 776, 185, 251, 16, 17, 22, 23, 25, 184, 19, 23, 207, 23, 24, 207, 22, 67, 263, 23, 3137, 18299, 872, 315, 3018, 6127, 72, 6297, 15, 87, 17, 23, 7, 4, 15686, 79, 8, 185, 251, 16, 17, 22, 66, 25, 184, 19, 23, 207, 23, 24, 207, 22, 20, 263, 15, 3137, 18299, 872, 315, 3018, 3303, 72, 6297, 15, 87, 18, 15, 7, 4, 15686, 79, 8, 185, 251, 16, 17, 23, 15, 25, 23012, 22, 207, 19, 20, 300, 23, 207, 15, 15, 207, 15, 15, 207, 15, 15, 207, 15, 15, 207, 18299, 872, 75, 20097, 15, 87, 15, 6297, 15, 87, 16, 23, 7, 4, 15686, 79, 8, 185, 251, 16, 17, 23, 22, 25, 23012, 22, 207, 19, 20, 16174, 207, 15, 15, 207, 15, 15, 207, 15, 15, 207, 15, 15, 207, 18299, 872, 75, 20097, 15, 87, 15, 6297, 15, 87, 16, 19, 7, 4, 15686, 79, 8, 185, 251, 16, 17, 23, 68, 25, 184, 68, 24, 207, 24, 65, 207, 15, 15, 207, 15, 15, 207, 15, 15, 436, 184, 73, 2782, 251, 16, 18, 17, 68, 1013, 897, 7308, 62, 1027, 10, 15, 25962, 20, 29, 185, 251, 16, 17, 24, 18, 25, 184, 68, 23, 263, 23, 745, 31008, 31008, 436, 184, 4749, 315, 16, 16, 22, 15, 1013, 1437, 296, 768, 62, 65, 62, 2043, 31, 449, 83, 29, 185, 251, 16, 17, 24, 23, 25, 184, 19, 23, 207, 23, 65, 207, 16, 15, 3462, 18299, 872, 315, 334, 4, 401, 87, 650, 4, 6127, 87, 185, 251, 16, 17, 24, 65, 25, 184, 23, 65, 207, 19, 20, 300, 23, 3462, 18299, 872, 315, 567, 15, 87, 16, 23, 7, 4, 15686, 79, 650, 4, 68, 1099, 185, 251, 16, 17, 24, 68, 25, 184, 19, 23, 207, 21, 18, 258, 23, 3462, 18299, 872, 3836, 80, 3018, 68, 1099, 11, 4, 2607, 87, 185, 251, 16, 17, 64, 16, 25, 184, 19, 23, 207, 23, 65, 207, 19, 20, 263, 23, 3137, 18299, 872, 315, 567, 15, 87, 17, 23, 7, 4, 15686, 79, 650, 4, 401, 87, 185, 251, 16, 17, 64, 20, 25, 184, 19, 23, 207, 15, 16, 258, 23, 3462, 184, 1761, 315, 3018, 2607, 87, 11, 4, 401, 87, 185, 251, 16, 17, 64, 23, 25, 184, 15, 69, 270, 21, 207, 15, 15, 3462, 18299, 872, 89, 1638, 334, 4, 401, 87, 650, 4, 68, 1099, 185, 251, 16, 17, 356, 25, 184, 19, 23, 207, 15, 69, 330, 258, 15, 3137, 18299, 872, 24872, 80, 3018, 266, 11, 4, 401, 87, 185, 251, 16, 17, 2623, 25, 184, 19, 23, 207, 15, 16, 258, 15, 3462, 184, 1761, 315, 3018, 401, 87, 11, 4, 401, 87, 185, 251, 16, 17, 65, 17, 25, 184, 19, 23, 207, 15, 16, 263, 15, 3462, 184, 1761, 315, 3018, 6127, 87, 11, 4, 401, 87, 185, 251, 16, 17, 65, 20, 25, 184, 15, 69, 270, 22, 207, 15, 15, 3462, 18299, 872, 89, 13443, 334, 4, 401, 87, 650, 4, 68, 1099, 185, 251, 16, 17, 65, 23, 25, 184, 15, 69, 270, 22, 258, 15, 3462, 18299, 872, 89, 13443, 3018, 1099, 11, 4, 68, 1099, 185, 251, 16, 17, 7890, 25, 184, 17, 20, 207, 15, 15, 207, 15, 19, 207, 15, 15, 207, 15, 15, 436, 184, 384, 6128, 15, 87, 19, 15, 15, 11, 4, 68, 1099, 185, 251, 16, 17, 66, 15, 25, 184, 23, 20, 258, 15, 474, 184, 2806, 243, 3018, 68, 1099, 11, 4, 68, 1099, 185, 251, 16, 17, 66, 17, 25, 184, 22, 19, 207, 21, 21, 474, 184, 9009, 730, 16, 18, 17, 64, 1013, 897, 7308, 62, 1027, 10, 15, 25962, 16, 29, 185, 251, 16, 17, 66, 19, 25, 184, 23, 65, 207, 19, 20, 300, 23, 3462, 18299, 872, 315, 567, 15, 87, 16, 23, 7, 4, 15686, 79, 650, 4, 68, 1099, 185, 251, 16, 17, 66, 22, 25, 184, 19, 23, 207, 21, 18, 263, 15, 3462, 18299, 872, 3836, 80, 3018, 68, 1099, 11, 4, 6127, 87, 185, 251, 16, 17, 4591, 25, 184, 19, 23, 207, 23, 65, 207, 19, 20, 263, 23, 3137, 18299, 872, 315, 567, 15, 87, 17, 23, 7, 4, 15686, 79, 650, 4, 401, 87, 185, 251, 16, 17, 347, 25, 184, 19, 23, 207, 15, 16, 263, 15, 3462, 184, 1761, 315, 3018, 6127, 87, 11, 4, 401, 87, 185, 251, 16, 17, 67, 16, 25, 184, 15, 69, 270, 21, 207, 15, 15, 3462, 18299, 872, 89, 1638, 334, 4, 401, 87, 650, 4, 68, 1099, 185, 251, 16, 17, 67, 19, 25, 184, 15, 69, 330, 258, 15, 3462, 18299, 872, 82, 1638, 3018, 266, 11, 4, 68, 1099, 185, 251, 16, 17, 67, 22, 25, 184, 23, 24, 258, 22, 474, 18299, 872, 315, 3018, 68, 1099, 11, 4, 271, 72, 185, 251, 16, 17, 67, 24, 25, 184, 68, 23, 207, 22, 17, 745, 31008, 31008, 436, 184, 4749, 315, 16, 16, 20, 15, 1013, 83, 313, 1173, 31, 449, 83, 29, 185, 251, 16, 17, 581, 25, 184, 19, 16, 207, 23, 24, 258, 19, 3462], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100].
Sample 32754 of the training set: <｜begin▁of▁sentence｜># This is the assembly code:
# This is the assembly code:
<encrypt_line>:
    1269:	f3 0f 1e fa          	endbr64 
    126d:	55                   	push   %rbp
    126e:	48 89 e5             	mov    %rsp,%rbp
    1271:	41 54                	push   %r12
    1273:	53                   	push   %rbx
    1274:	48 83 ec 20          	sub    $0x20,%rsp
    1278:	48 89 7d d8          	mov    %rdi,-0x28(%rbp)
    127c:	48 89 75 d0          	mov    %rsi,-0x30(%rbp)
    1280:	c7 45 e8 00 00 00 00 	movl   $0x0,-0x18(%rbp)
    1287:	c7 45 ec 00 00 00 00 	movl   $0x0,-0x14(%rbp)
    128e:	e9 9b 00 00 00       	jmp    132e <encrypt_line+0xc5>
    1293:	e8 d8 fe ff ff       	call   1170 <__ctype_b_loc@plt>
    1298:	48 8b 10             	mov    (%rax),%rdx
    129b:	8b 45 e8             	mov    -0x18(%rbp),%eax
    129e:	48 63 c8             	movslq %eax,%rcx
    12a1:	48 8b 45 d8          	mov    -0x28(%rbp),%rax
    12a5:	48 01 c8             	add    %rcx,%rax
    12a8:	0f b6 00             	movzbl (%rax),%eax
    12ab:	48 0f be c0          	movsbq %al,%rax
    12af:	48 01 c0             	add    %rax,%rax
    12b2:	48 01 d0             	add    %rdx,%rax
    12b5:	0f b7 00             	movzwl (%rax),%eax
    12b8:	0f b7 c0             	movzwl %ax,%eax
    12bb:	25 00 04 00 00       	and    $0x400,%eax
    12c0:	85 c0                	test   %eax,%eax
    12c2:	74 66                	je     132a <encrypt_line+0xc1>
    12c4:	8b 45 e8             	mov    -0x18(%rbp),%eax
    12c7:	48 63 d0             	movslq %eax,%rdx
    12ca:	48 8b 45 d8          	mov    -0x28(%rbp),%rax
    12ce:	48 01 d0             	add    %rdx,%rax
    12d1:	0f b6 00             	movzbl (%rax),%eax
    12d4:	0f be c0             	movsbl %al,%eax
    12d7:	89 c7                	mov    %eax,%edi
    12d9:	e8 72 fe ff ff       	call   1150 <tolower@plt>
    12de:	41 89 c4             .
Sample 53405 of the training set: [32013, 2, 997, 317, 254, 14664, 2974, 25, 185, 2, 997, 317, 254, 14664, 2974, 25, 185, 27, 1761, 13484, 29, 25, 185, 251, 16, 20, 15, 15, 25, 26435, 18, 207, 15, 69, 207, 16, 68, 3280, 3137, 184, 408, 1645, 21, 19, 207, 185, 251, 16, 20, 15, 19, 25, 184, 20, 20, 1817, 184, 8247, 243, 3018, 15686, 79, 185, 251, 16, 20, 15, 20, 25, 184, 19, 23, 207, 23, 67, 207, 18, 20, 267, 23, 207, 15, 64, 207, 15, 15, 207, 15, 15, 207, 184, 275, 64, 251, 15, 87, 2623, 23, 7, 4, 2772, 650, 4, 3303, 72, 436, 1494, 207, 17, 15, 15, 19, 1013, 62, 6860, 62, 8387, 246, 62, 4504, 10, 15, 87, 19, 29, 185, 251, 16, 20, 15, 66, 25, 184, 2161, 207, 15, 16, 207, 15, 15, 207, 15, 15, 207, 15, 15, 436, 18299, 872, 6128, 15, 87, 16, 11, 4, 271, 72, 185, 251, 16, 20, 16, 16, 25, 184, 19, 23, 207, 23, 67, 207, 17, 67, 207, 15, 21, 207, 15, 65, 207, 15, 15, 207, 15, 15, 207, 184, 275, 64, 251, 15, 87, 65, 15, 21, 7, 4, 2772, 650, 4, 15686, 79, 436, 1494, 207, 17, 15, 16, 68, 1013, 62, 6860, 62, 8387, 246, 62, 4504, 10, 15, 87, 16, 68, 29, 185, 251, 16, 20, 16, 23, 25, 184, 19, 23, 207, 23, 18, 16174, 207, 18, 15, 3137, 184, 1580, 6128, 15, 87, 18, 15, 11, 4, 81, 776, 185, 251, 16, 20, 16, 66, 25, 184, 21, 19, 207, 19, 23, 207, 23, 65, 207, 15, 19, 207, 17, 20, 207, 17, 23, 207, 15, 15, 207, 18299, 872, 315, 3018, 5538, 25, 15, 87, 17, 23, 11, 4, 401, 87, 185, 251, 16, 20, 17, 18, 25, 184, 15, 15, 207, 15, 15, 207, 185, 251, 16, 20, 17, 20, 25, 184, 19, 23, 207, 23, 24, 207, 19, 19, 207, 17, 19, 207, 17, 23, 436, 18299, 872, 315, 3018, 401, 87, 11, 15, 87, 17, 23, 7, 4, 81, 776, 8, 185, 251, 16, 20, 17, 64, 25, 184, 18, 16, 258, 15, 474, 184, 87, 256, 315, 3018, 68, 1099, 11, 4, 68, 1099, 185, 251, 16, 20, 17, 66, 25, 184, 68, 23, 207, 18, 69, 267, 66, 31008, 31008, 436, 184, 4749, 315, 16, 16, 22, 15, 1013, 1437, 17186, 62, 358, 74, 31, 449, 83, 29, 185, 251, 16, 20, 18, 16, 25, 184, 19, 23, 207, 23, 24, 300, 21, 3462, 18299, 872, 315, 3018, 81, 776, 11, 4, 3303, 72, 185, 251, 16, 20, 18, 19, 25, 184, 19, 23, 207, 23, 24, 30960, 3462, 18299, 872, 315, 3018, 15686, 79, 11, 4, 6127, 72, 185, 251, 16, 20, 18, 22, 25, 184, 18, 16, 258, 15, 474, 184, 87, 256, 315, 3018, 68, 1099, 11, 4, 68, 1099, 185, 251, 16, 20, 18, 24, 25, 184, 68, 23, 207, 21, 17, 267, 66, 31008, 31008, 436, 184, 4749, 315, 16, 16, 64, 15, 1013, 1437, 262, 404, 24, 24, 62, 21619, 69, 31, 449, 83, 29, 185, 251, 16, 20, 18, 68, 25, 184, 19, 23, 207, 23, 67, 207, 18, 20, 263, 66, 207, 15, 64, 207, 15, 15, 207, 15, 15, 207, 184, 275, 64, 251, 15, 87, 307, 66, 7, 4, 2772, 650, 4, 3303, 72, 436, 1494, 207, 17, 15, 17, 16, 1013, 62, 6860, 62, 8387, 246, 62, 4504, 10, 15, 87, 17, 16, 29, 185, 251, 16, 20, 19, 20, 25, 184, 2161, 207, 15, 16, 207, 15, 15, 207, 15, 15, 207, 15, 15, 436, 18299, 872, 6128, 15, 87, 16, 11, 4, 271, 72, 185, 251, 16, 20, 19, 64, 25, 184, 18, 16, 258, 15, 474, 184, 87, 256, 315, 3018, 68, 1099, 11, 4, 68, 1099, 185, 251, 16, 20, 19, 66, 25, 184, 68, 23, 207, 16, 69, 267, 66, 31008, 31008, 436, 184, 4749, 315, 16, 16, 22, 15, 1013, 1437, 17186, 62, 358, 74, 31, 449, 83, 29, 185, 251, 16, 20, 20, 16, 25, 184, 19, 23, 207, 23, 67, 207, 22, 19, 207, 17, 19, 207, 15, 66, 436, 184, 275, 64, 251, 15, 25962, 7, 4, 81, 776, 650, 4, 3303, 72, 185, 251, 16, 20, 20, 21, 25, 184, 19, 23, 207, 23, 67, 207, 18, 67, 263, 18, 207, 15, 64, 207, 15, 15, 207, 15, 15, 207, 184, 275, 64, 251, 15, 87, 307, 18, 7, 4, 2772, 650, 4, 6127, 72, 436, 1494, 207, 17, 15, 18, 15, 1013, 62, 6860, 62, 8387, 246, 62, 4504, 10, 15, 87, 18, 15, 29, 185, 251, 16, 20, 20, 67, 25, 184, 18, 16, 258, 15, 474, 184, 87, 256, 315, 3018, 68, 1099, 11, 4, 68, 1099, 185, 251, 16, 20, 20, 69, 25, 184, 68, 23, 207, 18, 66, 267, 66, 31008, 31008, 436, 184, 4749, 315, 16, 16, 64, 15, 1013, 1437, 262, 404, 24, 24, 62, 21619, 69, 31, 449, 83, 29, 185, 251, 16, 20, 21, 19, 25, 184, 19, 23, 207, 23, 67, 207, 18, 20, 258, 23, 207, 15, 64, 207, 15, 15, 207, 15, 15, 207, 184, 275, 64, 251, 15, 87, 305, 23, 7, 4, 2772, 650, 4, 3303, 72, 436, 1494, 207, 17, 15, 18, 18, 1013, 62, 6860, 62, 8387, 246, 62, 4504, 10, 15, 87, 18, 18, 29, 185, 251, 16, 20, 21, 65, 25, 184, 2161, 207, 15, 16, 207, 15, 15, 207, 15, 15, 207, 15, 15, 436, 18299, 872, 6128, 15, 87, 16, 11, 4, 271, 72, 185, 251, 16, 20, 22, 15, 25, 184, 18, 16, 258, 15, 474, 184, 87, 256, 315, 3018, 68, 1099, 11, 4, 68, 1099, 185, 251, 16, 20, 22, 17, 25, 184, 68, 23, 267, 24, 267, 65, 31008, 31008, 436, 184, 4749, 315, 16, 16, 22, 15, 1013, 1437, 17186, 62, 358, 74, 31, 449, 83, 29, 185, 251, 16, 20, 22, 22, 25, 184, 19, 23, 207, 23, 24, 30960, 3462, 18299, 872, 315, 3018, 15686, 79, 11, 4, 6127, 72, 185, 251, 16, 20, 22, 64, 25], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100].
Sample 53405 of the training set: <｜begin▁of▁sentence｜># This is the assembly code:
# This is the assembly code:
<addRecord>:
    1500:	f3 0f 1e fa          	endbr64 
    1504:	55                   	push   %rbp
    1505:	48 8d 35 f8 0a 00 00 	lea    0xaf8(%rip),%rsi        # 2004 <_IO_stdin_used+0x4>
    150c:	bf 01 00 00 00       	mov    $0x1,%edi
    1511:	48 8d 2d 06 0b 00 00 	lea    0xb06(%rip),%rbp        # 201e <_IO_stdin_used+0x1e>
    1518:	48 83 ec 30          	sub    $0x30,%rsp
    151c:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    1523:	00 00 
    1525:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    152a:	31 c0                	xor    %eax,%eax
    152c:	e8 3f fc ff ff       	call   1170 <__printf_chk@plt>
    1531:	48 89 e6             	mov    %rsp,%rsi
    1534:	48 89 ef             	mov    %rbp,%rdi
    1537:	31 c0                	xor    %eax,%eax
    1539:	e8 62 fc ff ff       	call   11a0 <__isoc99_scanf@plt>
    153e:	48 8d 35 dc 0a 00 00 	lea    0xadc(%rip),%rsi        # 2021 <_IO_stdin_used+0x21>
    1545:	bf 01 00 00 00       	mov    $0x1,%edi
    154a:	31 c0                	xor    %eax,%eax
    154c:	e8 1f fc ff ff       	call   1170 <__printf_chk@plt>
    1551:	48 8d 74 24 0c       	lea    0xc(%rsp),%rsi
    1556:	48 8d 3d d3 0a 00 00 	lea    0xad3(%rip),%rdi        # 2030 <_IO_stdin_used+0x30>
    155d:	31 c0                	xor    %eax,%eax
    155f:	e8 3c fc ff ff       	call   11a0 <__isoc99_scanf@plt>
    1564:	48 8d 35 c8 0a 00 00 	lea    0xac8(%rip),%rsi        # 2033 <_IO_stdin_used+0x33>
    156b:	bf 01 00 00 00       	mov    $0x1,%edi
    1570:	31 c0                	xor    %eax,%eax
    1572:	e8 f9 fb ff ff       	call   1170 <__printf_chk@plt>
    1577:	48 89 ef             	mov    %rbp,%rdi
    157a:.
Sample 145 of the training set: [32013, 2, 997, 317, 254, 14664, 2974, 25, 185, 2, 997, 317, 254, 14664, 2974, 25, 185, 27, 10221, 1889, 8061, 29, 25, 185, 251, 16, 18, 23, 15, 25, 26435, 18, 207, 15, 69, 207, 16, 68, 3280, 3137, 184, 408, 1645, 21, 19, 207, 185, 251, 16, 18, 23, 19, 25, 184, 23, 18, 31008, 207, 15, 24, 3462, 23012, 2782, 6128, 15, 87, 24, 11, 4, 271, 72, 185, 251, 16, 18, 23, 22, 25, 184, 22, 21, 207, 16, 22, 474, 184, 73, 1338, 251, 16, 18, 64, 15, 1013, 10221, 1889, 8061, 10, 15, 87, 17, 15, 29, 185, 251, 16, 18, 23, 24, 25, 184, 23, 67, 207, 19, 22, 267, 21, 3462, 184, 275, 64, 315, 567, 15, 7287, 7, 4, 6127, 72, 650, 4, 68, 1099, 185, 251, 16, 18, 23, 66, 25, 184, 23, 18, 258, 22, 207, 18, 22, 3462, 184, 1761, 6128, 15, 87, 18, 22, 11, 4, 271, 72, 185, 251, 16, 18, 23, 69, 25, 184, 23, 18, 267, 23, 207, 15, 21, 3462, 23012, 2782, 6128, 15, 87, 21, 11, 4, 68, 1099, 185, 251, 16, 18, 24, 17, 25, 184, 65, 23, 207, 17, 15, 207, 15, 15, 207, 15, 15, 207, 15, 15, 436, 18299, 872, 6128, 15, 87, 17, 15, 11, 4, 68, 1099, 185, 251, 16, 18, 24, 22, 25, 184, 15, 69, 207, 19, 17, 258, 22, 3462, 184, 3203, 872, 65, 207, 3018, 271, 72, 11, 4, 68, 1099, 185, 251, 16, 18, 24, 64, 25, 23012, 18, 1817, 184, 2534, 251, 185, 251, 16, 18, 24, 65, 25, 184, 15, 69, 207, 16, 69, 207, 19, 19, 207, 15, 15, 207, 15, 15, 436, 184, 77, 9493, 315, 15, 87, 15, 7, 4, 401, 87, 11, 4, 401, 87, 11, 16, 8, 185, 251, 16, 18, 64, 15, 25, 184, 23, 67, 207, 19, 22, 207, 18, 15, 3462, 184, 275, 64, 251, 15, 87, 18, 15, 7, 4, 6127, 72, 650, 4, 68, 1099, 185, 251, 16, 18, 64, 18, 25, 23012, 18, 1817, 184, 2534, 251, 185, 251, 16, 18, 64, 19, 25, 184, 21, 21, 207, 21, 21, 207, 17, 68, 207, 15, 69, 207, 16, 69, 207, 23, 19, 207, 15, 15, 207, 184, 2448, 16, 21, 258, 82, 291, 424, 86, 207, 15, 87, 15, 7, 4, 401, 87, 11, 4, 401, 87, 11, 16, 8, 185, 251, 16, 18, 356, 25, 184, 15, 15, 207, 15, 15, 207, 15, 15, 207, 15, 15, 207, 185, 251, 16, 18, 2623, 25, 184, 24, 15, 1817, 184, 77, 424, 185, 185, 185, 2, 2450, 317, 254, 3117, 2974, 30, 185, 185, 2, 2450, 317, 254, 3117, 2974, 30, 185, 5897, 1450, 1889, 8061, 7, 569, 263, 8, 185, 90, 185, 315, 562, 7, 67, 25057, 15, 2956, 263, 27, 28, 24, 8, 185, 436, 967, 263, 10, 6, 15, 4057, 185, 315, 1969, 562, 7, 67, 25057, 16, 15, 2956, 263, 27, 28, 16, 20, 8, 185, 436, 967, 263, 12, 16, 15, 10, 6, 32, 4057, 185, 315, 1969, 185, 436, 967, 651, 651, 26, 185, 92, 185, 185, 32014], [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5897, 1450, 1889, 8061, 7, 569, 263, 8, 185, 90, 185, 315, 562, 7, 67, 25057, 15, 2956, 263, 27, 28, 24, 8, 185, 436, 967, 263, 10, 6, 15, 4057, 185, 315, 1969, 562, 7, 67, 25057, 16, 15, 2956, 263, 27, 28, 16, 20, 8, 185, 436, 967, 263, 12, 16, 15, 10, 6, 32, 4057, 185, 315, 1969, 185, 436, 967, 651, 651, 26, 185, 92, 185, 185, 32014].
Sample 145 of the training set: <｜begin▁of▁sentence｜># This is the assembly code:
# This is the assembly code:
<decToChar>:
    1380:	f3 0f 1e fa          	endbr64 
    1384:	83 ff 09             	cmp    $0x9,%edi
    1387:	76 17                	jbe    13a0 <decToChar+0x20>
    1389:	8d 47 f6             	lea    -0xa(%rdi),%eax
    138c:	83 c7 37             	add    $0x37,%edi
    138f:	83 f8 06             	cmp    $0x6,%eax
    1392:	b8 20 00 00 00       	mov    $0x20,%eax
    1397:	0f 42 c7             	cmovb  %edi,%eax
    139a:	c3                   	ret    
    139b:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
    13a0:	8d 47 30             	lea    0x30(%rdi),%eax
    13a3:	c3                   	ret    
    13a4:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    13ab:	00 00 00 00 
    13af:	90                   	nop


# What is the source code?

# What is the source code?
char decToChar(int d)
{
    if(d>=0 && d<=9)
        return d+'0';
    else if(d>=10 && d<=15)
        return d-10+'A';
    else
        return ' ';
}

<｜end▁of▁sentence｜>.
/home/staval/LLM4Decompile/train/finetune.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
  0%|          | 0/780 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 1/780 [00:53<11:40:51, 53.98s/it]                                                  {'loss': 0.509, 'grad_norm': 2.5625, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/780 [00:54<11:40:51, 53.98s/it]  0%|          | 2/780 [01:48<11:41:34, 54.11s/it]                                                  {'loss': 0.4856, 'grad_norm': 2.453125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}
  0%|          | 2/780 [01:48<11:41:34, 54.11s/it]  0%|          | 3/780 [02:42<11:41:26, 54.17s/it]                                                  {'loss': 0.5543, 'grad_norm': 2.546875, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
  0%|          | 3/780 [02:42<11:41:26, 54.17s/it]  1%|          | 4/780 [03:36<11:40:39, 54.18s/it]                                                  {'loss': 0.4856, 'grad_norm': 2.484375, 'learning_rate': 3e-06, 'epoch': 0.01}
  1%|          | 4/780 [03:36<11:40:39, 54.18s/it]  1%|          | 5/780 [04:30<11:40:15, 54.21s/it]                                                  {'loss': 0.5078, 'grad_norm': 2.4375, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 5/780 [04:30<11:40:15, 54.21s/it]  1%|          | 6/780 [05:25<11:39:55, 54.26s/it]                                                  {'loss': 0.4915, 'grad_norm': 2.609375, 'learning_rate': 5e-06, 'epoch': 0.02}
  1%|          | 6/780 [05:25<11:39:55, 54.26s/it]  1%|          | 7/780 [06:19<11:38:55, 54.25s/it]                                                  {'loss': 0.5165, 'grad_norm': 2.4375, 'learning_rate': 6e-06, 'epoch': 0.02}
  1%|          | 7/780 [06:19<11:38:55, 54.25s/it]  1%|          | 8/780 [07:13<11:38:27, 54.28s/it]                                                  {'loss': 0.4309, 'grad_norm': 2.453125, 'learning_rate': 7e-06, 'epoch': 0.02}
  1%|          | 8/780 [07:13<11:38:27, 54.28s/it]  1%|          | 9/780 [08:08<11:38:03, 54.32s/it]                                                  {'loss': 0.4244, 'grad_norm': 2.109375, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}
  1%|          | 9/780 [08:08<11:38:03, 54.32s/it]  1%|▏         | 10/780 [09:02<11:37:00, 54.31s/it]                                                   {'loss': 0.3995, 'grad_norm': 1.6796875, 'learning_rate': 9e-06, 'epoch': 0.03}
  1%|▏         | 10/780 [09:02<11:37:00, 54.31s/it]  1%|▏         | 11/780 [09:56<11:35:47, 54.29s/it]                                                   {'loss': 0.3893, 'grad_norm': 1.2421875, 'learning_rate': 1e-05, 'epoch': 0.03}
  1%|▏         | 11/780 [09:56<11:35:47, 54.29s/it]  2%|▏         | 12/780 [10:50<11:34:33, 54.26s/it]                                                   {'loss': 0.415, 'grad_norm': 1.0546875, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.03}
  2%|▏         | 12/780 [10:51<11:34:33, 54.26s/it]  2%|▏         | 13/780 [11:45<11:33:16, 54.23s/it]                                                   {'loss': 0.3977, 'grad_norm': 0.9296875, 'learning_rate': 1.2e-05, 'epoch': 0.03}
  2%|▏         | 13/780 [11:45<11:33:16, 54.23s/it]  2%|▏         | 14/780 [12:39<11:32:59, 54.28s/it]                                                   {'loss': 0.3485, 'grad_norm': 0.7734375, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.04}
  2%|▏         | 14/780 [12:39<11:32:59, 54.28s/it]  2%|▏         | 15/780 [13:33<11:32:24, 54.31s/it]                                                   {'loss': 0.3659, 'grad_norm': 0.83984375, 'learning_rate': 1.4e-05, 'epoch': 0.04}
  2%|▏         | 15/780 [13:33<11:32:24, 54.31s/it]  2%|▏         | 16/780 [14:28<11:31:36, 54.31s/it]                                                   {'loss': 0.3131, 'grad_norm': 0.6953125, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.04}
  2%|▏         | 16/780 [14:28<11:31:36, 54.31s/it]  2%|▏         | 17/780 [15:22<11:30:36, 54.31s/it]                                                   {'loss': 0.3229, 'grad_norm': 0.640625, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.04}
  2%|▏         | 17/780 [15:22<11:30:36, 54.31s/it]  2%|▏         | 18/780 [16:16<11:29:31, 54.29s/it]                                                   {'loss': 0.3579, 'grad_norm': 0.6953125, 'learning_rate': 1.7e-05, 'epoch': 0.05}
  2%|▏         | 18/780 [16:16<11:29:31, 54.29s/it]  2%|▏         | 19/780 [17:11<11:29:01, 54.33s/it]                                                   {'loss': 0.2904, 'grad_norm': 0.5390625, 'learning_rate': 1.8e-05, 'epoch': 0.05}
  2%|▏         | 19/780 [17:11<11:29:01, 54.33s/it]  3%|▎         | 20/780 [18:05<11:28:06, 54.32s/it]                                                   {'loss': 0.315, 'grad_norm': 0.6171875, 'learning_rate': 1.9e-05, 'epoch': 0.05}
  3%|▎         | 20/780 [18:05<11:28:06, 54.32s/it]  3%|▎         | 21/780 [18:59<11:26:49, 54.29s/it]                                                   {'loss': 0.3048, 'grad_norm': 0.65625, 'learning_rate': 2e-05, 'epoch': 0.05}
  3%|▎         | 21/780 [18:59<11:26:49, 54.29s/it]  3%|▎         | 22/780 [19:53<11:25:22, 54.25s/it]                                                   {'loss': 0.3335, 'grad_norm': 0.640625, 'learning_rate': 1.999991456379547e-05, 'epoch': 0.06}
  3%|▎         | 22/780 [19:53<11:25:22, 54.25s/it]  3%|▎         | 23/780 [20:48<11:24:18, 54.24s/it]                                                   {'loss': 0.3582, 'grad_norm': 0.546875, 'learning_rate': 1.9999658256641746e-05, 'epoch': 0.06}
  3%|▎         | 23/780 [20:48<11:24:18, 54.24s/it]  3%|▎         | 24/780 [21:42<11:23:39, 54.26s/it]                                                   {'loss': 0.321, 'grad_norm': 0.52734375, 'learning_rate': 1.9999231082918415e-05, 'epoch': 0.06}
  3%|▎         | 24/780 [21:42<11:23:39, 54.26s/it]  3%|▎         | 25/780 [22:36<11:22:21, 54.23s/it]                                                   {'loss': 0.2827, 'grad_norm': 0.59375, 'learning_rate': 1.9998633049924693e-05, 'epoch': 0.06}
  3%|▎         | 25/780 [22:36<11:22:21, 54.23s/it]  3%|▎         | 26/780 [23:30<11:21:41, 54.25s/it]                                                   {'loss': 0.2869, 'grad_norm': 0.59765625, 'learning_rate': 1.9997864167879313e-05, 'epoch': 0.07}
  3%|▎         | 26/780 [23:30<11:21:41, 54.25s/it]  3%|▎         | 27/780 [24:24<11:20:26, 54.22s/it]                                                   {'loss': 0.3363, 'grad_norm': 0.55078125, 'learning_rate': 1.999692444992035e-05, 'epoch': 0.07}
  3%|▎         | 27/780 [24:25<11:20:26, 54.22s/it]  4%|▎         | 28/780 [25:19<11:19:40, 54.23s/it]                                                   {'loss': 0.3293, 'grad_norm': 0.6328125, 'learning_rate': 1.9995813912104988e-05, 'epoch': 0.07}
  4%|▎         | 28/780 [25:19<11:19:40, 54.23s/it]  4%|▎         | 29/780 [26:13<11:18:41, 54.22s/it]                                                   {'loss': 0.3206, 'grad_norm': 0.54296875, 'learning_rate': 1.999453257340926e-05, 'epoch': 0.07}
  4%|▎         | 29/780 [26:13<11:18:41, 54.22s/it]  4%|▍         | 30/780 [27:07<11:18:00, 54.24s/it]                                                   {'loss': 0.3604, 'grad_norm': 0.6796875, 'learning_rate': 1.9993080455727705e-05, 'epoch': 0.08}
  4%|▍         | 30/780 [27:07<11:18:00, 54.24s/it]  4%|▍         | 31/780 [28:02<11:17:28, 54.27s/it]                                                   {'loss': 0.3337, 'grad_norm': 0.57421875, 'learning_rate': 1.999145758387301e-05, 'epoch': 0.08}
  4%|▍         | 31/780 [28:02<11:17:28, 54.27s/it]  4%|▍         | 32/780 [28:56<11:16:11, 54.24s/it]                                                   {'loss': 0.3299, 'grad_norm': 0.58984375, 'learning_rate': 1.9989663985575575e-05, 'epoch': 0.08}
  4%|▍         | 32/780 [28:56<11:16:11, 54.24s/it]  4%|▍         | 33/780 [29:50<11:15:34, 54.26s/it]                                                   {'loss': 0.3396, 'grad_norm': 0.55859375, 'learning_rate': 1.998769969148305e-05, 'epoch': 0.08}
  4%|▍         | 33/780 [29:50<11:15:34, 54.26s/it]  4%|▍         | 34/780 [30:44<11:14:59, 54.29s/it]                                                   {'loss': 0.3213, 'grad_norm': 0.59765625, 'learning_rate': 1.9985564735159796e-05, 'epoch': 0.09}
  4%|▍         | 34/780 [30:44<11:14:59, 54.29s/it]  4%|▍         | 35/780 [31:39<11:13:46, 54.26s/it]                                                   {'loss': 0.2687, 'grad_norm': 0.53125, 'learning_rate': 1.9983259153086328e-05, 'epoch': 0.09}
  4%|▍         | 35/780 [31:39<11:13:46, 54.26s/it]  5%|▍         | 36/780 [32:33<11:13:12, 54.29s/it]                                                   {'loss': 0.2631, 'grad_norm': 0.5234375, 'learning_rate': 1.9980782984658682e-05, 'epoch': 0.09}
  5%|▍         | 36/780 [32:33<11:13:12, 54.29s/it]  5%|▍         | 37/780 [33:27<11:12:43, 54.32s/it]                                                   {'loss': 0.2797, 'grad_norm': 0.5234375, 'learning_rate': 1.9978136272187745e-05, 'epoch': 0.09}
  5%|▍         | 37/780 [33:27<11:12:43, 54.32s/it]  5%|▍         | 38/780 [34:22<11:11:36, 54.31s/it]                                                   {'loss': 0.2768, 'grad_norm': 0.5390625, 'learning_rate': 1.9975319060898535e-05, 'epoch': 0.1}
  5%|▍         | 38/780 [34:22<11:11:36, 54.31s/it]  5%|▌         | 39/780 [35:16<11:10:38, 54.30s/it]                                                   {'loss': 0.2904, 'grad_norm': 0.625, 'learning_rate': 1.997233139892941e-05, 'epoch': 0.1}
  5%|▌         | 39/780 [35:16<11:10:38, 54.30s/it]  5%|▌         | 40/780 [36:10<11:09:21, 54.27s/it]                                                   {'loss': 0.2845, 'grad_norm': 0.5078125, 'learning_rate': 1.9969173337331283e-05, 'epoch': 0.1}
  5%|▌         | 40/780 [36:10<11:09:21, 54.27s/it]  5%|▌         | 41/780 [37:04<11:07:55, 54.23s/it]                                                   {'loss': 0.2665, 'grad_norm': 0.5859375, 'learning_rate': 1.99658449300667e-05, 'epoch': 0.1}
  5%|▌         | 41/780 [37:04<11:07:55, 54.23s/it]  5%|▌         | 42/780 [37:58<11:06:48, 54.21s/it]                                                   {'loss': 0.2753, 'grad_norm': 0.55859375, 'learning_rate': 1.996234623400897e-05, 'epoch': 0.11}
  5%|▌         | 42/780 [37:58<11:06:48, 54.21s/it]  6%|▌         | 43/780 [38:53<11:06:07, 54.23s/it]                                                   {'loss': 0.3384, 'grad_norm': 0.55859375, 'learning_rate': 1.995867730894114e-05, 'epoch': 0.11}
  6%|▌         | 43/780 [38:53<11:06:07, 54.23s/it]  6%|▌         | 44/780 [39:47<11:05:02, 54.22s/it]                                                   {'loss': 0.266, 'grad_norm': 0.5, 'learning_rate': 1.995483821755503e-05, 'epoch': 0.11}
  6%|▌         | 44/780 [39:47<11:05:02, 54.22s/it]  6%|▌         | 45/780 [40:41<11:03:51, 54.19s/it]                                                   {'loss': 0.3623, 'grad_norm': 0.59375, 'learning_rate': 1.9950829025450116e-05, 'epoch': 0.12}
  6%|▌         | 45/780 [40:41<11:03:51, 54.19s/it]  6%|▌         | 46/780 [41:35<11:03:09, 54.21s/it]                                                   {'loss': 0.2925, 'grad_norm': 0.515625, 'learning_rate': 1.994664980113243e-05, 'epoch': 0.12}
  6%|▌         | 46/780 [41:35<11:03:09, 54.21s/it]  6%|▌         | 47/780 [42:30<11:02:37, 54.24s/it]                                                   {'loss': 0.2716, 'grad_norm': 0.490234375, 'learning_rate': 1.9942300616013378e-05, 'epoch': 0.12}
  6%|▌         | 47/780 [42:30<11:02:37, 54.24s/it]  6%|▌         | 48/780 [43:24<11:01:16, 54.20s/it]                                                   {'loss': 0.2742, 'grad_norm': 0.515625, 'learning_rate': 1.993778154440854e-05, 'epoch': 0.12}
  6%|▌         | 48/780 [43:24<11:01:16, 54.20s/it]  6%|▋         | 49/780 [44:18<10:59:45, 54.15s/it]                                                   {'loss': 0.3088, 'grad_norm': 0.53515625, 'learning_rate': 1.9933092663536384e-05, 'epoch': 0.13}
  6%|▋         | 49/780 [44:18<10:59:45, 54.15s/it]  6%|▋         | 50/780 [45:12<10:59:02, 54.17s/it]                                                   {'loss': 0.2993, 'grad_norm': 0.4609375, 'learning_rate': 1.992823405351694e-05, 'epoch': 0.13}
  6%|▋         | 50/780 [45:12<10:59:02, 54.17s/it]  7%|▋         | 51/780 [46:06<10:58:36, 54.21s/it]                                                   {'loss': 0.2872, 'grad_norm': 0.47265625, 'learning_rate': 1.992320579737045e-05, 'epoch': 0.13}
  7%|▋         | 51/780 [46:06<10:58:36, 54.21s/it]  7%|▋         | 52/780 [47:00<10:57:34, 54.20s/it]                                                   {'loss': 0.3551, 'grad_norm': 0.51953125, 'learning_rate': 1.9918007981015942e-05, 'epoch': 0.13}
  7%|▋         | 52/780 [47:00<10:57:34, 54.20s/it]  7%|▋         | 53/780 [47:55<10:56:43, 54.20s/it]                                                   {'loss': 0.2844, 'grad_norm': 0.494140625, 'learning_rate': 1.9912640693269754e-05, 'epoch': 0.14}
  7%|▋         | 53/780 [47:55<10:56:43, 54.20s/it]  7%|▋         | 54/780 [48:49<10:56:09, 54.23s/it]                                                   {'loss': 0.2598, 'grad_norm': 0.484375, 'learning_rate': 1.9907104025844024e-05, 'epoch': 0.14}
  7%|▋         | 54/780 [48:49<10:56:09, 54.23s/it]  7%|▋         | 55/780 [49:43<10:54:53, 54.20s/it]                                                   {'loss': 0.2664, 'grad_norm': 0.51171875, 'learning_rate': 1.990139807334512e-05, 'epoch': 0.14}
  7%|▋         | 55/780 [49:43<10:54:53, 54.20s/it]  7%|▋         | 56/780 [50:37<10:54:07, 54.21s/it]                                                   {'loss': 0.2668, 'grad_norm': 0.57421875, 'learning_rate': 1.9895522933272028e-05, 'epoch': 0.14}
  7%|▋         | 56/780 [50:37<10:54:07, 54.21s/it]  7%|▋         | 57/780 [51:31<10:53:07, 54.20s/it]                                                   {'loss': 0.2885, 'grad_norm': 0.5234375, 'learning_rate': 1.9889478706014687e-05, 'epoch': 0.15}
  7%|▋         | 57/780 [51:31<10:53:07, 54.20s/it]  7%|▋         | 58/780 [52:26<10:52:25, 54.22s/it]                                                   {'loss': 0.2702, 'grad_norm': 0.55078125, 'learning_rate': 1.9883265494852258e-05, 'epoch': 0.15}
  7%|▋         | 58/780 [52:26<10:52:25, 54.22s/it]  8%|▊         | 59/780 [53:20<10:51:52, 54.25s/it]                                                   {'loss': 0.3109, 'grad_norm': 0.5234375, 'learning_rate': 1.9876883405951378e-05, 'epoch': 0.15}
  8%|▊         | 59/780 [53:20<10:51:52, 54.25s/it]  8%|▊         | 60/780 [54:14<10:50:57, 54.25s/it]                                                   {'loss': 0.2652, 'grad_norm': 0.51171875, 'learning_rate': 1.9870332548364342e-05, 'epoch': 0.15}
  8%|▊         | 60/780 [54:14<10:50:57, 54.25s/it]  8%|▊         | 61/780 [55:08<10:49:46, 54.22s/it]                                                   {'loss': 0.3054, 'grad_norm': 0.546875, 'learning_rate': 1.9863613034027224e-05, 'epoch': 0.16}
  8%|▊         | 61/780 [55:08<10:49:46, 54.22s/it]  8%|▊         | 62/780 [56:03<10:49:30, 54.28s/it]                                                   {'loss': 0.2915, 'grad_norm': 2.484375, 'learning_rate': 1.9856724977757993e-05, 'epoch': 0.16}
  8%|▊         | 62/780 [56:03<10:49:30, 54.28s/it]  8%|▊         | 63/780 [56:57<10:48:22, 54.26s/it]                                                   {'loss': 0.2954, 'grad_norm': 0.54296875, 'learning_rate': 1.984966849725452e-05, 'epoch': 0.16}
  8%|▊         | 63/780 [56:57<10:48:22, 54.26s/it]  8%|▊         | 64/780 [57:51<10:47:49, 54.29s/it]                                                   {'loss': 0.3036, 'grad_norm': 0.51953125, 'learning_rate': 1.984244371309259e-05, 'epoch': 0.16}
  8%|▊         | 64/780 [57:51<10:47:49, 54.29s/it]  8%|▊         | 65/780 [58:46<10:47:41, 54.35s/it]                                                   {'loss': 0.2809, 'grad_norm': 0.49609375, 'learning_rate': 1.9835050748723826e-05, 'epoch': 0.17}
  8%|▊         | 65/780 [58:46<10:47:41, 54.35s/it]  8%|▊         | 66/780 [59:40<10:46:10, 54.30s/it]                                                   {'loss': 0.2901, 'grad_norm': 0.55859375, 'learning_rate': 1.9827489730473597e-05, 'epoch': 0.17}
  8%|▊         | 66/780 [59:40<10:46:10, 54.30s/it]  9%|▊         | 67/780 [1:00:34<10:45:18, 54.30s/it]                                                     {'loss': 0.276, 'grad_norm': 0.498046875, 'learning_rate': 1.981976078753884e-05, 'epoch': 0.17}
  9%|▊         | 67/780 [1:00:34<10:45:18, 54.30s/it]  9%|▊         | 68/780 [1:01:29<10:44:06, 54.28s/it]                                                     {'loss': 0.2665, 'grad_norm': 0.6015625, 'learning_rate': 1.9811864051985865e-05, 'epoch': 0.17}
  9%|▊         | 68/780 [1:01:29<10:44:06, 54.28s/it]  9%|▉         | 69/780 [1:02:23<10:43:16, 54.28s/it]                                                     {'loss': 0.2258, 'grad_norm': 0.515625, 'learning_rate': 1.9803799658748096e-05, 'epoch': 0.18}
  9%|▉         | 69/780 [1:02:23<10:43:16, 54.28s/it]  9%|▉         | 70/780 [1:03:17<10:42:20, 54.28s/it]                                                     {'loss': 0.2948, 'grad_norm': 0.4921875, 'learning_rate': 1.979556774562376e-05, 'epoch': 0.18}
  9%|▉         | 70/780 [1:03:17<10:42:20, 54.28s/it]  9%|▉         | 71/780 [1:04:12<10:41:34, 54.29s/it]                                                     {'loss': 0.2232, 'grad_norm': 0.51171875, 'learning_rate': 1.9787168453273546e-05, 'epoch': 0.18}
  9%|▉         | 71/780 [1:04:12<10:41:34, 54.29s/it]  9%|▉         | 72/780 [1:05:06<10:40:38, 54.29s/it]                                                     {'loss': 0.2792, 'grad_norm': 0.53515625, 'learning_rate': 1.977860192521818e-05, 'epoch': 0.18}
  9%|▉         | 72/780 [1:05:06<10:40:38, 54.29s/it]  9%|▉         | 73/780 [1:06:00<10:39:30, 54.27s/it]                                                     {'loss': 0.2724, 'grad_norm': 0.56640625, 'learning_rate': 1.9769868307835996e-05, 'epoch': 0.19}
  9%|▉         | 73/780 [1:06:00<10:39:30, 54.27s/it]  9%|▉         | 74/780 [1:06:54<10:38:28, 54.26s/it]                                                     {'loss': 0.25, 'grad_norm': 0.51171875, 'learning_rate': 1.976096775036041e-05, 'epoch': 0.19}
  9%|▉         | 74/780 [1:06:54<10:38:28, 54.26s/it] 10%|▉         | 75/780 [1:07:48<10:37:29, 54.25s/it]                                                     {'loss': 0.2521, 'grad_norm': 0.51171875, 'learning_rate': 1.97519004048774e-05, 'epoch': 0.19}
 10%|▉         | 75/780 [1:07:49<10:37:29, 54.25s/it] 10%|▉         | 76/780 [1:08:43<10:36:30, 54.25s/it]                                                     {'loss': 0.2514, 'grad_norm': 0.5078125, 'learning_rate': 1.9742666426322877e-05, 'epoch': 0.19}
 10%|▉         | 76/780 [1:08:43<10:36:30, 54.25s/it] 10%|▉         | 77/780 [1:09:37<10:36:07, 54.29s/it]                                                     {'loss': 0.3014, 'grad_norm': 0.49609375, 'learning_rate': 1.973326597248006e-05, 'epoch': 0.2}
 10%|▉         | 77/780 [1:09:37<10:36:07, 54.29s/it] 10%|█         | 78/780 [1:10:31<10:35:01, 54.28s/it]                                                     {'loss': 0.2808, 'grad_norm': 0.50390625, 'learning_rate': 1.9723699203976768e-05, 'epoch': 0.2}
 10%|█         | 78/780 [1:10:31<10:35:01, 54.28s/it] 10%|█         | 79/780 [1:11:26<10:34:17, 54.29s/it]                                                     {'loss': 0.2667, 'grad_norm': 0.5546875, 'learning_rate': 1.9713966284282677e-05, 'epoch': 0.2}
 10%|█         | 79/780 [1:11:26<10:34:17, 54.29s/it] 10%|█         | 80/780 [1:12:20<10:32:59, 54.26s/it]                                                     {'loss': 0.2653, 'grad_norm': 0.57421875, 'learning_rate': 1.9704067379706537e-05, 'epoch': 0.2}
 10%|█         | 80/780 [1:12:20<10:32:59, 54.26s/it] 10%|█         | 81/780 [1:13:14<10:32:11, 54.27s/it]                                                     {'loss': 0.2902, 'grad_norm': 0.53515625, 'learning_rate': 1.9694002659393306e-05, 'epoch': 0.21}
 10%|█         | 81/780 [1:13:14<10:32:11, 54.27s/it] 11%|█         | 82/780 [1:14:09<10:31:44, 54.31s/it]                                                     {'loss': 0.2989, 'grad_norm': 0.5, 'learning_rate': 1.968377229532129e-05, 'epoch': 0.21}
 11%|█         | 82/780 [1:14:09<10:31:44, 54.31s/it] 11%|█         | 83/780 [1:15:03<10:30:22, 54.26s/it]                                                     {'loss': 0.2493, 'grad_norm': 0.5703125, 'learning_rate': 1.9673376462299186e-05, 'epoch': 0.21}
 11%|█         | 83/780 [1:15:03<10:30:22, 54.26s/it] 11%|█         | 84/780 [1:15:57<10:29:47, 54.29s/it]                                                     {'loss': 0.2974, 'grad_norm': 0.482421875, 'learning_rate': 1.9662815337963092e-05, 'epoch': 0.22}
 11%|█         | 84/780 [1:15:57<10:29:47, 54.29s/it] 11%|█         | 85/780 [1:16:51<10:29:05, 54.31s/it]                                                     {'loss': 0.3039, 'grad_norm': 0.5546875, 'learning_rate': 1.9652089102773487e-05, 'epoch': 0.22}
 11%|█         | 85/780 [1:16:51<10:29:05, 54.31s/it] 11%|█         | 86/780 [1:17:46<10:28:36, 54.35s/it]                                                     {'loss': 0.2765, 'grad_norm': 0.474609375, 'learning_rate': 1.9641197940012136e-05, 'epoch': 0.22}
 11%|█         | 86/780 [1:17:46<10:28:36, 54.35s/it] 11%|█         | 87/780 [1:18:40<10:27:34, 54.34s/it]                                                     {'loss': 0.2546, 'grad_norm': 0.4375, 'learning_rate': 1.963014203577896e-05, 'epoch': 0.22}
 11%|█         | 87/780 [1:18:40<10:27:34, 54.34s/it] 11%|█▏        | 88/780 [1:19:34<10:26:34, 54.33s/it]                                                     {'loss': 0.2595, 'grad_norm': 0.486328125, 'learning_rate': 1.9618921578988863e-05, 'epoch': 0.23}
 11%|█▏        | 88/780 [1:19:35<10:26:34, 54.33s/it] 11%|█▏        | 89/780 [1:20:29<10:25:12, 54.29s/it]                                                     {'loss': 0.3141, 'grad_norm': 0.6328125, 'learning_rate': 1.9607536761368484e-05, 'epoch': 0.23}
 11%|█▏        | 89/780 [1:20:29<10:25:12, 54.29s/it] 12%|█▏        | 90/780 [1:21:23<10:24:37, 54.32s/it]                                                     {'loss': 0.2599, 'grad_norm': 0.490234375, 'learning_rate': 1.9595987777452946e-05, 'epoch': 0.23}
 12%|█▏        | 90/780 [1:21:23<10:24:37, 54.32s/it] 12%|█▏        | 91/780 [1:22:17<10:23:21, 54.28s/it]                                                     {'loss': 0.304, 'grad_norm': 0.5, 'learning_rate': 1.958427482458253e-05, 'epoch': 0.23}
 12%|█▏        | 91/780 [1:22:17<10:23:21, 54.28s/it] 12%|█▏        | 92/780 [1:23:12<10:23:06, 54.34s/it]                                                     {'loss': 0.2623, 'grad_norm': 0.484375, 'learning_rate': 1.957239810289927e-05, 'epoch': 0.24}
 12%|█▏        | 92/780 [1:23:12<10:23:06, 54.34s/it] 12%|█▏        | 93/780 [1:24:06<10:22:09, 54.34s/it]                                                     {'loss': 0.2299, 'grad_norm': 0.51171875, 'learning_rate': 1.9560357815343577e-05, 'epoch': 0.24}
 12%|█▏        | 93/780 [1:24:06<10:22:09, 54.34s/it] 12%|█▏        | 94/780 [1:25:00<10:21:01, 54.32s/it]                                                     {'loss': 0.2827, 'grad_norm': 0.53515625, 'learning_rate': 1.9548154167650746e-05, 'epoch': 0.24}
 12%|█▏        | 94/780 [1:25:00<10:21:01, 54.32s/it] 12%|█▏        | 95/780 [1:25:55<10:20:21, 54.34s/it]                                                     {'loss': 0.2697, 'grad_norm': 0.486328125, 'learning_rate': 1.9535787368347444e-05, 'epoch': 0.24}
 12%|█▏        | 95/780 [1:25:55<10:20:21, 54.34s/it] 12%|█▏        | 96/780 [1:26:49<10:18:53, 54.29s/it]                                                     {'loss': 0.2617, 'grad_norm': 0.70703125, 'learning_rate': 1.9523257628748148e-05, 'epoch': 0.25}
 12%|█▏        | 96/780 [1:26:49<10:18:53, 54.29s/it] 12%|█▏        | 97/780 [1:27:43<10:17:26, 54.24s/it]                                                     {'loss': 0.294, 'grad_norm': 0.55078125, 'learning_rate': 1.9510565162951538e-05, 'epoch': 0.25}
 12%|█▏        | 97/780 [1:27:43<10:17:26, 54.24s/it] 13%|█▎        | 98/780 [1:28:37<10:16:30, 54.24s/it]                                                     {'loss': 0.2481, 'grad_norm': 0.474609375, 'learning_rate': 1.9497710187836832e-05, 'epoch': 0.25}
 13%|█▎        | 98/780 [1:28:37<10:16:30, 54.24s/it] 13%|█▎        | 99/780 [1:29:31<10:15:16, 54.21s/it]                                                     {'loss': 0.2741, 'grad_norm': 0.55078125, 'learning_rate': 1.9484692923060095e-05, 'epoch': 0.25}
 13%|█▎        | 99/780 [1:29:31<10:15:16, 54.21s/it] 13%|█▎        | 100/780 [1:30:26<10:14:34, 54.23s/it]                                                      {'loss': 0.3017, 'grad_norm': 0.53515625, 'learning_rate': 1.947151359105046e-05, 'epoch': 0.26}
 13%|█▎        | 100/780 [1:30:26<10:14:34, 54.23s/it] 13%|█▎        | 101/780 [1:31:20<10:13:11, 54.18s/it]                                                      {'loss': 0.2237, 'grad_norm': 0.546875, 'learning_rate': 1.9458172417006347e-05, 'epoch': 0.26}
 13%|█▎        | 101/780 [1:31:20<10:13:11, 54.18s/it] 13%|█▎        | 102/780 [1:32:14<10:12:17, 54.19s/it]                                                      {'loss': 0.274, 'grad_norm': 0.5, 'learning_rate': 1.9444669628891618e-05, 'epoch': 0.26}
 13%|█▎        | 102/780 [1:32:14<10:12:17, 54.19s/it] 13%|█▎        | 103/780 [1:33:08<10:11:08, 54.16s/it]                                                      {'loss': 0.2778, 'grad_norm': 0.5625, 'learning_rate': 1.9431005457431654e-05, 'epoch': 0.26}
 13%|█▎        | 103/780 [1:33:08<10:11:08, 54.16s/it] 13%|█▎        | 104/780 [1:34:02<10:10:16, 54.17s/it]                                                      {'loss': 0.2717, 'grad_norm': 0.5859375, 'learning_rate': 1.9417180136109456e-05, 'epoch': 0.27}
 13%|█▎        | 104/780 [1:34:02<10:10:16, 54.17s/it] 13%|█▎        | 105/780 [1:34:56<10:09:22, 54.17s/it]                                                      {'loss': 0.2586, 'grad_norm': 0.51171875, 'learning_rate': 1.9403193901161614e-05, 'epoch': 0.27}
 13%|█▎        | 105/780 [1:34:56<10:09:22, 54.17s/it] 14%|█▎        | 106/780 [1:35:51<10:08:44, 54.19s/it]                                                      {'loss': 0.2366, 'grad_norm': 0.453125, 'learning_rate': 1.9389046991574298e-05, 'epoch': 0.27}
 14%|█▎        | 106/780 [1:35:51<10:08:44, 54.19s/it] 14%|█▎        | 107/780 [1:36:45<10:07:43, 54.18s/it]                                                      {'loss': 0.3099, 'grad_norm': 0.58984375, 'learning_rate': 1.9374739649079155e-05, 'epoch': 0.27}
 14%|█▎        | 107/780 [1:36:45<10:07:43, 54.18s/it] 14%|█▍        | 108/780 [1:37:39<10:06:44, 54.17s/it]                                                      {'loss': 0.2279, 'grad_norm': 0.54296875, 'learning_rate': 1.9360272118149195e-05, 'epoch': 0.28}
 14%|█▍        | 108/780 [1:37:39<10:06:44, 54.17s/it] 14%|█▍        | 109/780 [1:38:33<10:05:38, 54.16s/it]                                                      {'loss': 0.2671, 'grad_norm': 0.57421875, 'learning_rate': 1.934564464599461e-05, 'epoch': 0.28}
 14%|█▍        | 109/780 [1:38:33<10:05:38, 54.16s/it] 14%|█▍        | 110/780 [1:39:27<10:04:19, 54.12s/it]                                                      {'loss': 0.2556, 'grad_norm': 0.5546875, 'learning_rate': 1.9330857482558533e-05, 'epoch': 0.28}
 14%|█▍        | 110/780 [1:39:27<10:04:19, 54.12s/it] 14%|█▍        | 111/780 [1:40:21<10:03:44, 54.15s/it]                                                      {'loss': 0.2391, 'grad_norm': 0.484375, 'learning_rate': 1.9315910880512792e-05, 'epoch': 0.28}
 14%|█▍        | 111/780 [1:40:21<10:03:44, 54.15s/it] 14%|█▍        | 112/780 [1:41:16<10:03:15, 54.19s/it]                                                      {'loss': 0.265, 'grad_norm': 0.53515625, 'learning_rate': 1.9300805095253575e-05, 'epoch': 0.29}
 14%|█▍        | 112/780 [1:41:16<10:03:15, 54.19s/it] 14%|█▍        | 113/780 [1:42:10<10:02:46, 54.22s/it]                                                      {'loss': 0.2397, 'grad_norm': 0.5234375, 'learning_rate': 1.9285540384897073e-05, 'epoch': 0.29}
 14%|█▍        | 113/780 [1:42:10<10:02:46, 54.22s/it] 15%|█▍        | 114/780 [1:43:04<10:02:09, 54.25s/it]                                                      {'loss': 0.2405, 'grad_norm': 0.50390625, 'learning_rate': 1.9270117010275072e-05, 'epoch': 0.29}
 15%|█▍        | 114/780 [1:43:04<10:02:09, 54.25s/it] 15%|█▍        | 115/780 [1:43:58<10:01:14, 54.25s/it]                                                      {'loss': 0.2856, 'grad_norm': 0.62890625, 'learning_rate': 1.9254535234930486e-05, 'epoch': 0.29}
 15%|█▍        | 115/780 [1:43:59<10:01:14, 54.25s/it] 15%|█▍        | 116/780 [1:44:53<10:00:15, 54.24s/it]                                                      {'loss': 0.3104, 'grad_norm': 0.59375, 'learning_rate': 1.9238795325112867e-05, 'epoch': 0.3}
 15%|█▍        | 116/780 [1:44:53<10:00:15, 54.24s/it] 15%|█▌        | 117/780 [1:45:47<9:59:40, 54.27s/it]                                                      {'loss': 0.2552, 'grad_norm': 0.52734375, 'learning_rate': 1.922289754977385e-05, 'epoch': 0.3}
 15%|█▌        | 117/780 [1:45:47<9:59:40, 54.27s/it] 15%|█▌        | 118/780 [1:46:41<9:58:50, 54.28s/it]                                                     {'loss': 0.2732, 'grad_norm': 0.4921875, 'learning_rate': 1.920684218056254e-05, 'epoch': 0.3}
 15%|█▌        | 118/780 [1:46:41<9:58:50, 54.28s/it] 15%|█▌        | 119/780 [1:47:36<9:57:53, 54.27s/it]                                                     {'loss': 0.216, 'grad_norm': 0.50390625, 'learning_rate': 1.919062949182091e-05, 'epoch': 0.3}
 15%|█▌        | 119/780 [1:47:36<9:57:53, 54.27s/it] 15%|█▌        | 120/780 [1:48:30<9:57:29, 54.32s/it]                                                     {'loss': 0.2434, 'grad_norm': 0.5, 'learning_rate': 1.9174259760579078e-05, 'epoch': 0.31}
 15%|█▌        | 120/780 [1:48:30<9:57:29, 54.32s/it] 16%|█▌        | 121/780 [1:49:24<9:56:56, 54.35s/it]                                                     {'loss': 0.2359, 'grad_norm': 0.53125, 'learning_rate': 1.9157733266550577e-05, 'epoch': 0.31}
 16%|█▌        | 121/780 [1:49:24<9:56:56, 54.35s/it] 16%|█▌        | 122/780 [1:50:19<9:56:13, 54.37s/it]                                                     {'loss': 0.2832, 'grad_norm': 0.515625, 'learning_rate': 1.9141050292127598e-05, 'epoch': 0.31}
 16%|█▌        | 122/780 [1:50:19<9:56:13, 54.37s/it] 16%|█▌        | 123/780 [1:51:13<9:55:16, 54.36s/it]                                                     {'loss': 0.2633, 'grad_norm': 0.53515625, 'learning_rate': 1.9124211122376138e-05, 'epoch': 0.31}
 16%|█▌        | 123/780 [1:51:13<9:55:16, 54.36s/it] 16%|█▌        | 124/780 [1:52:08<9:54:33, 54.38s/it]                                                     {'loss': 0.2037, 'grad_norm': 0.42578125, 'learning_rate': 1.9107216045031154e-05, 'epoch': 0.32}
 16%|█▌        | 124/780 [1:52:08<9:54:33, 54.38s/it] 16%|█▌        | 125/780 [1:53:02<9:53:12, 54.34s/it]                                                     {'loss': 0.2571, 'grad_norm': 0.53125, 'learning_rate': 1.909006535049163e-05, 'epoch': 0.32}
 16%|█▌        | 125/780 [1:53:02<9:53:12, 54.34s/it] 16%|█▌        | 126/780 [1:53:56<9:52:07, 54.32s/it]                                                     {'loss': 0.2273, 'grad_norm': 0.51171875, 'learning_rate': 1.9072759331815602e-05, 'epoch': 0.32}
 16%|█▌        | 126/780 [1:53:56<9:52:07, 54.32s/it] 16%|█▋        | 127/780 [1:54:50<9:51:07, 54.31s/it]                                                     {'loss': 0.2767, 'grad_norm': 0.53125, 'learning_rate': 1.9055298284715192e-05, 'epoch': 0.33}
 16%|█▋        | 127/780 [1:54:50<9:51:07, 54.31s/it] 16%|█▋        | 128/780 [1:55:44<9:49:16, 54.23s/it]                                                     {'loss': 0.2716, 'grad_norm': 0.640625, 'learning_rate': 1.903768250755151e-05, 'epoch': 0.33}
 16%|█▋        | 128/780 [1:55:44<9:49:16, 54.23s/it] 17%|█▋        | 129/780 [1:56:39<9:47:59, 54.19s/it]                                                     {'loss': 0.2796, 'grad_norm': 0.56640625, 'learning_rate': 1.9019912301329593e-05, 'epoch': 0.33}
 17%|█▋        | 129/780 [1:56:39<9:47:59, 54.19s/it] 17%|█▋        | 130/780 [1:57:33<9:47:07, 54.20s/it]                                                     {'loss': 0.2564, 'grad_norm': 0.546875, 'learning_rate': 1.9001987969693228e-05, 'epoch': 0.33}
 17%|█▋        | 130/780 [1:57:33<9:47:07, 54.20s/it] 17%|█▋        | 131/780 [1:58:27<9:45:54, 54.17s/it]                                                     {'loss': 0.2469, 'grad_norm': 0.55078125, 'learning_rate': 1.898390981891979e-05, 'epoch': 0.34}
 17%|█▋        | 131/780 [1:58:27<9:45:54, 54.17s/it] 17%|█▋        | 132/780 [1:59:21<9:44:56, 54.16s/it]                                                     {'loss': 0.2566, 'grad_norm': 0.58203125, 'learning_rate': 1.8965678157915e-05, 'epoch': 0.34}
 17%|█▋        | 132/780 [1:59:21<9:44:56, 54.16s/it] 17%|█▋        | 133/780 [2:00:15<9:44:11, 54.18s/it]                                                     {'loss': 0.2601, 'grad_norm': 0.515625, 'learning_rate': 1.8947293298207637e-05, 'epoch': 0.34}
 17%|█▋        | 133/780 [2:00:15<9:44:11, 54.18s/it] 17%|█▋        | 134/780 [2:01:09<9:42:58, 54.15s/it]                                                     {'loss': 0.2365, 'grad_norm': 0.54296875, 'learning_rate': 1.892875555394423e-05, 'epoch': 0.34}
 17%|█▋        | 134/780 [2:01:09<9:42:58, 54.15s/it] 17%|█▋        | 135/780 [2:02:04<9:42:21, 54.17s/it]                                                     {'loss': 0.2667, 'grad_norm': 0.5625, 'learning_rate': 1.891006524188368e-05, 'epoch': 0.35}
 17%|█▋        | 135/780 [2:02:04<9:42:21, 54.17s/it] 17%|█▋        | 136/780 [2:02:58<9:41:27, 54.17s/it]                                                     {'loss': 0.2619, 'grad_norm': 0.56640625, 'learning_rate': 1.8891222681391853e-05, 'epoch': 0.35}
 17%|█▋        | 136/780 [2:02:58<9:41:27, 54.17s/it] 18%|█▊        | 137/780 [2:03:52<9:41:02, 54.22s/it]                                                     {'loss': 0.2698, 'grad_norm': 0.6015625, 'learning_rate': 1.887222819443612e-05, 'epoch': 0.35}
 18%|█▊        | 137/780 [2:03:52<9:41:02, 54.22s/it] 18%|█▊        | 138/780 [2:04:46<9:40:10, 54.22s/it]                                                     {'loss': 0.2882, 'grad_norm': 0.55078125, 'learning_rate': 1.8853082105579853e-05, 'epoch': 0.35}
 18%|█▊        | 138/780 [2:04:46<9:40:10, 54.22s/it] 18%|█▊        | 139/780 [2:05:40<9:39:20, 54.23s/it]                                                     {'loss': 0.2398, 'grad_norm': 0.53125, 'learning_rate': 1.883378474197689e-05, 'epoch': 0.36}
 18%|█▊        | 139/780 [2:05:41<9:39:20, 54.23s/it] 18%|█▊        | 140/780 [2:06:35<9:38:52, 54.27s/it]                                                     {'loss': 0.2244, 'grad_norm': 0.46875, 'learning_rate': 1.8814336433365924e-05, 'epoch': 0.36}
 18%|█▊        | 140/780 [2:06:35<9:38:52, 54.27s/it] 18%|█▊        | 141/780 [2:07:29<9:37:45, 54.25s/it]                                                     {'loss': 0.2532, 'grad_norm': 0.51953125, 'learning_rate': 1.879473751206489e-05, 'epoch': 0.36}
 18%|█▊        | 141/780 [2:07:29<9:37:45, 54.25s/it] 18%|█▊        | 142/780 [2:08:23<9:37:05, 54.27s/it]                                                     {'loss': 0.2701, 'grad_norm': 0.5, 'learning_rate': 1.8774988312965287e-05, 'epoch': 0.36}
 18%|█▊        | 142/780 [2:08:23<9:37:05, 54.27s/it] 18%|█▊        | 143/780 [2:09:17<9:34:42, 54.13s/it]                                                     {'loss': 0.288, 'grad_norm': 0.55859375, 'learning_rate': 1.875508917352643e-05, 'epoch': 0.37}
 18%|█▊        | 143/780 [2:09:17<9:34:42, 54.13s/it] 18%|█▊        | 144/780 [2:10:11<9:34:01, 54.15s/it]                                                     {'loss': 0.2457, 'grad_norm': 0.53515625, 'learning_rate': 1.873504043376971e-05, 'epoch': 0.37}
 18%|█▊        | 144/780 [2:10:11<9:34:01, 54.15s/it] 19%|█▊        | 145/780 [2:11:06<9:33:15, 54.17s/it]                                                     {'loss': 0.3044, 'grad_norm': 0.5390625, 'learning_rate': 1.8714842436272774e-05, 'epoch': 0.37}
 19%|█▊        | 145/780 [2:11:06<9:33:15, 54.17s/it] 19%|█▊        | 146/780 [2:12:00<9:32:48, 54.21s/it]                                                     {'loss': 0.2422, 'grad_norm': 0.5234375, 'learning_rate': 1.869449552616367e-05, 'epoch': 0.37}
 19%|█▊        | 146/780 [2:12:00<9:32:48, 54.21s/it] 19%|█▉        | 147/780 [2:12:54<9:32:18, 54.25s/it]                                                     {'loss': 0.2929, 'grad_norm': 0.5, 'learning_rate': 1.8674000051114953e-05, 'epoch': 0.38}
 19%|█▉        | 147/780 [2:12:54<9:32:18, 54.25s/it] 19%|█▉        | 148/780 [2:13:49<9:31:58, 54.30s/it]                                                     {'loss': 0.2507, 'grad_norm': 0.53125, 'learning_rate': 1.8653356361337743e-05, 'epoch': 0.38}
 19%|█▉        | 148/780 [2:13:49<9:31:58, 54.30s/it] 19%|█▉        | 149/780 [2:14:43<9:30:39, 54.26s/it]                                                     {'loss': 0.204, 'grad_norm': 0.52734375, 'learning_rate': 1.863256480957574e-05, 'epoch': 0.38}
 19%|█▉        | 149/780 [2:14:43<9:30:39, 54.26s/it] 19%|█▉        | 150/780 [2:15:37<9:29:49, 54.27s/it]                                                     {'loss': 0.2575, 'grad_norm': 0.53125, 'learning_rate': 1.8611625751099197e-05, 'epoch': 0.38}
 19%|█▉        | 150/780 [2:15:37<9:29:49, 54.27s/it] 19%|█▉        | 151/780 [2:16:31<9:28:09, 54.20s/it]                                                     {'loss': 0.234, 'grad_norm': 0.455078125, 'learning_rate': 1.8590539543698852e-05, 'epoch': 0.39}
 19%|█▉        | 151/780 [2:16:31<9:28:09, 54.20s/it] 19%|█▉        | 152/780 [2:17:26<9:28:08, 54.28s/it]                                                     {'loss': 0.2796, 'grad_norm': 0.474609375, 'learning_rate': 1.856930654767981e-05, 'epoch': 0.39}
 19%|█▉        | 152/780 [2:17:26<9:28:08, 54.28s/it] 20%|█▉        | 153/780 [2:18:20<9:27:26, 54.30s/it]                                                     {'loss': 0.2565, 'grad_norm': 0.5234375, 'learning_rate': 1.854792712585539e-05, 'epoch': 0.39}
 20%|█▉        | 153/780 [2:18:20<9:27:26, 54.30s/it] 20%|█▉        | 154/780 [2:19:14<9:27:02, 54.35s/it]                                                     {'loss': 0.2688, 'grad_norm': 0.494140625, 'learning_rate': 1.8526401643540924e-05, 'epoch': 0.39}
 20%|█▉        | 154/780 [2:19:14<9:27:02, 54.35s/it] 20%|█▉        | 155/780 [2:20:09<9:25:41, 54.31s/it]                                                     {'loss': 0.2645, 'grad_norm': 0.59375, 'learning_rate': 1.8504730468547508e-05, 'epoch': 0.4}
 20%|█▉        | 155/780 [2:20:09<9:25:41, 54.31s/it] 20%|██        | 156/780 [2:21:03<9:24:47, 54.31s/it]                                                     {'loss': 0.2475, 'grad_norm': 0.55859375, 'learning_rate': 1.8482913971175737e-05, 'epoch': 0.4}
 20%|██        | 156/780 [2:21:03<9:24:47, 54.31s/it] 20%|██        | 157/780 [2:21:57<9:24:11, 54.34s/it]                                                     {'loss': 0.2496, 'grad_norm': 0.49609375, 'learning_rate': 1.8460952524209355e-05, 'epoch': 0.4}
 20%|██        | 157/780 [2:21:57<9:24:11, 54.34s/it] 20%|██        | 158/780 [2:22:52<9:23:15, 54.33s/it]                                                     {'loss': 0.2908, 'grad_norm': 0.5546875, 'learning_rate': 1.8438846502908895e-05, 'epoch': 0.4}
 20%|██        | 158/780 [2:22:52<9:23:15, 54.33s/it] 20%|██        | 159/780 [2:23:46<9:21:20, 54.24s/it]                                                     {'loss': 0.2732, 'grad_norm': 0.5859375, 'learning_rate': 1.8416596285005274e-05, 'epoch': 0.41}
 20%|██        | 159/780 [2:23:46<9:21:20, 54.24s/it] 21%|██        | 160/780 [2:24:40<9:20:11, 54.21s/it]                                                     {'loss': 0.2602, 'grad_norm': 0.58203125, 'learning_rate': 1.8394202250693315e-05, 'epoch': 0.41}
 21%|██        | 160/780 [2:24:40<9:20:11, 54.21s/it] 21%|██        | 161/780 [2:25:34<9:19:05, 54.19s/it]                                                     {'loss': 0.2463, 'grad_norm': 0.52734375, 'learning_rate': 1.8371664782625287e-05, 'epoch': 0.41}
 21%|██        | 161/780 [2:25:34<9:19:05, 54.19s/it] 21%|██        | 162/780 [2:26:28<9:18:00, 54.18s/it]                                                     {'loss': 0.2483, 'grad_norm': 0.50390625, 'learning_rate': 1.8348984265904333e-05, 'epoch': 0.41}
 21%|██        | 162/780 [2:26:28<9:18:00, 54.18s/it] 21%|██        | 163/780 [2:27:22<9:16:54, 54.16s/it]                                                     {'loss': 0.2845, 'grad_norm': 0.57421875, 'learning_rate': 1.8326161088077905e-05, 'epoch': 0.42}
 21%|██        | 163/780 [2:27:22<9:16:54, 54.16s/it] 21%|██        | 164/780 [2:28:17<9:16:36, 54.22s/it]                                                     {'loss': 0.2385, 'grad_norm': 0.486328125, 'learning_rate': 1.830319563913114e-05, 'epoch': 0.42}
 21%|██        | 164/780 [2:28:17<9:16:36, 54.22s/it] 21%|██        | 165/780 [2:29:11<9:15:48, 54.23s/it]                                                     {'loss': 0.2941, 'grad_norm': 0.55859375, 'learning_rate': 1.8280088311480203e-05, 'epoch': 0.42}
 21%|██        | 165/780 [2:29:11<9:15:48, 54.23s/it] 21%|██▏       | 166/780 [2:30:05<9:14:22, 54.17s/it]                                                     {'loss': 0.2632, 'grad_norm': 0.59375, 'learning_rate': 1.825683949996556e-05, 'epoch': 0.42}
 21%|██▏       | 166/780 [2:30:05<9:14:22, 54.17s/it] 21%|██▏       | 167/780 [2:30:59<9:13:47, 54.20s/it]                                                     {'loss': 0.3049, 'grad_norm': 0.54296875, 'learning_rate': 1.823344960184526e-05, 'epoch': 0.43}
 21%|██▏       | 167/780 [2:30:59<9:13:47, 54.20s/it] 22%|██▏       | 168/780 [2:31:53<9:12:59, 54.22s/it]                                                     {'loss': 0.2615, 'grad_norm': 0.515625, 'learning_rate': 1.8209919016788124e-05, 'epoch': 0.43}
 22%|██▏       | 168/780 [2:31:53<9:12:59, 54.22s/it] 22%|██▏       | 169/780 [2:32:48<9:12:20, 54.24s/it]                                                     {'loss': 0.2352, 'grad_norm': 0.494140625, 'learning_rate': 1.8186248146866928e-05, 'epoch': 0.43}
 22%|██▏       | 169/780 [2:32:48<9:12:20, 54.24s/it] 22%|██▏       | 170/780 [2:33:42<9:11:29, 54.25s/it]                                                     {'loss': 0.2778, 'grad_norm': 0.52734375, 'learning_rate': 1.8162437396551527e-05, 'epoch': 0.44}
 22%|██▏       | 170/780 [2:33:42<9:11:29, 54.25s/it] 22%|██▏       | 171/780 [2:34:36<9:10:24, 54.23s/it]                                                     {'loss': 0.2316, 'grad_norm': 0.48046875, 'learning_rate': 1.813848717270195e-05, 'epoch': 0.44}
 22%|██▏       | 171/780 [2:34:36<9:10:24, 54.23s/it] 22%|██▏       | 172/780 [2:35:30<9:09:35, 54.24s/it]                                                     {'loss': 0.2727, 'grad_norm': 0.515625, 'learning_rate': 1.8114397884561446e-05, 'epoch': 0.44}
 22%|██▏       | 172/780 [2:35:30<9:09:35, 54.24s/it] 22%|██▏       | 173/780 [2:36:25<9:08:31, 54.22s/it]                                                     {'loss': 0.2304, 'grad_norm': 0.51171875, 'learning_rate': 1.8090169943749477e-05, 'epoch': 0.44}
 22%|██▏       | 173/780 [2:36:25<9:08:31, 54.22s/it] 22%|██▏       | 174/780 [2:37:19<9:07:08, 54.17s/it]                                                     {'loss': 0.2628, 'grad_norm': 0.609375, 'learning_rate': 1.806580376425471e-05, 'epoch': 0.45}
 22%|██▏       | 174/780 [2:37:19<9:07:08, 54.17s/it] 22%|██▏       | 175/780 [2:38:13<9:06:10, 54.17s/it]                                                     {'loss': 0.2318, 'grad_norm': 0.5, 'learning_rate': 1.804129976242792e-05, 'epoch': 0.45}
 22%|██▏       | 175/780 [2:38:13<9:06:10, 54.17s/it] 23%|██▎       | 176/780 [2:39:07<9:05:21, 54.18s/it]                                                     {'loss': 0.2649, 'grad_norm': 0.5234375, 'learning_rate': 1.8016658356974885e-05, 'epoch': 0.45}
 23%|██▎       | 176/780 [2:39:07<9:05:21, 54.18s/it] 23%|██▎       | 177/780 [2:40:01<9:04:57, 54.22s/it]                                                     {'loss': 0.2433, 'grad_norm': 0.5234375, 'learning_rate': 1.7991879968949248e-05, 'epoch': 0.45}
 23%|██▎       | 177/780 [2:40:01<9:04:57, 54.22s/it] 23%|██▎       | 178/780 [2:40:56<9:04:08, 54.23s/it]                                                     {'loss': 0.2181, 'grad_norm': 0.453125, 'learning_rate': 1.796696502174529e-05, 'epoch': 0.46}
 23%|██▎       | 178/780 [2:40:56<9:04:08, 54.23s/it] 23%|██▎       | 179/780 [2:41:50<9:03:09, 54.23s/it]                                                     {'loss': 0.2549, 'grad_norm': 0.5390625, 'learning_rate': 1.7941913941090712e-05, 'epoch': 0.46}
 23%|██▎       | 179/780 [2:41:50<9:03:09, 54.23s/it] 23%|██▎       | 180/780 [2:42:44<9:02:19, 54.23s/it]                                                     {'loss': 0.2681, 'grad_norm': 0.5078125, 'learning_rate': 1.7916727155039367e-05, 'epoch': 0.46}
 23%|██▎       | 180/780 [2:42:44<9:02:19, 54.23s/it] 23%|██▎       | 181/780 [2:43:38<9:01:43, 54.26s/it]                                                     {'loss': 0.2217, 'grad_norm': 0.53125, 'learning_rate': 1.789140509396394e-05, 'epoch': 0.46}
 23%|██▎       | 181/780 [2:43:38<9:01:43, 54.26s/it] 23%|██▎       | 182/780 [2:44:33<9:00:52, 54.27s/it]                                                     {'loss': 0.2367, 'grad_norm': 0.484375, 'learning_rate': 1.786594819054858e-05, 'epoch': 0.47}
 23%|██▎       | 182/780 [2:44:33<9:00:52, 54.27s/it] 23%|██▎       | 183/780 [2:45:27<9:00:34, 54.33s/it]                                                     {'loss': 0.282, 'grad_norm': 0.54296875, 'learning_rate': 1.784035687978153e-05, 'epoch': 0.47}
 23%|██▎       | 183/780 [2:45:27<9:00:34, 54.33s/it] 24%|██▎       | 184/780 [2:46:21<8:59:27, 54.31s/it]                                                     {'loss': 0.2898, 'grad_norm': 0.53125, 'learning_rate': 1.7814631598947692e-05, 'epoch': 0.47}
 24%|██▎       | 184/780 [2:46:21<8:59:27, 54.31s/it] 24%|██▎       | 185/780 [2:47:16<8:58:16, 54.28s/it]                                                     {'loss': 0.2651, 'grad_norm': 0.58203125, 'learning_rate': 1.7788772787621126e-05, 'epoch': 0.47}
 24%|██▎       | 185/780 [2:47:16<8:58:16, 54.28s/it] 24%|██▍       | 186/780 [2:48:10<8:57:07, 54.25s/it]                                                     {'loss': 0.2711, 'grad_norm': 0.578125, 'learning_rate': 1.7762780887657576e-05, 'epoch': 0.48}
 24%|██▍       | 186/780 [2:48:10<8:57:07, 54.25s/it] 24%|██▍       | 187/780 [2:49:04<8:55:51, 54.22s/it]                                                     {'loss': 0.226, 'grad_norm': 0.494140625, 'learning_rate': 1.7736656343186897e-05, 'epoch': 0.48}
 24%|██▍       | 187/780 [2:49:04<8:55:51, 54.22s/it] 24%|██▍       | 188/780 [2:49:58<8:54:45, 54.20s/it]                                                     {'loss': 0.2637, 'grad_norm': 0.484375, 'learning_rate': 1.7710399600605472e-05, 'epoch': 0.48}
 24%|██▍       | 188/780 [2:49:58<8:54:45, 54.20s/it] 24%|██▍       | 189/780 [2:50:52<8:54:10, 54.23s/it]                                                     {'loss': 0.2552, 'grad_norm': 0.48828125, 'learning_rate': 1.7684011108568593e-05, 'epoch': 0.48}
 24%|██▍       | 189/780 [2:50:52<8:54:10, 54.23s/it] 24%|██▍       | 190/780 [2:51:47<8:53:06, 54.21s/it]                                                     {'loss': 0.2898, 'grad_norm': 0.51171875, 'learning_rate': 1.7657491317982772e-05, 'epoch': 0.49}
 24%|██▍       | 190/780 [2:51:47<8:53:06, 54.21s/it] 24%|██▍       | 191/780 [2:52:41<8:52:02, 54.20s/it]                                                     {'loss': 0.2656, 'grad_norm': 0.515625, 'learning_rate': 1.7630840681998068e-05, 'epoch': 0.49}
 24%|██▍       | 191/780 [2:52:41<8:52:02, 54.20s/it] 25%|██▍       | 192/780 [2:53:35<8:50:57, 54.18s/it]                                                     {'loss': 0.2592, 'grad_norm': 0.625, 'learning_rate': 1.7604059656000313e-05, 'epoch': 0.49}
 25%|██▍       | 192/780 [2:53:35<8:50:57, 54.18s/it] 25%|██▍       | 193/780 [2:54:29<8:49:50, 54.16s/it]                                                     {'loss': 0.3197, 'grad_norm': 0.5234375, 'learning_rate': 1.757714869760335e-05, 'epoch': 0.49}
 25%|██▍       | 193/780 [2:54:29<8:49:50, 54.16s/it] 25%|██▍       | 194/780 [2:55:23<8:49:16, 54.19s/it]                                                     {'loss': 0.2655, 'grad_norm': 0.52734375, 'learning_rate': 1.7550108266641207e-05, 'epoch': 0.5}
 25%|██▍       | 194/780 [2:55:23<8:49:16, 54.19s/it] 25%|██▌       | 195/780 [2:56:18<8:48:37, 54.22s/it]                                                     {'loss': 0.2646, 'grad_norm': 0.5078125, 'learning_rate': 1.752293882516025e-05, 'epoch': 0.5}
 25%|██▌       | 195/780 [2:56:18<8:48:37, 54.22s/it] 25%|██▌       | 196/780 [2:57:12<8:47:31, 54.20s/it]                                                     {'loss': 0.2583, 'grad_norm': 0.48046875, 'learning_rate': 1.7495640837411265e-05, 'epoch': 0.5}
 25%|██▌       | 196/780 [2:57:12<8:47:31, 54.20s/it] 25%|██▌       | 197/780 [2:58:06<8:46:40, 54.20s/it]                                                     {'loss': 0.2829, 'grad_norm': 0.5078125, 'learning_rate': 1.7468214769841542e-05, 'epoch': 0.5}
 25%|██▌       | 197/780 [2:58:06<8:46:40, 54.20s/it] 25%|██▌       | 198/780 [2:59:00<8:46:03, 54.23s/it]                                                     {'loss': 0.2748, 'grad_norm': 0.5234375, 'learning_rate': 1.7440661091086908e-05, 'epoch': 0.51}
 25%|██▌       | 198/780 [2:59:00<8:46:03, 54.23s/it] 26%|██▌       | 199/780 [2:59:54<8:44:51, 54.20s/it]                                                     {'loss': 0.2379, 'grad_norm': 0.5234375, 'learning_rate': 1.7412980271963712e-05, 'epoch': 0.51}
 26%|██▌       | 199/780 [2:59:54<8:44:51, 54.20s/it] 26%|██▌       | 200/780 [3:00:49<8:44:00, 54.21s/it]                                                     {'loss': 0.2117, 'grad_norm': 0.47265625, 'learning_rate': 1.7385172785460775e-05, 'epoch': 0.51}
 26%|██▌       | 200/780 [3:00:49<8:44:00, 54.21s/it] 26%|██▌       | 201/780 [3:01:43<8:43:33, 54.25s/it]                                                     {'loss': 0.2573, 'grad_norm': 0.515625, 'learning_rate': 1.735723910673132e-05, 'epoch': 0.51}
 26%|██▌       | 201/780 [3:01:43<8:43:33, 54.25s/it] 26%|██▌       | 202/780 [3:02:37<8:42:48, 54.27s/it]                                                     {'loss': 0.2848, 'grad_norm': 0.48828125, 'learning_rate': 1.732917971308484e-05, 'epoch': 0.52}
 26%|██▌       | 202/780 [3:02:37<8:42:48, 54.27s/it] 26%|██▌       | 203/780 [3:03:31<8:41:51, 54.27s/it]                                                     {'loss': 0.291, 'grad_norm': 0.5859375, 'learning_rate': 1.7300995083978965e-05, 'epoch': 0.52}
 26%|██▌       | 203/780 [3:03:32<8:41:51, 54.27s/it] 26%|██▌       | 204/780 [3:04:26<8:41:06, 54.28s/it]                                                     {'loss': 0.2518, 'grad_norm': 0.490234375, 'learning_rate': 1.727268570101123e-05, 'epoch': 0.52}
 26%|██▌       | 204/780 [3:04:26<8:41:06, 54.28s/it] 26%|██▋       | 205/780 [3:05:20<8:39:53, 54.25s/it]                                                     {'loss': 0.2207, 'grad_norm': 0.51171875, 'learning_rate': 1.7244252047910893e-05, 'epoch': 0.52}
 26%|██▋       | 205/780 [3:05:20<8:39:53, 54.25s/it] 26%|██▋       | 206/780 [3:06:14<8:39:17, 54.28s/it]                                                     {'loss': 0.2228, 'grad_norm': 0.47265625, 'learning_rate': 1.7215694610530624e-05, 'epoch': 0.53}
 26%|██▋       | 206/780 [3:06:14<8:39:17, 54.28s/it] 27%|██▋       | 207/780 [3:07:09<8:38:36, 54.30s/it]                                                     {'loss': 0.228, 'grad_norm': 0.50390625, 'learning_rate': 1.718701387683824e-05, 'epoch': 0.53}
 27%|██▋       | 207/780 [3:07:09<8:38:36, 54.30s/it] 27%|██▋       | 208/780 [3:08:03<8:37:18, 54.26s/it]                                                     {'loss': 0.2698, 'grad_norm': 0.66015625, 'learning_rate': 1.7158210336908346e-05, 'epoch': 0.53}
 27%|██▋       | 208/780 [3:08:03<8:37:18, 54.26s/it] 27%|██▋       | 209/780 [3:08:57<8:36:00, 54.22s/it]                                                     {'loss': 0.2549, 'grad_norm': 0.55859375, 'learning_rate': 1.7129284482913973e-05, 'epoch': 0.54}
 27%|██▋       | 209/780 [3:08:57<8:36:00, 54.22s/it] 27%|██▋       | 210/780 [3:09:51<8:35:37, 54.28s/it]                                                     {'loss': 0.2715, 'grad_norm': 0.51953125, 'learning_rate': 1.7100236809118148e-05, 'epoch': 0.54}
 27%|██▋       | 210/780 [3:09:51<8:35:37, 54.28s/it] 27%|██▋       | 211/780 [3:10:46<8:35:11, 54.33s/it]                                                     {'loss': 0.2277, 'grad_norm': 0.5, 'learning_rate': 1.7071067811865477e-05, 'epoch': 0.54}
 27%|██▋       | 211/780 [3:10:46<8:35:11, 54.33s/it] 27%|██▋       | 212/780 [3:11:40<8:34:18, 54.33s/it]                                                     {'loss': 0.2611, 'grad_norm': 0.5625, 'learning_rate': 1.704177798957364e-05, 'epoch': 0.54}
 27%|██▋       | 212/780 [3:11:40<8:34:18, 54.33s/it] 27%|██▋       | 213/780 [3:12:34<8:33:18, 54.32s/it]                                                     {'loss': 0.2659, 'grad_norm': 0.53515625, 'learning_rate': 1.7012367842724887e-05, 'epoch': 0.55}
 27%|██▋       | 213/780 [3:12:35<8:33:18, 54.32s/it] 27%|██▋       | 214/780 [3:13:29<8:32:41, 54.35s/it]                                                     {'loss': 0.2799, 'grad_norm': 0.486328125, 'learning_rate': 1.6982837873857485e-05, 'epoch': 0.55}
 27%|██▋       | 214/780 [3:13:29<8:32:41, 54.35s/it] 28%|██▊       | 215/780 [3:14:23<8:31:52, 54.36s/it]                                                     {'loss': 0.3235, 'grad_norm': 0.5703125, 'learning_rate': 1.6953188587557122e-05, 'epoch': 0.55}
 28%|██▊       | 215/780 [3:14:23<8:31:52, 54.36s/it] 28%|██▊       | 216/780 [3:15:18<8:30:53, 54.35s/it]                                                     {'loss': 0.27, 'grad_norm': 0.5078125, 'learning_rate': 1.6923420490448298e-05, 'epoch': 0.55}
 28%|██▊       | 216/780 [3:15:18<8:30:53, 54.35s/it] 28%|██▊       | 217/780 [3:16:12<8:29:47, 54.33s/it]                                                     {'loss': 0.2582, 'grad_norm': 0.58984375, 'learning_rate': 1.6893534091185658e-05, 'epoch': 0.56}
 28%|██▊       | 217/780 [3:16:12<8:29:47, 54.33s/it] 28%|██▊       | 218/780 [3:17:06<8:28:25, 54.28s/it]                                                     {'loss': 0.2683, 'grad_norm': 0.54296875, 'learning_rate': 1.686352990044531e-05, 'epoch': 0.56}
 28%|██▊       | 218/780 [3:17:06<8:28:25, 54.28s/it] 28%|██▊       | 219/780 [3:18:00<8:27:42, 54.30s/it]                                                     {'loss': 0.2769, 'grad_norm': 0.51953125, 'learning_rate': 1.6833408430916085e-05, 'epoch': 0.56}
 28%|██▊       | 219/780 [3:18:00<8:27:42, 54.30s/it] 28%|██▊       | 220/780 [3:18:55<8:26:36, 54.28s/it]                                                     {'loss': 0.2853, 'grad_norm': 0.6171875, 'learning_rate': 1.6803170197290792e-05, 'epoch': 0.56}
 28%|██▊       | 220/780 [3:18:55<8:26:36, 54.28s/it] 28%|██▊       | 221/780 [3:19:49<8:25:43, 54.28s/it]                                                     {'loss': 0.2461, 'grad_norm': 0.55078125, 'learning_rate': 1.6772815716257414e-05, 'epoch': 0.57}
 28%|██▊       | 221/780 [3:19:49<8:25:43, 54.28s/it] 28%|██▊       | 222/780 [3:20:43<8:24:54, 54.29s/it]                                                     {'loss': 0.2529, 'grad_norm': 0.51171875, 'learning_rate': 1.6742345506490277e-05, 'epoch': 0.57}
 28%|██▊       | 222/780 [3:20:43<8:24:54, 54.29s/it] 29%|██▊       | 223/780 [3:21:37<8:23:52, 54.28s/it]                                                     {'loss': 0.2509, 'grad_norm': 0.5234375, 'learning_rate': 1.6711760088641197e-05, 'epoch': 0.57}
 29%|██▊       | 223/780 [3:21:38<8:23:52, 54.28s/it] 29%|██▊       | 224/780 [3:22:32<8:22:50, 54.26s/it]                                                     {'loss': 0.2584, 'grad_norm': 0.6484375, 'learning_rate': 1.6681059985330578e-05, 'epoch': 0.57}
 29%|██▊       | 224/780 [3:22:32<8:22:50, 54.26s/it] 29%|██▉       | 225/780 [3:23:26<8:21:42, 54.24s/it]                                                     {'loss': 0.2122, 'grad_norm': 0.5625, 'learning_rate': 1.6650245721138483e-05, 'epoch': 0.58}
 29%|██▉       | 225/780 [3:23:26<8:21:42, 54.24s/it] 29%|██▉       | 226/780 [3:24:20<8:20:54, 54.25s/it]                                                     {'loss': 0.2493, 'grad_norm': 0.498046875, 'learning_rate': 1.6619317822595666e-05, 'epoch': 0.58}
 29%|██▉       | 226/780 [3:24:20<8:20:54, 54.25s/it] 29%|██▉       | 227/780 [3:25:14<8:19:57, 54.25s/it]                                                     {'loss': 0.2192, 'grad_norm': 0.51953125, 'learning_rate': 1.658827681817458e-05, 'epoch': 0.58}
 29%|██▉       | 227/780 [3:25:14<8:19:57, 54.25s/it] 29%|██▉       | 228/780 [3:26:09<8:19:08, 54.25s/it]                                                     {'loss': 0.2371, 'grad_norm': 0.5, 'learning_rate': 1.6557123238280347e-05, 'epoch': 0.58}
 29%|██▉       | 228/780 [3:26:09<8:19:08, 54.25s/it] 29%|██▉       | 229/780 [3:27:03<8:17:34, 54.18s/it]                                                     {'loss': 0.3078, 'grad_norm': 0.78515625, 'learning_rate': 1.6525857615241686e-05, 'epoch': 0.59}
 29%|██▉       | 229/780 [3:27:03<8:17:34, 54.18s/it] 29%|██▉       | 230/780 [3:27:57<8:16:46, 54.19s/it]                                                     {'loss': 0.2775, 'grad_norm': 0.5, 'learning_rate': 1.6494480483301836e-05, 'epoch': 0.59}
 29%|██▉       | 230/780 [3:27:57<8:16:46, 54.19s/it] 30%|██▉       | 231/780 [3:28:51<8:16:13, 54.23s/it]                                                     {'loss': 0.2407, 'grad_norm': 0.4921875, 'learning_rate': 1.646299237860941e-05, 'epoch': 0.59}
 30%|██▉       | 231/780 [3:28:51<8:16:13, 54.23s/it] 30%|██▉       | 232/780 [3:29:45<8:15:12, 54.22s/it]                                                     {'loss': 0.2187, 'grad_norm': 0.50390625, 'learning_rate': 1.6431393839209237e-05, 'epoch': 0.59}
 30%|██▉       | 232/780 [3:29:45<8:15:12, 54.22s/it] 30%|██▉       | 233/780 [3:30:40<8:14:15, 54.21s/it]                                                     {'loss': 0.2677, 'grad_norm': 0.57421875, 'learning_rate': 1.6399685405033168e-05, 'epoch': 0.6}
 30%|██▉       | 233/780 [3:30:40<8:14:15, 54.21s/it] 30%|███       | 234/780 [3:31:34<8:13:17, 54.21s/it]                                                     {'loss': 0.2357, 'grad_norm': 0.52734375, 'learning_rate': 1.636786761789086e-05, 'epoch': 0.6}
 30%|███       | 234/780 [3:31:34<8:13:17, 54.21s/it] 30%|███       | 235/780 [3:32:28<8:12:41, 54.24s/it]                                                     {'loss': 0.2434, 'grad_norm': 0.73828125, 'learning_rate': 1.6335941021460507e-05, 'epoch': 0.6}
 30%|███       | 235/780 [3:32:28<8:12:41, 54.24s/it] 30%|███       | 236/780 [3:33:22<8:11:30, 54.21s/it]                                                     {'loss': 0.2584, 'grad_norm': 0.5546875, 'learning_rate': 1.6303906161279554e-05, 'epoch': 0.6}
 30%|███       | 236/780 [3:33:22<8:11:30, 54.21s/it] 30%|███       | 237/780 [3:34:17<8:10:59, 54.25s/it]                                                     {'loss': 0.2315, 'grad_norm': 0.4765625, 'learning_rate': 1.6271763584735373e-05, 'epoch': 0.61}
 30%|███       | 237/780 [3:34:17<8:10:59, 54.25s/it] 31%|███       | 238/780 [3:35:11<8:10:08, 54.26s/it]                                                     {'loss': 0.2059, 'grad_norm': 0.46875, 'learning_rate': 1.623951384105591e-05, 'epoch': 0.61}
 31%|███       | 238/780 [3:35:11<8:10:08, 54.26s/it] 31%|███       | 239/780 [3:36:05<8:09:05, 54.24s/it]                                                     {'loss': 0.2852, 'grad_norm': 0.58203125, 'learning_rate': 1.6207157481300315e-05, 'epoch': 0.61}
 31%|███       | 239/780 [3:36:05<8:09:05, 54.24s/it] 31%|███       | 240/780 [3:36:59<8:08:07, 54.24s/it]                                                     {'loss': 0.2694, 'grad_norm': 0.515625, 'learning_rate': 1.6174695058349487e-05, 'epoch': 0.61}
 31%|███       | 240/780 [3:36:59<8:08:07, 54.24s/it] 31%|███       | 241/780 [3:37:54<8:07:18, 54.25s/it]                                                     {'loss': 0.2599, 'grad_norm': 0.5390625, 'learning_rate': 1.6142127126896682e-05, 'epoch': 0.62}
 31%|███       | 241/780 [3:37:54<8:07:18, 54.25s/it] 31%|███       | 242/780 [3:38:48<8:07:05, 54.32s/it]                                                     {'loss': 0.2614, 'grad_norm': 0.46875, 'learning_rate': 1.6109454243437977e-05, 'epoch': 0.62}
 31%|███       | 242/780 [3:38:48<8:07:05, 54.32s/it] 31%|███       | 243/780 [3:39:43<8:06:38, 54.37s/it]                                                     {'loss': 0.2423, 'grad_norm': 0.50390625, 'learning_rate': 1.6076676966262815e-05, 'epoch': 0.62}
 31%|███       | 243/780 [3:39:43<8:06:38, 54.37s/it] 31%|███▏      | 244/780 [3:40:37<8:05:34, 54.35s/it]                                                     {'loss': 0.3037, 'grad_norm': 0.54296875, 'learning_rate': 1.6043795855444418e-05, 'epoch': 0.62}
 31%|███▏      | 244/780 [3:40:37<8:05:34, 54.35s/it] 31%|███▏      | 245/780 [3:41:31<8:04:26, 54.33s/it]                                                     {'loss': 0.2754, 'grad_norm': 0.546875, 'learning_rate': 1.6010811472830253e-05, 'epoch': 0.63}
 31%|███▏      | 245/780 [3:41:31<8:04:26, 54.33s/it] 32%|███▏      | 246/780 [3:42:25<8:03:12, 54.29s/it]                                                     {'loss': 0.3036, 'grad_norm': 0.62890625, 'learning_rate': 1.597772438203241e-05, 'epoch': 0.63}
 32%|███▏      | 246/780 [3:42:25<8:03:12, 54.29s/it] 32%|███▏      | 247/780 [3:43:20<8:02:09, 54.28s/it]                                                     {'loss': 0.2675, 'grad_norm': 0.5390625, 'learning_rate': 1.5944535148417982e-05, 'epoch': 0.63}
 32%|███▏      | 247/780 [3:43:20<8:02:09, 54.28s/it] 32%|███▏      | 248/780 [3:44:14<8:01:28, 54.30s/it]                                                     {'loss': 0.2431, 'grad_norm': 0.5, 'learning_rate': 1.5911244339099393e-05, 'epoch': 0.63}
 32%|███▏      | 248/780 [3:44:14<8:01:28, 54.30s/it] 32%|███▏      | 249/780 [3:45:08<8:00:49, 54.33s/it]                                                     {'loss': 0.2545, 'grad_norm': 0.4609375, 'learning_rate': 1.5877852522924733e-05, 'epoch': 0.64}
 32%|███▏      | 249/780 [3:45:08<8:00:49, 54.33s/it] 32%|███▏      | 250/780 [3:46:03<7:59:48, 54.32s/it]                                                     {'loss': 0.2489, 'grad_norm': 0.546875, 'learning_rate': 1.5844360270468e-05, 'epoch': 0.64}
 32%|███▏      | 250/780 [3:46:03<7:59:48, 54.32s/it] 32%|███▏      | 251/780 [3:46:57<7:58:40, 54.29s/it]                                                     {'loss': 0.2798, 'grad_norm': 0.453125, 'learning_rate': 1.5810768154019386e-05, 'epoch': 0.64}
 32%|███▏      | 251/780 [3:46:57<7:58:40, 54.29s/it] 32%|███▏      | 252/780 [3:47:51<7:57:28, 54.26s/it]                                                     {'loss': 0.2479, 'grad_norm': 0.515625, 'learning_rate': 1.577707674757547e-05, 'epoch': 0.65}
 32%|███▏      | 252/780 [3:47:51<7:57:28, 54.26s/it] 32%|███▏      | 253/780 [3:48:45<7:56:41, 54.27s/it]                                                     {'loss': 0.2462, 'grad_norm': 0.57421875, 'learning_rate': 1.5743286626829437e-05, 'epoch': 0.65}
 32%|███▏      | 253/780 [3:48:45<7:56:41, 54.27s/it] 33%|███▎      | 254/780 [3:49:39<7:54:45, 54.15s/it]                                                     {'loss': 0.2453, 'grad_norm': 0.50390625, 'learning_rate': 1.570939836916122e-05, 'epoch': 0.65}
 33%|███▎      | 254/780 [3:49:39<7:54:45, 54.15s/it] 33%|███▎      | 255/780 [3:50:33<7:54:00, 54.17s/it]                                                     {'loss': 0.2256, 'grad_norm': 0.455078125, 'learning_rate': 1.5675412553627638e-05, 'epoch': 0.65}
 33%|███▎      | 255/780 [3:50:34<7:54:00, 54.17s/it] 33%|███▎      | 256/780 [3:51:28<7:52:57, 54.16s/it]                                                     {'loss': 0.2512, 'grad_norm': 0.50390625, 'learning_rate': 1.5641329760952514e-05, 'epoch': 0.66}
 33%|███▎      | 256/780 [3:51:28<7:52:57, 54.16s/it] 33%|███▎      | 257/780 [3:52:22<7:52:01, 54.15s/it]                                                     {'loss': 0.2271, 'grad_norm': 0.48046875, 'learning_rate': 1.560715057351673e-05, 'epoch': 0.66}
 33%|███▎      | 257/780 [3:52:22<7:52:01, 54.15s/it] 33%|███▎      | 258/780 [3:53:16<7:51:23, 54.18s/it]                                                     {'loss': 0.2715, 'grad_norm': 0.65625, 'learning_rate': 1.5572875575348298e-05, 'epoch': 0.66}
 33%|███▎      | 258/780 [3:53:16<7:51:23, 54.18s/it] 33%|███▎      | 259/780 [3:54:10<7:50:39, 54.20s/it]                                                     {'loss': 0.232, 'grad_norm': 0.49609375, 'learning_rate': 1.5538505352112373e-05, 'epoch': 0.66}
 33%|███▎      | 259/780 [3:54:10<7:50:39, 54.20s/it] 33%|███▎      | 260/780 [3:55:04<7:49:28, 54.17s/it]                                                     {'loss': 0.239, 'grad_norm': 0.5703125, 'learning_rate': 1.5504040491101235e-05, 'epoch': 0.67}
 33%|███▎      | 260/780 [3:55:04<7:49:28, 54.17s/it] 33%|███▎      | 261/780 [3:55:58<7:48:36, 54.17s/it]                                                     {'loss': 0.2853, 'grad_norm': 0.474609375, 'learning_rate': 1.5469481581224274e-05, 'epoch': 0.67}
 33%|███▎      | 261/780 [3:55:59<7:48:36, 54.17s/it] 34%|███▎      | 262/780 [3:56:53<7:47:40, 54.17s/it]                                                     {'loss': 0.2547, 'grad_norm': 0.53515625, 'learning_rate': 1.5434829212997896e-05, 'epoch': 0.67}
 34%|███▎      | 262/780 [3:56:53<7:47:40, 54.17s/it] 34%|███▎      | 263/780 [3:57:47<7:47:04, 54.21s/it]                                                     {'loss': 0.2516, 'grad_norm': 0.498046875, 'learning_rate': 1.5400083978535475e-05, 'epoch': 0.67}
 34%|███▎      | 263/780 [3:57:47<7:47:04, 54.21s/it] 34%|███▍      | 264/780 [3:58:41<7:46:03, 54.19s/it]                                                     {'loss': 0.2692, 'grad_norm': 0.5234375, 'learning_rate': 1.5365246471537196e-05, 'epoch': 0.68}
 34%|███▍      | 264/780 [3:58:41<7:46:03, 54.19s/it] 34%|███▍      | 265/780 [3:59:35<7:45:28, 54.23s/it]                                                     {'loss': 0.2335, 'grad_norm': 0.44140625, 'learning_rate': 1.533031728727994e-05, 'epoch': 0.68}
 34%|███▍      | 265/780 [3:59:35<7:45:28, 54.23s/it] 34%|███▍      | 266/780 [4:00:30<7:44:24, 54.21s/it]                                                     {'loss': 0.2748, 'grad_norm': 0.5703125, 'learning_rate': 1.529529702260709e-05, 'epoch': 0.68}
 34%|███▍      | 266/780 [4:00:30<7:44:24, 54.21s/it] 34%|███▍      | 267/780 [4:01:24<7:43:58, 54.27s/it]                                                     {'loss': 0.2319, 'grad_norm': 0.50390625, 'learning_rate': 1.526018627591834e-05, 'epoch': 0.68}
 34%|███▍      | 267/780 [4:01:24<7:43:58, 54.27s/it] 34%|███▍      | 268/780 [4:02:18<7:43:23, 54.30s/it]                                                     {'loss': 0.2612, 'grad_norm': 0.470703125, 'learning_rate': 1.5224985647159489e-05, 'epoch': 0.69}
 34%|███▍      | 268/780 [4:02:18<7:43:23, 54.30s/it] 34%|███▍      | 269/780 [4:03:13<7:42:19, 54.29s/it]                                                     {'loss': 0.2314, 'grad_norm': 0.55859375, 'learning_rate': 1.5189695737812153e-05, 'epoch': 0.69}
 34%|███▍      | 269/780 [4:03:13<7:42:19, 54.29s/it] 35%|███▍      | 270/780 [4:04:07<7:41:51, 54.34s/it]                                                     {'loss': 0.2555, 'grad_norm': 0.51171875, 'learning_rate': 1.5154317150883513e-05, 'epoch': 0.69}
 35%|███▍      | 270/780 [4:04:07<7:41:51, 54.34s/it] 35%|███▍      | 271/780 [4:05:01<7:40:53, 54.33s/it]                                                     {'loss': 0.2455, 'grad_norm': 0.47265625, 'learning_rate': 1.5118850490896012e-05, 'epoch': 0.69}
 35%|███▍      | 271/780 [4:05:01<7:40:53, 54.33s/it] 35%|███▍      | 272/780 [4:05:56<7:40:01, 54.33s/it]                                                     {'loss': 0.2234, 'grad_norm': 0.51171875, 'learning_rate': 1.5083296363877007e-05, 'epoch': 0.7}
 35%|███▍      | 272/780 [4:05:56<7:40:01, 54.33s/it] 35%|███▌      | 273/780 [4:06:50<7:39:03, 54.33s/it]                                                     {'loss': 0.2254, 'grad_norm': 0.53125, 'learning_rate': 1.504765537734844e-05, 'epoch': 0.7}
 35%|███▌      | 273/780 [4:06:50<7:39:03, 54.33s/it] 35%|███▌      | 274/780 [4:07:44<7:38:11, 54.33s/it]                                                     {'loss': 0.2765, 'grad_norm': 0.55078125, 'learning_rate': 1.5011928140316428e-05, 'epoch': 0.7}
 35%|███▌      | 274/780 [4:07:44<7:38:11, 54.33s/it] 35%|███▌      | 275/780 [4:08:39<7:37:22, 54.34s/it]                                                     {'loss': 0.2238, 'grad_norm': 0.5078125, 'learning_rate': 1.4976115263260876e-05, 'epoch': 0.7}
 35%|███▌      | 275/780 [4:08:39<7:37:22, 54.34s/it] 35%|███▌      | 276/780 [4:09:33<7:36:40, 54.37s/it]                                                     {'loss': 0.2216, 'grad_norm': 0.466796875, 'learning_rate': 1.4940217358125042e-05, 'epoch': 0.71}
 35%|███▌      | 276/780 [4:09:33<7:36:40, 54.37s/it] 36%|███▌      | 277/780 [4:10:27<7:35:09, 54.29s/it]                                                     {'loss': 0.246, 'grad_norm': 0.51953125, 'learning_rate': 1.4904235038305084e-05, 'epoch': 0.71}
 36%|███▌      | 277/780 [4:10:27<7:35:09, 54.29s/it] 36%|███▌      | 278/780 [4:11:22<7:34:14, 54.29s/it]                                                     {'loss': 0.2207, 'grad_norm': 0.53515625, 'learning_rate': 1.4868168918639564e-05, 'epoch': 0.71}
 36%|███▌      | 278/780 [4:11:22<7:34:14, 54.29s/it] 36%|███▌      | 279/780 [4:12:16<7:33:16, 54.28s/it]                                                     {'loss': 0.2455, 'grad_norm': 0.515625, 'learning_rate': 1.4832019615398962e-05, 'epoch': 0.71}
 36%|███▌      | 279/780 [4:12:16<7:33:16, 54.28s/it] 36%|███▌      | 280/780 [4:13:10<7:32:18, 54.28s/it]                                                     {'loss': 0.2235, 'grad_norm': 0.50390625, 'learning_rate': 1.4795787746275128e-05, 'epoch': 0.72}
 36%|███▌      | 280/780 [4:13:10<7:32:18, 54.28s/it] 36%|███▌      | 281/780 [4:14:04<7:31:24, 54.28s/it]                                                     {'loss': 0.2483, 'grad_norm': 0.6640625, 'learning_rate': 1.4759473930370738e-05, 'epoch': 0.72}
 36%|███▌      | 281/780 [4:14:04<7:31:24, 54.28s/it] 36%|███▌      | 282/780 [4:14:59<7:30:48, 54.31s/it]                                                     {'loss': 0.2525, 'grad_norm': 0.5234375, 'learning_rate': 1.4723078788188714e-05, 'epoch': 0.72}
 36%|███▌      | 282/780 [4:14:59<7:30:48, 54.31s/it] 36%|███▋      | 283/780 [4:15:53<7:29:51, 54.31s/it]                                                     {'loss': 0.2476, 'grad_norm': 0.57421875, 'learning_rate': 1.4686602941621618e-05, 'epoch': 0.72}
 36%|███▋      | 283/780 [4:15:53<7:29:51, 54.31s/it] 36%|███▋      | 284/780 [4:16:47<7:28:20, 54.23s/it]                                                     {'loss': 0.2989, 'grad_norm': 0.59765625, 'learning_rate': 1.4650047013941024e-05, 'epoch': 0.73}
 36%|███▋      | 284/780 [4:16:47<7:28:20, 54.23s/it] 37%|███▋      | 285/780 [4:17:41<7:27:12, 54.21s/it]                                                     {'loss': 0.2456, 'grad_norm': 0.5703125, 'learning_rate': 1.461341162978688e-05, 'epoch': 0.73}
 37%|███▋      | 285/780 [4:17:41<7:27:12, 54.21s/it] 37%|███▋      | 286/780 [4:18:35<7:26:13, 54.20s/it]                                                     {'loss': 0.2702, 'grad_norm': 0.5703125, 'learning_rate': 1.4576697415156818e-05, 'epoch': 0.73}
 37%|███▋      | 286/780 [4:18:36<7:26:13, 54.20s/it] 37%|███▋      | 287/780 [4:19:30<7:25:20, 54.20s/it]                                                     {'loss': 0.2439, 'grad_norm': 0.55078125, 'learning_rate': 1.4539904997395468e-05, 'epoch': 0.73}
 37%|███▋      | 287/780 [4:19:30<7:25:20, 54.20s/it] 37%|███▋      | 288/780 [4:20:24<7:24:56, 54.26s/it]                                                     {'loss': 0.2606, 'grad_norm': 0.4765625, 'learning_rate': 1.4503035005183739e-05, 'epoch': 0.74}
 37%|███▋      | 288/780 [4:20:24<7:24:56, 54.26s/it] 37%|███▋      | 289/780 [4:21:18<7:23:06, 54.15s/it]                                                     {'loss': 0.2455, 'grad_norm': 0.5390625, 'learning_rate': 1.4466088068528068e-05, 'epoch': 0.74}
 37%|███▋      | 289/780 [4:21:18<7:23:06, 54.15s/it] 37%|███▋      | 290/780 [4:22:12<7:21:32, 54.07s/it]                                                     {'loss': 0.2716, 'grad_norm': 0.75, 'learning_rate': 1.4429064818749659e-05, 'epoch': 0.74}
 37%|███▋      | 290/780 [4:22:12<7:21:32, 54.07s/it] 37%|███▋      | 291/780 [4:23:06<7:21:13, 54.14s/it]                                                     {'loss': 0.2291, 'grad_norm': 0.50390625, 'learning_rate': 1.4391965888473705e-05, 'epoch': 0.74}
 37%|███▋      | 291/780 [4:23:06<7:21:13, 54.14s/it] 37%|███▋      | 292/780 [4:24:00<7:20:48, 54.20s/it]                                                     {'loss': 0.2608, 'grad_norm': 0.5234375, 'learning_rate': 1.4354791911618561e-05, 'epoch': 0.75}
 37%|███▋      | 292/780 [4:24:01<7:20:48, 54.20s/it] 38%|███▊      | 293/780 [4:24:55<7:20:26, 54.26s/it]                                                     {'loss': 0.2784, 'grad_norm': 0.59765625, 'learning_rate': 1.4317543523384928e-05, 'epoch': 0.75}
 38%|███▊      | 293/780 [4:24:55<7:20:26, 54.26s/it] 38%|███▊      | 294/780 [4:25:49<7:19:29, 54.26s/it]                                                     {'loss': 0.2257, 'grad_norm': 0.5234375, 'learning_rate': 1.4280221360244993e-05, 'epoch': 0.75}
 38%|███▊      | 294/780 [4:25:49<7:19:29, 54.26s/it] 38%|███▊      | 295/780 [4:26:43<7:18:31, 54.25s/it]                                                     {'loss': 0.2616, 'grad_norm': 0.5703125, 'learning_rate': 1.4242826059931538e-05, 'epoch': 0.76}
 38%|███▊      | 295/780 [4:26:43<7:18:31, 54.25s/it] 38%|███▊      | 296/780 [4:27:38<7:17:42, 54.26s/it]                                                     {'loss': 0.1886, 'grad_norm': 0.54296875, 'learning_rate': 1.4205358261427076e-05, 'epoch': 0.76}
 38%|███▊      | 296/780 [4:27:38<7:17:42, 54.26s/it] 38%|███▊      | 297/780 [4:28:32<7:17:08, 54.30s/it]                                                     {'loss': 0.2635, 'grad_norm': 0.50390625, 'learning_rate': 1.4167818604952906e-05, 'epoch': 0.76}
 38%|███▊      | 297/780 [4:28:32<7:17:08, 54.30s/it] 38%|███▊      | 298/780 [4:29:26<7:16:11, 54.30s/it]                                                     {'loss': 0.226, 'grad_norm': 0.5625, 'learning_rate': 1.4130207731958176e-05, 'epoch': 0.76}
 38%|███▊      | 298/780 [4:29:26<7:16:11, 54.30s/it] 38%|███▊      | 299/780 [4:30:21<7:15:06, 54.28s/it]                                                     {'loss': 0.1896, 'grad_norm': 0.51171875, 'learning_rate': 1.409252628510894e-05, 'epoch': 0.77}
 38%|███▊      | 299/780 [4:30:21<7:15:06, 54.28s/it] 38%|███▊      | 300/780 [4:31:15<7:14:07, 54.27s/it]                                                     {'loss': 0.2335, 'grad_norm': 0.50390625, 'learning_rate': 1.4054774908277158e-05, 'epoch': 0.77}
 38%|███▊      | 300/780 [4:31:15<7:14:07, 54.27s/it] 39%|███▊      | 301/780 [4:32:09<7:13:03, 54.24s/it]                                                     {'loss': 0.2496, 'grad_norm': 0.5078125, 'learning_rate': 1.4016954246529697e-05, 'epoch': 0.77}
 39%|███▊      | 301/780 [4:32:09<7:13:03, 54.24s/it] 39%|███▊      | 302/780 [4:33:03<7:11:06, 54.11s/it]                                                     {'loss': 0.2853, 'grad_norm': 0.5625, 'learning_rate': 1.3979064946117316e-05, 'epoch': 0.77}
 39%|███▊      | 302/780 [4:33:03<7:11:06, 54.11s/it] 39%|███▉      | 303/780 [4:33:57<7:10:26, 54.14s/it]                                                     {'loss': 0.2727, 'grad_norm': 0.53515625, 'learning_rate': 1.3941107654463619e-05, 'epoch': 0.78}
 39%|███▉      | 303/780 [4:33:57<7:10:26, 54.14s/it] 39%|███▉      | 304/780 [4:34:51<7:09:29, 54.14s/it]                                                     {'loss': 0.2607, 'grad_norm': 0.5625, 'learning_rate': 1.3903083020153991e-05, 'epoch': 0.78}
 39%|███▉      | 304/780 [4:34:51<7:09:29, 54.14s/it] 39%|███▉      | 305/780 [4:35:45<7:08:49, 54.17s/it]                                                     {'loss': 0.239, 'grad_norm': 0.578125, 'learning_rate': 1.3864991692924524e-05, 'epoch': 0.78}
 39%|███▉      | 305/780 [4:35:45<7:08:49, 54.17s/it] 39%|███▉      | 306/780 [4:36:40<7:08:08, 54.19s/it]                                                     {'loss': 0.2661, 'grad_norm': 0.5078125, 'learning_rate': 1.3826834323650899e-05, 'epoch': 0.78}
 39%|███▉      | 306/780 [4:36:40<7:08:08, 54.19s/it] 39%|███▉      | 307/780 [4:37:34<7:07:24, 54.22s/it]                                                     {'loss': 0.2562, 'grad_norm': 0.51171875, 'learning_rate': 1.3788611564337277e-05, 'epoch': 0.79}
 39%|███▉      | 307/780 [4:37:34<7:07:24, 54.22s/it] 39%|███▉      | 308/780 [4:38:28<7:06:33, 54.22s/it]                                                     {'loss': 0.2432, 'grad_norm': 0.5078125, 'learning_rate': 1.3750324068105156e-05, 'epoch': 0.79}
 39%|███▉      | 308/780 [4:38:28<7:06:33, 54.22s/it] 40%|███▉      | 309/780 [4:39:22<7:05:27, 54.20s/it]                                                     {'loss': 0.2833, 'grad_norm': 0.58984375, 'learning_rate': 1.3711972489182208e-05, 'epoch': 0.79}
 40%|███▉      | 309/780 [4:39:22<7:05:27, 54.20s/it] 40%|███▉      | 310/780 [4:40:17<7:04:39, 54.21s/it]                                                     {'loss': 0.2749, 'grad_norm': 0.48046875, 'learning_rate': 1.36735574828911e-05, 'epoch': 0.79}
 40%|███▉      | 310/780 [4:40:17<7:04:39, 54.21s/it] 40%|███▉      | 311/780 [4:41:11<7:03:32, 54.18s/it]                                                     {'loss': 0.2495, 'grad_norm': 0.5390625, 'learning_rate': 1.3635079705638298e-05, 'epoch': 0.8}
 40%|███▉      | 311/780 [4:41:11<7:03:32, 54.18s/it] 40%|████      | 312/780 [4:42:05<7:02:33, 54.17s/it]                                                     {'loss': 0.2074, 'grad_norm': 0.455078125, 'learning_rate': 1.3596539814902856e-05, 'epoch': 0.8}
 40%|████      | 312/780 [4:42:05<7:02:33, 54.17s/it] 40%|████      | 313/780 [4:42:59<7:01:23, 54.14s/it]                                                     {'loss': 0.2383, 'grad_norm': 0.5390625, 'learning_rate': 1.3557938469225167e-05, 'epoch': 0.8}
 40%|████      | 313/780 [4:42:59<7:01:23, 54.14s/it] 40%|████      | 314/780 [4:43:53<7:00:41, 54.17s/it]                                                     {'loss': 0.2524, 'grad_norm': 0.4921875, 'learning_rate': 1.3519276328195725e-05, 'epoch': 0.8}
 40%|████      | 314/780 [4:43:53<7:00:41, 54.17s/it] 40%|████      | 315/780 [4:44:47<6:59:53, 54.18s/it]                                                     {'loss': 0.2781, 'grad_norm': 0.5390625, 'learning_rate': 1.3480554052443847e-05, 'epoch': 0.81}
 40%|████      | 315/780 [4:44:47<6:59:53, 54.18s/it] 41%|████      | 316/780 [4:45:41<6:58:42, 54.14s/it]                                                     {'loss': 0.2497, 'grad_norm': 0.59765625, 'learning_rate': 1.3441772303626387e-05, 'epoch': 0.81}
 41%|████      | 316/780 [4:45:41<6:58:42, 54.14s/it] 41%|████      | 317/780 [4:46:36<6:58:08, 54.19s/it]                                                     {'loss': 0.2504, 'grad_norm': 0.447265625, 'learning_rate': 1.3402931744416432e-05, 'epoch': 0.81}
 41%|████      | 317/780 [4:46:36<6:58:08, 54.19s/it] 41%|████      | 318/780 [4:47:30<6:57:27, 54.22s/it]                                                     {'loss': 0.2468, 'grad_norm': 0.54296875, 'learning_rate': 1.3364033038491972e-05, 'epoch': 0.81}
 41%|████      | 318/780 [4:47:30<6:57:27, 54.22s/it] 41%|████      | 319/780 [4:48:24<6:56:57, 54.27s/it]                                                     {'loss': 0.2283, 'grad_norm': 0.4609375, 'learning_rate': 1.332507685052457e-05, 'epoch': 0.82}
 41%|████      | 319/780 [4:48:24<6:56:57, 54.27s/it] 41%|████      | 320/780 [4:49:19<6:56:28, 54.32s/it]                                                     {'loss': 0.2816, 'grad_norm': 0.4296875, 'learning_rate': 1.328606384616799e-05, 'epoch': 0.82}
 41%|████      | 320/780 [4:49:19<6:56:28, 54.32s/it] 41%|████      | 321/780 [4:50:13<6:55:45, 54.35s/it]                                                     {'loss': 0.2602, 'grad_norm': 0.5390625, 'learning_rate': 1.3246994692046837e-05, 'epoch': 0.82}
 41%|████      | 321/780 [4:50:13<6:55:45, 54.35s/it] 41%|████▏     | 322/780 [4:51:07<6:54:20, 54.28s/it]                                                     {'loss': 0.2596, 'grad_norm': 0.60546875, 'learning_rate': 1.320787005574516e-05, 'epoch': 0.82}
 41%|████▏     | 322/780 [4:51:07<6:54:20, 54.28s/it] 41%|████▏     | 323/780 [4:52:02<6:53:43, 54.32s/it]                                                     {'loss': 0.2395, 'grad_norm': 0.47265625, 'learning_rate': 1.3168690605795044e-05, 'epoch': 0.83}
 41%|████▏     | 323/780 [4:52:02<6:53:43, 54.32s/it] 42%|████▏     | 324/780 [4:52:56<6:53:13, 54.37s/it]                                                     {'loss': 0.2538, 'grad_norm': 0.494140625, 'learning_rate': 1.3129457011665191e-05, 'epoch': 0.83}
 42%|████▏     | 324/780 [4:52:56<6:53:13, 54.37s/it] 42%|████▏     | 325/780 [4:53:50<6:52:00, 54.33s/it]                                                     {'loss': 0.2429, 'grad_norm': 0.578125, 'learning_rate': 1.3090169943749475e-05, 'epoch': 0.83}
 42%|████▏     | 325/780 [4:53:50<6:52:00, 54.33s/it] 42%|████▏     | 326/780 [4:54:45<6:50:56, 54.31s/it]                                                     {'loss': 0.2797, 'grad_norm': 0.5390625, 'learning_rate': 1.305083007335549e-05, 'epoch': 0.83}
 42%|████▏     | 326/780 [4:54:45<6:50:56, 54.31s/it] 42%|████▏     | 327/780 [4:55:39<6:50:10, 54.33s/it]                                                     {'loss': 0.2563, 'grad_norm': 0.55078125, 'learning_rate': 1.3011438072693077e-05, 'epoch': 0.84}
 42%|████▏     | 327/780 [4:55:39<6:50:10, 54.33s/it] 42%|████▏     | 328/780 [4:56:33<6:49:06, 54.31s/it]                                                     {'loss': 0.2735, 'grad_norm': 0.6328125, 'learning_rate': 1.297199461486284e-05, 'epoch': 0.84}
 42%|████▏     | 328/780 [4:56:33<6:49:06, 54.31s/it] 42%|████▏     | 329/780 [4:57:28<6:48:08, 54.30s/it]                                                     {'loss': 0.2704, 'grad_norm': 0.578125, 'learning_rate': 1.293250037384465e-05, 'epoch': 0.84}
 42%|████▏     | 329/780 [4:57:28<6:48:08, 54.30s/it] 42%|████▏     | 330/780 [4:58:22<6:47:14, 54.30s/it]                                                     {'loss': 0.2819, 'grad_norm': 0.51953125, 'learning_rate': 1.2892956024486111e-05, 'epoch': 0.84}
 42%|████▏     | 330/780 [4:58:22<6:47:14, 54.30s/it] 42%|████▏     | 331/780 [4:59:16<6:46:04, 54.26s/it]                                                     {'loss': 0.2443, 'grad_norm': 0.51953125, 'learning_rate': 1.2853362242491054e-05, 'epoch': 0.85}
 42%|████▏     | 331/780 [4:59:16<6:46:04, 54.26s/it] 43%|████▎     | 332/780 [5:00:10<6:45:12, 54.27s/it]                                                     {'loss': 0.2213, 'grad_norm': 0.51953125, 'learning_rate': 1.2813719704407965e-05, 'epoch': 0.85}
 43%|████▎     | 332/780 [5:00:10<6:45:12, 54.27s/it] 43%|████▎     | 333/780 [5:01:05<6:44:07, 54.25s/it]                                                     {'loss': 0.2959, 'grad_norm': 0.5625, 'learning_rate': 1.2774029087618448e-05, 'epoch': 0.85}
 43%|████▎     | 333/780 [5:01:05<6:44:07, 54.25s/it] 43%|████▎     | 334/780 [5:01:59<6:42:50, 54.19s/it]                                                     {'loss': 0.245, 'grad_norm': 0.55078125, 'learning_rate': 1.2734291070325627e-05, 'epoch': 0.86}
 43%|████▎     | 334/780 [5:01:59<6:42:50, 54.19s/it] 43%|████▎     | 335/780 [5:02:53<6:41:59, 54.20s/it]                                                     {'loss': 0.2407, 'grad_norm': 0.51171875, 'learning_rate': 1.269450633154258e-05, 'epoch': 0.86}
 43%|████▎     | 335/780 [5:02:53<6:41:59, 54.20s/it] 43%|████▎     | 336/780 [5:03:47<6:40:58, 54.19s/it]                                                     {'loss': 0.2273, 'grad_norm': 0.53515625, 'learning_rate': 1.2654675551080724e-05, 'epoch': 0.86}
 43%|████▎     | 336/780 [5:03:47<6:40:58, 54.19s/it] 43%|████▎     | 337/780 [5:04:41<6:39:42, 54.14s/it]                                                     {'loss': 0.2132, 'grad_norm': 0.55078125, 'learning_rate': 1.26147994095382e-05, 'epoch': 0.86}
 43%|████▎     | 337/780 [5:04:41<6:39:42, 54.14s/it] 43%|████▎     | 338/780 [5:05:35<6:38:51, 54.14s/it]                                                     {'loss': 0.2898, 'grad_norm': 0.61328125, 'learning_rate': 1.257487858828824e-05, 'epoch': 0.87}
 43%|████▎     | 338/780 [5:05:35<6:38:51, 54.14s/it] 43%|████▎     | 339/780 [5:06:29<6:38:00, 54.15s/it]                                                     {'loss': 0.2102, 'grad_norm': 0.48046875, 'learning_rate': 1.253491376946754e-05, 'epoch': 0.87}
 43%|████▎     | 339/780 [5:06:29<6:38:00, 54.15s/it] 44%|████▎     | 340/780 [5:07:24<6:37:15, 54.17s/it]                                                     {'loss': 0.2859, 'grad_norm': 0.5234375, 'learning_rate': 1.2494905635964587e-05, 'epoch': 0.87}
 44%|████▎     | 340/780 [5:07:24<6:37:15, 54.17s/it] 44%|████▎     | 341/780 [5:08:18<6:36:10, 54.15s/it]                                                     {'loss': 0.2588, 'grad_norm': 0.56640625, 'learning_rate': 1.2454854871407993e-05, 'epoch': 0.87}
 44%|████▎     | 341/780 [5:08:18<6:36:10, 54.15s/it] 44%|████▍     | 342/780 [5:09:12<6:35:30, 54.18s/it]                                                     {'loss': 0.2403, 'grad_norm': 0.515625, 'learning_rate': 1.241476216015482e-05, 'epoch': 0.88}
 44%|████▍     | 342/780 [5:09:12<6:35:30, 54.18s/it] 44%|████▍     | 343/780 [5:10:06<6:34:45, 54.20s/it]                                                     {'loss': 0.2531, 'grad_norm': 0.58984375, 'learning_rate': 1.2374628187278888e-05, 'epoch': 0.88}
 44%|████▍     | 343/780 [5:10:06<6:34:45, 54.20s/it] 44%|████▍     | 344/780 [5:11:00<6:33:50, 54.20s/it]                                                     {'loss': 0.2759, 'grad_norm': 0.515625, 'learning_rate': 1.2334453638559057e-05, 'epoch': 0.88}
 44%|████▍     | 344/780 [5:11:00<6:33:50, 54.20s/it] 44%|████▍     | 345/780 [5:11:55<6:33:14, 54.24s/it]                                                     {'loss': 0.2633, 'grad_norm': 0.55078125, 'learning_rate': 1.2294239200467516e-05, 'epoch': 0.88}
 44%|████▍     | 345/780 [5:11:55<6:33:14, 54.24s/it] 44%|████▍     | 346/780 [5:12:49<6:32:25, 54.25s/it]                                                     {'loss': 0.2109, 'grad_norm': 0.48046875, 'learning_rate': 1.2253985560158064e-05, 'epoch': 0.89}
 44%|████▍     | 346/780 [5:12:49<6:32:25, 54.25s/it] 44%|████▍     | 347/780 [5:13:43<6:32:04, 54.33s/it]                                                     {'loss': 0.2554, 'grad_norm': 0.494140625, 'learning_rate': 1.2213693405454345e-05, 'epoch': 0.89}
 44%|████▍     | 347/780 [5:13:44<6:32:04, 54.33s/it] 45%|████▍     | 348/780 [5:14:38<6:31:07, 54.32s/it]                                                     {'loss': 0.2796, 'grad_norm': 0.53125, 'learning_rate': 1.2173363424838116e-05, 'epoch': 0.89}
 45%|████▍     | 348/780 [5:14:38<6:31:07, 54.32s/it] 45%|████▍     | 349/780 [5:15:32<6:30:20, 54.34s/it]                                                     {'loss': 0.2415, 'grad_norm': 0.5078125, 'learning_rate': 1.213299630743747e-05, 'epoch': 0.89}
 45%|████▍     | 349/780 [5:15:32<6:30:20, 54.34s/it] 45%|████▍     | 350/780 [5:16:26<6:29:21, 54.33s/it]                                                     {'loss': 0.2885, 'grad_norm': 0.54296875, 'learning_rate': 1.2092592743015065e-05, 'epoch': 0.9}
 45%|████▍     | 350/780 [5:16:27<6:29:21, 54.33s/it] 45%|████▌     | 351/780 [5:17:21<6:28:18, 54.31s/it]                                                     {'loss': 0.2427, 'grad_norm': 0.5078125, 'learning_rate': 1.2052153421956343e-05, 'epoch': 0.9}
 45%|████▌     | 351/780 [5:17:21<6:28:18, 54.31s/it] 45%|████▌     | 352/780 [5:18:15<6:27:19, 54.30s/it]                                                     {'loss': 0.2812, 'grad_norm': 0.53125, 'learning_rate': 1.2011679035257724e-05, 'epoch': 0.9}
 45%|████▌     | 352/780 [5:18:15<6:27:19, 54.30s/it] 45%|████▌     | 353/780 [5:19:09<6:26:35, 54.32s/it]                                                     {'loss': 0.2338, 'grad_norm': 0.5546875, 'learning_rate': 1.1971170274514802e-05, 'epoch': 0.9}
 45%|████▌     | 353/780 [5:19:09<6:26:35, 54.32s/it] 45%|████▌     | 354/780 [5:20:04<6:25:40, 54.32s/it]                                                     {'loss': 0.2782, 'grad_norm': 0.5, 'learning_rate': 1.1930627831910537e-05, 'epoch': 0.91}
 45%|████▌     | 354/780 [5:20:04<6:25:40, 54.32s/it] 46%|████▌     | 355/780 [5:20:58<6:24:56, 54.35s/it]                                                     {'loss': 0.2307, 'grad_norm': 0.470703125, 'learning_rate': 1.1890052400203405e-05, 'epoch': 0.91}
 46%|████▌     | 355/780 [5:20:58<6:24:56, 54.35s/it] 46%|████▌     | 356/780 [5:21:52<6:23:51, 54.32s/it]                                                     {'loss': 0.2842, 'grad_norm': 0.53515625, 'learning_rate': 1.1849444672715587e-05, 'epoch': 0.91}
 46%|████▌     | 356/780 [5:21:52<6:23:51, 54.32s/it] 46%|████▌     | 357/780 [5:22:47<6:22:48, 54.30s/it]                                                     {'loss': 0.2393, 'grad_norm': 0.478515625, 'learning_rate': 1.1808805343321102e-05, 'epoch': 0.91}
 46%|████▌     | 357/780 [5:22:47<6:22:48, 54.30s/it] 46%|████▌     | 358/780 [5:23:41<6:21:49, 54.29s/it]                                                     {'loss': 0.2359, 'grad_norm': 0.50390625, 'learning_rate': 1.1768135106433961e-05, 'epoch': 0.92}
 46%|████▌     | 358/780 [5:23:41<6:21:49, 54.29s/it] 46%|████▌     | 359/780 [5:24:35<6:20:57, 54.29s/it]                                                     {'loss': 0.2378, 'grad_norm': 0.546875, 'learning_rate': 1.1727434656996306e-05, 'epoch': 0.92}
 46%|████▌     | 359/780 [5:24:35<6:20:57, 54.29s/it] 46%|████▌     | 360/780 [5:25:29<6:19:42, 54.25s/it]                                                     {'loss': 0.2548, 'grad_norm': 0.61328125, 'learning_rate': 1.1686704690466515e-05, 'epoch': 0.92}
 46%|████▌     | 360/780 [5:25:29<6:19:42, 54.25s/it] 46%|████▋     | 361/780 [5:26:24<6:18:56, 54.26s/it]                                                     {'loss': 0.2031, 'grad_norm': 0.490234375, 'learning_rate': 1.164594590280734e-05, 'epoch': 0.92}
 46%|████▋     | 361/780 [5:26:24<6:18:56, 54.26s/it] 46%|████▋     | 362/780 [5:27:18<6:17:53, 54.24s/it]                                                     {'loss': 0.2496, 'grad_norm': 0.51171875, 'learning_rate': 1.1605158990474008e-05, 'epoch': 0.93}
 46%|████▋     | 362/780 [5:27:18<6:17:53, 54.24s/it] 47%|████▋     | 363/780 [5:28:12<6:16:59, 54.24s/it]                                                     {'loss': 0.2491, 'grad_norm': 0.5078125, 'learning_rate': 1.156434465040231e-05, 'epoch': 0.93}
 47%|████▋     | 363/780 [5:28:12<6:16:59, 54.24s/it] 47%|████▋     | 364/780 [5:29:06<6:16:20, 54.28s/it]                                                     {'loss': 0.2488, 'grad_norm': 0.46484375, 'learning_rate': 1.152350357999671e-05, 'epoch': 0.93}
 47%|████▋     | 364/780 [5:29:06<6:16:20, 54.28s/it] 47%|████▋     | 365/780 [5:30:01<6:15:09, 54.24s/it]                                                     {'loss': 0.251, 'grad_norm': 0.55078125, 'learning_rate': 1.148263647711842e-05, 'epoch': 0.93}
 47%|████▋     | 365/780 [5:30:01<6:15:09, 54.24s/it] 47%|████▋     | 366/780 [5:30:55<6:14:30, 54.28s/it]                                                     {'loss': 0.2509, 'grad_norm': 0.494140625, 'learning_rate': 1.1441744040073469e-05, 'epoch': 0.94}
 47%|████▋     | 366/780 [5:30:55<6:14:30, 54.28s/it] 47%|████▋     | 367/780 [5:31:49<6:13:45, 54.30s/it]                                                     {'loss': 0.2736, 'grad_norm': 0.5390625, 'learning_rate': 1.140082696760078e-05, 'epoch': 0.94}
 47%|████▋     | 367/780 [5:31:49<6:13:45, 54.30s/it] 47%|████▋     | 368/780 [5:32:44<6:12:53, 54.30s/it]                                                     {'loss': 0.2151, 'grad_norm': 0.5, 'learning_rate': 1.1359885958860228e-05, 'epoch': 0.94}
 47%|████▋     | 368/780 [5:32:44<6:12:53, 54.30s/it] 47%|████▋     | 369/780 [5:33:38<6:12:02, 54.31s/it]                                                     {'loss': 0.2147, 'grad_norm': 0.54296875, 'learning_rate': 1.1318921713420691e-05, 'epoch': 0.94}
 47%|████▋     | 369/780 [5:33:38<6:12:02, 54.31s/it] 47%|████▋     | 370/780 [5:34:32<6:11:18, 54.34s/it]                                                     {'loss': 0.259, 'grad_norm': 0.5390625, 'learning_rate': 1.1277934931248103e-05, 'epoch': 0.95}
 47%|████▋     | 370/780 [5:34:32<6:11:18, 54.34s/it] 48%|████▊     | 371/780 [5:35:27<6:10:38, 54.37s/it]                                                     {'loss': 0.2344, 'grad_norm': 0.5078125, 'learning_rate': 1.123692631269348e-05, 'epoch': 0.95}
 48%|████▊     | 371/780 [5:35:27<6:10:38, 54.37s/it] 48%|████▊     | 372/780 [5:36:21<6:09:48, 54.38s/it]                                                     {'loss': 0.228, 'grad_norm': 0.578125, 'learning_rate': 1.1195896558480967e-05, 'epoch': 0.95}
 48%|████▊     | 372/780 [5:36:21<6:09:48, 54.38s/it] 48%|████▊     | 373/780 [5:37:16<6:08:57, 54.39s/it]                                                     {'loss': 0.2344, 'grad_norm': 0.546875, 'learning_rate': 1.1154846369695864e-05, 'epoch': 0.95}
 48%|████▊     | 373/780 [5:37:16<6:08:57, 54.39s/it] 48%|████▊     | 374/780 [5:38:10<6:07:48, 54.36s/it]                                                     {'loss': 0.2435, 'grad_norm': 0.5390625, 'learning_rate': 1.111377644777263e-05, 'epoch': 0.96}
 48%|████▊     | 374/780 [5:38:10<6:07:48, 54.36s/it] 48%|████▊     | 375/780 [5:39:04<6:06:29, 54.29s/it]                                                     {'loss': 0.2651, 'grad_norm': 1.3984375, 'learning_rate': 1.107268749448292e-05, 'epoch': 0.96}
 48%|████▊     | 375/780 [5:39:04<6:06:29, 54.29s/it] 48%|████▊     | 376/780 [5:39:58<6:05:37, 54.30s/it]                                                     {'loss': 0.2142, 'grad_norm': 0.5078125, 'learning_rate': 1.103158021192357e-05, 'epoch': 0.96}
 48%|████▊     | 376/780 [5:39:58<6:05:37, 54.30s/it] 48%|████▊     | 377/780 [5:40:53<6:04:40, 54.29s/it]                                                     {'loss': 0.2225, 'grad_norm': 0.671875, 'learning_rate': 1.099045530250463e-05, 'epoch': 0.97}
 48%|████▊     | 377/780 [5:40:53<6:04:40, 54.29s/it] 48%|████▊     | 378/780 [5:41:47<6:03:34, 54.27s/it]                                                     {'loss': 0.2371, 'grad_norm': 0.6171875, 'learning_rate': 1.0949313468937325e-05, 'epoch': 0.97}
 48%|████▊     | 378/780 [5:41:47<6:03:34, 54.27s/it] 49%|████▊     | 379/780 [5:42:41<6:02:30, 54.24s/it]                                                     {'loss': 0.2429, 'grad_norm': 0.53125, 'learning_rate': 1.0908155414222083e-05, 'epoch': 0.97}
 49%|████▊     | 379/780 [5:42:41<6:02:30, 54.24s/it] 49%|████▊     | 380/780 [5:43:35<6:01:34, 54.24s/it]                                                     {'loss': 0.261, 'grad_norm': 0.5546875, 'learning_rate': 1.08669818416365e-05, 'epoch': 0.97}
 49%|████▊     | 380/780 [5:43:35<6:01:34, 54.24s/it] 49%|████▉     | 381/780 [5:44:29<6:00:42, 54.24s/it]                                                     {'loss': 0.2194, 'grad_norm': 0.46484375, 'learning_rate': 1.0825793454723325e-05, 'epoch': 0.98}
 49%|████▉     | 381/780 [5:44:30<6:00:42, 54.24s/it] 49%|████▉     | 382/780 [5:45:24<5:59:23, 54.18s/it]                                                     {'loss': 0.3032, 'grad_norm': 0.6796875, 'learning_rate': 1.0784590957278452e-05, 'epoch': 0.98}
 49%|████▉     | 382/780 [5:45:24<5:59:23, 54.18s/it] 49%|████▉     | 383/780 [5:46:18<5:58:53, 54.24s/it]                                                     {'loss': 0.2644, 'grad_norm': 0.51171875, 'learning_rate': 1.0743375053338879e-05, 'epoch': 0.98}
 49%|████▉     | 383/780 [5:46:18<5:58:53, 54.24s/it] 49%|████▉     | 384/780 [5:47:12<5:57:54, 54.23s/it]                                                     {'loss': 0.2555, 'grad_norm': 0.5390625, 'learning_rate': 1.0702146447170683e-05, 'epoch': 0.98}
 49%|████▉     | 384/780 [5:47:12<5:57:54, 54.23s/it] 49%|████▉     | 385/780 [5:48:06<5:56:49, 54.20s/it]                                                     {'loss': 0.2551, 'grad_norm': 0.54296875, 'learning_rate': 1.0660905843256995e-05, 'epoch': 0.99}
 49%|████▉     | 385/780 [5:48:06<5:56:49, 54.20s/it] 49%|████▉     | 386/780 [5:49:00<5:55:55, 54.20s/it]                                                     {'loss': 0.2682, 'grad_norm': 0.474609375, 'learning_rate': 1.0619653946285948e-05, 'epoch': 0.99}
 49%|████▉     | 386/780 [5:49:01<5:55:55, 54.20s/it] 50%|████▉     | 387/780 [5:49:55<5:55:00, 54.20s/it]                                                     {'loss': 0.2024, 'grad_norm': 0.609375, 'learning_rate': 1.0578391461138642e-05, 'epoch': 0.99}
 50%|████▉     | 387/780 [5:49:55<5:55:00, 54.20s/it] 50%|████▉     | 388/780 [5:50:49<5:54:11, 54.21s/it]                                                     {'loss': 0.3038, 'grad_norm': 0.5390625, 'learning_rate': 1.05371190928771e-05, 'epoch': 0.99}
 50%|████▉     | 388/780 [5:50:49<5:54:11, 54.21s/it] 50%|████▉     | 389/780 [5:51:43<5:53:16, 54.21s/it]                                                     {'loss': 0.2554, 'grad_norm': 0.53125, 'learning_rate': 1.0495837546732224e-05, 'epoch': 1.0}
 50%|████▉     | 389/780 [5:51:43<5:53:16, 54.21s/it] 50%|█████     | 390/780 [5:52:37<5:52:27, 54.22s/it]                                                     {'loss': 0.2176, 'grad_norm': 0.51953125, 'learning_rate': 1.0454547528091737e-05, 'epoch': 1.0}
 50%|█████     | 390/780 [5:52:37<5:52:27, 54.22s/it] 50%|█████     | 391/780 [5:53:11<5:12:00, 48.13s/it]                                                     {'loss': 0.2158, 'grad_norm': 0.64453125, 'learning_rate': 1.0413249742488132e-05, 'epoch': 1.0}
 50%|█████     | 391/780 [5:53:11<5:12:00, 48.13s/it] 50%|█████     | 392/780 [5:54:06<5:23:22, 50.01s/it]                                                     {'loss': 0.227, 'grad_norm': 0.439453125, 'learning_rate': 1.0371944895586626e-05, 'epoch': 1.0}
 50%|█████     | 392/780 [5:54:06<5:23:22, 50.01s/it] 50%|█████     | 393/780 [5:55:00<5:30:55, 51.31s/it]                                                     {'loss': 0.2285, 'grad_norm': 0.435546875, 'learning_rate': 1.0330633693173083e-05, 'epoch': 1.01}
 50%|█████     | 393/780 [5:55:00<5:30:55, 51.31s/it] 51%|█████     | 394/780 [5:55:54<5:35:54, 52.21s/it]                                                     {'loss': 0.2103, 'grad_norm': 0.478515625, 'learning_rate': 1.0289316841141972e-05, 'epoch': 1.01}
 51%|█████     | 394/780 [5:55:54<5:35:54, 52.21s/it] 51%|█████     | 395/780 [5:56:49<5:38:54, 52.82s/it]                                                     {'loss': 0.253, 'grad_norm': 0.5, 'learning_rate': 1.0247995045484303e-05, 'epoch': 1.01}
 51%|█████     | 395/780 [5:56:49<5:38:54, 52.82s/it] 51%|█████     | 396/780 [5:57:43<5:40:55, 53.27s/it]                                                     {'loss': 0.227, 'grad_norm': 0.4453125, 'learning_rate': 1.0206669012275546e-05, 'epoch': 1.01}
 51%|█████     | 396/780 [5:57:43<5:40:55, 53.27s/it] 51%|█████     | 397/780 [5:58:37<5:41:56, 53.57s/it]                                                     {'loss': 0.2419, 'grad_norm': 0.439453125, 'learning_rate': 1.0165339447663586e-05, 'epoch': 1.02}
 51%|█████     | 397/780 [5:58:37<5:41:56, 53.57s/it] 51%|█████     | 398/780 [5:59:31<5:42:18, 53.77s/it]                                                     {'loss': 0.2166, 'grad_norm': 0.4453125, 'learning_rate': 1.0124007057856656e-05, 'epoch': 1.02}
 51%|█████     | 398/780 [5:59:31<5:42:18, 53.77s/it] 51%|█████     | 399/780 [6:00:26<5:42:25, 53.92s/it]                                                     {'loss': 0.2183, 'grad_norm': 0.49609375, 'learning_rate': 1.008267254911125e-05, 'epoch': 1.02}
 51%|█████     | 399/780 [6:00:26<5:42:25, 53.92s/it] 51%|█████▏    | 400/780 [6:01:20<5:41:57, 53.99s/it]                                                     {'loss': 0.2275, 'grad_norm': 0.494140625, 'learning_rate': 1.0041336627720085e-05, 'epoch': 1.02}
 51%|█████▏    | 400/780 [6:01:20<5:41:57, 53.99s/it] 51%|█████▏    | 401/780 [6:02:14<5:41:13, 54.02s/it]                                                     {'loss': 0.2043, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 1.03}
 51%|█████▏    | 401/780 [6:02:14<5:41:13, 54.02s/it] 52%|█████▏    | 402/780 [6:03:08<5:40:53, 54.11s/it]                                                     {'loss': 0.2289, 'grad_norm': 0.486328125, 'learning_rate': 9.95866337227992e-06, 'epoch': 1.03}
 52%|█████▏    | 402/780 [6:03:08<5:40:53, 54.11s/it] 52%|█████▏    | 403/780 [6:04:02<5:40:16, 54.15s/it]                                                     {'loss': 0.2467, 'grad_norm': 0.5078125, 'learning_rate': 9.917327450888751e-06, 'epoch': 1.03}
 52%|█████▏    | 403/780 [6:04:03<5:40:16, 54.15s/it] 52%|█████▏    | 404/780 [6:04:57<5:39:19, 54.15s/it]                                                     {'loss': 0.2216, 'grad_norm': 0.5234375, 'learning_rate': 9.875992942143351e-06, 'epoch': 1.03}
 52%|█████▏    | 404/780 [6:04:57<5:39:19, 54.15s/it] 52%|█████▏    | 405/780 [6:05:51<5:38:30, 54.16s/it]                                                     {'loss': 0.2502, 'grad_norm': 0.47265625, 'learning_rate': 9.834660552336415e-06, 'epoch': 1.04}
 52%|█████▏    | 405/780 [6:05:51<5:38:30, 54.16s/it] 52%|█████▏    | 406/780 [6:06:45<5:37:50, 54.20s/it]                                                     {'loss': 0.235, 'grad_norm': 0.49609375, 'learning_rate': 9.79333098772446e-06, 'epoch': 1.04}
 52%|█████▏    | 406/780 [6:06:45<5:37:50, 54.20s/it] 52%|█████▏    | 407/780 [6:07:39<5:36:56, 54.20s/it]                                                     {'loss': 0.2247, 'grad_norm': 0.50390625, 'learning_rate': 9.7520049545157e-06, 'epoch': 1.04}
 52%|█████▏    | 407/780 [6:07:39<5:36:56, 54.20s/it] 52%|█████▏    | 408/780 [6:08:34<5:36:17, 54.24s/it]                                                     {'loss': 0.2213, 'grad_norm': 0.451171875, 'learning_rate': 9.71068315885803e-06, 'epoch': 1.04}
 52%|█████▏    | 408/780 [6:08:34<5:36:17, 54.24s/it] 52%|█████▏    | 409/780 [6:09:28<5:35:28, 54.26s/it]                                                     {'loss': 0.2218, 'grad_norm': 0.6015625, 'learning_rate': 9.669366306826919e-06, 'epoch': 1.05}
 52%|█████▏    | 409/780 [6:09:28<5:35:28, 54.26s/it] 53%|█████▎    | 410/780 [6:10:22<5:34:37, 54.26s/it]                                                     {'loss': 0.2775, 'grad_norm': 0.53125, 'learning_rate': 9.628055104413379e-06, 'epoch': 1.05}
 53%|█████▎    | 410/780 [6:10:22<5:34:37, 54.26s/it] 53%|█████▎    | 411/780 [6:11:16<5:33:47, 54.27s/it]                                                     {'loss': 0.2284, 'grad_norm': 0.484375, 'learning_rate': 9.586750257511868e-06, 'epoch': 1.05}
 53%|█████▎    | 411/780 [6:11:17<5:33:47, 54.27s/it] 53%|█████▎    | 412/780 [6:12:11<5:33:06, 54.31s/it]                                                     {'loss': 0.2479, 'grad_norm': 0.4921875, 'learning_rate': 9.545452471908266e-06, 'epoch': 1.05}
 53%|█████▎    | 412/780 [6:12:11<5:33:06, 54.31s/it] 53%|█████▎    | 413/780 [6:13:05<5:31:26, 54.19s/it]                                                     {'loss': 0.2274, 'grad_norm': 0.498046875, 'learning_rate': 9.504162453267776e-06, 'epoch': 1.06}
 53%|█████▎    | 413/780 [6:13:05<5:31:26, 54.19s/it] 53%|█████▎    | 414/780 [6:13:59<5:30:43, 54.22s/it]                                                     {'loss': 0.2165, 'grad_norm': 0.62109375, 'learning_rate': 9.462880907122904e-06, 'epoch': 1.06}
 53%|█████▎    | 414/780 [6:13:59<5:30:43, 54.22s/it] 53%|█████▎    | 415/780 [6:14:53<5:29:47, 54.21s/it]                                                     {'loss': 0.2144, 'grad_norm': 0.56640625, 'learning_rate': 9.421608538861361e-06, 'epoch': 1.06}
 53%|█████▎    | 415/780 [6:14:53<5:29:47, 54.21s/it] 53%|█████▎    | 416/780 [6:15:48<5:29:08, 54.25s/it]                                                     {'loss': 0.2174, 'grad_norm': 0.46484375, 'learning_rate': 9.380346053714055e-06, 'epoch': 1.06}
 53%|█████▎    | 416/780 [6:15:48<5:29:08, 54.25s/it] 53%|█████▎    | 417/780 [6:16:42<5:28:27, 54.29s/it]                                                     {'loss': 0.2475, 'grad_norm': 0.515625, 'learning_rate': 9.339094156743007e-06, 'epoch': 1.07}
 53%|█████▎    | 417/780 [6:16:42<5:28:27, 54.29s/it] 54%|█████▎    | 418/780 [6:17:36<5:27:21, 54.26s/it]                                                     {'loss': 0.22, 'grad_norm': 0.53515625, 'learning_rate': 9.297853552829319e-06, 'epoch': 1.07}
 54%|█████▎    | 418/780 [6:17:36<5:27:21, 54.26s/it] 54%|█████▎    | 419/780 [6:18:30<5:26:31, 54.27s/it]                                                     {'loss': 0.2273, 'grad_norm': 0.52734375, 'learning_rate': 9.256624946661126e-06, 'epoch': 1.07}
 54%|█████▎    | 419/780 [6:18:31<5:26:31, 54.27s/it] 54%|█████▍    | 420/780 [6:19:25<5:25:20, 54.22s/it]                                                     {'loss': 0.2038, 'grad_norm': 0.51953125, 'learning_rate': 9.215409042721553e-06, 'epoch': 1.07}
 54%|█████▍    | 420/780 [6:19:25<5:25:20, 54.22s/it] 54%|█████▍    | 421/780 [6:20:19<5:24:27, 54.23s/it]                                                     {'loss': 0.2452, 'grad_norm': 0.52734375, 'learning_rate': 9.174206545276678e-06, 'epoch': 1.08}
 54%|█████▍    | 421/780 [6:20:19<5:24:27, 54.23s/it] 54%|█████▍    | 422/780 [6:21:13<5:23:30, 54.22s/it]                                                     {'loss': 0.2159, 'grad_norm': 0.515625, 'learning_rate': 9.133018158363504e-06, 'epoch': 1.08}
 54%|█████▍    | 422/780 [6:21:13<5:23:30, 54.22s/it] 54%|█████▍    | 423/780 [6:22:07<5:22:29, 54.20s/it]                                                     {'loss': 0.281, 'grad_norm': 0.5703125, 'learning_rate': 9.091844585777919e-06, 'epoch': 1.08}
 54%|█████▍    | 423/780 [6:22:07<5:22:29, 54.20s/it] 54%|█████▍    | 424/780 [6:23:01<5:21:25, 54.17s/it]                                                     {'loss': 0.2376, 'grad_norm': 0.5234375, 'learning_rate': 9.050686531062676e-06, 'epoch': 1.08}
 54%|█████▍    | 424/780 [6:23:01<5:21:25, 54.17s/it] 54%|█████▍    | 425/780 [6:23:56<5:20:51, 54.23s/it]                                                     {'loss': 0.2181, 'grad_norm': 0.4921875, 'learning_rate': 9.009544697495373e-06, 'epoch': 1.09}
 54%|█████▍    | 425/780 [6:23:56<5:20:51, 54.23s/it] 55%|█████▍    | 426/780 [6:24:50<5:19:54, 54.22s/it]                                                     {'loss': 0.2484, 'grad_norm': 0.51171875, 'learning_rate': 8.968419788076431e-06, 'epoch': 1.09}
 55%|█████▍    | 426/780 [6:24:50<5:19:54, 54.22s/it] 55%|█████▍    | 427/780 [6:25:44<5:18:48, 54.19s/it]                                                     {'loss': 0.244, 'grad_norm': 0.578125, 'learning_rate': 8.927312505517086e-06, 'epoch': 1.09}
 55%|█████▍    | 427/780 [6:25:44<5:18:48, 54.19s/it] 55%|█████▍    | 428/780 [6:26:38<5:17:51, 54.18s/it]                                                     {'loss': 0.2263, 'grad_norm': 0.5390625, 'learning_rate': 8.886223552227373e-06, 'epoch': 1.09}
 55%|█████▍    | 428/780 [6:26:38<5:17:51, 54.18s/it] 55%|█████▌    | 429/780 [6:27:32<5:16:59, 54.19s/it]                                                     {'loss': 0.1883, 'grad_norm': 0.484375, 'learning_rate': 8.84515363030414e-06, 'epoch': 1.1}
 55%|█████▌    | 429/780 [6:27:32<5:16:59, 54.19s/it] 55%|█████▌    | 430/780 [6:28:26<5:15:59, 54.17s/it]                                                     {'loss': 0.2042, 'grad_norm': 0.5625, 'learning_rate': 8.804103441519037e-06, 'epoch': 1.1}
 55%|█████▌    | 430/780 [6:28:27<5:15:59, 54.17s/it] 55%|█████▌    | 431/780 [6:29:21<5:15:40, 54.27s/it]                                                     {'loss': 0.2835, 'grad_norm': 0.498046875, 'learning_rate': 8.763073687306523e-06, 'epoch': 1.1}
 55%|█████▌    | 431/780 [6:29:21<5:15:40, 54.27s/it] 55%|█████▌    | 432/780 [6:30:15<5:15:02, 54.32s/it]                                                     {'loss': 0.2318, 'grad_norm': 0.482421875, 'learning_rate': 8.722065068751904e-06, 'epoch': 1.1}
 55%|█████▌    | 432/780 [6:30:15<5:15:02, 54.32s/it] 56%|█████▌    | 433/780 [6:31:10<5:14:04, 54.31s/it]                                                     {'loss': 0.2181, 'grad_norm': 0.5390625, 'learning_rate': 8.68107828657931e-06, 'epoch': 1.11}
 56%|█████▌    | 433/780 [6:31:10<5:14:04, 54.31s/it] 56%|█████▌    | 434/780 [6:32:04<5:13:03, 54.29s/it]                                                     {'loss': 0.2, 'grad_norm': 0.48828125, 'learning_rate': 8.640114041139776e-06, 'epoch': 1.11}
 56%|█████▌    | 434/780 [6:32:04<5:13:03, 54.29s/it] 56%|█████▌    | 435/780 [6:32:58<5:12:14, 54.30s/it]                                                     {'loss': 0.2504, 'grad_norm': 0.55859375, 'learning_rate': 8.599173032399222e-06, 'epoch': 1.11}
 56%|█████▌    | 435/780 [6:32:58<5:12:14, 54.30s/it] 56%|█████▌    | 436/780 [6:33:53<5:11:29, 54.33s/it]                                                     {'loss': 0.3001, 'grad_norm': 0.5234375, 'learning_rate': 8.558255959926533e-06, 'epoch': 1.12}
 56%|█████▌    | 436/780 [6:33:53<5:11:29, 54.33s/it] 56%|█████▌    | 437/780 [6:34:47<5:10:34, 54.33s/it]                                                     {'loss': 0.2383, 'grad_norm': 0.50390625, 'learning_rate': 8.51736352288158e-06, 'epoch': 1.12}
 56%|█████▌    | 437/780 [6:34:47<5:10:34, 54.33s/it] 56%|█████▌    | 438/780 [6:35:41<5:09:38, 54.32s/it]                                                     {'loss': 0.2564, 'grad_norm': 0.56640625, 'learning_rate': 8.476496420003291e-06, 'epoch': 1.12}
 56%|█████▌    | 438/780 [6:35:41<5:09:38, 54.32s/it] 56%|█████▋    | 439/780 [6:36:36<5:08:53, 54.35s/it]                                                     {'loss': 0.2377, 'grad_norm': 0.5390625, 'learning_rate': 8.43565534959769e-06, 'epoch': 1.12}
 56%|█████▋    | 439/780 [6:36:36<5:08:53, 54.35s/it] 56%|█████▋    | 440/780 [6:37:30<5:08:07, 54.37s/it]                                                     {'loss': 0.2574, 'grad_norm': 0.546875, 'learning_rate': 8.394841009525995e-06, 'epoch': 1.13}
 56%|█████▋    | 440/780 [6:37:30<5:08:07, 54.37s/it] 57%|█████▋    | 441/780 [6:38:24<5:07:05, 54.35s/it]                                                     {'loss': 0.2299, 'grad_norm': 0.57421875, 'learning_rate': 8.35405409719266e-06, 'epoch': 1.13}
 57%|█████▋    | 441/780 [6:38:24<5:07:05, 54.35s/it] 57%|█████▋    | 442/780 [6:39:19<5:06:15, 54.36s/it]                                                     {'loss': 0.2045, 'grad_norm': 0.5, 'learning_rate': 8.313295309533488e-06, 'epoch': 1.13}
 57%|█████▋    | 442/780 [6:39:19<5:06:15, 54.36s/it] 57%|█████▋    | 443/780 [6:40:13<5:05:25, 54.38s/it]                                                     {'loss': 0.2091, 'grad_norm': 0.466796875, 'learning_rate': 8.2725653430037e-06, 'epoch': 1.13}
 57%|█████▋    | 443/780 [6:40:13<5:05:25, 54.38s/it] 57%|█████▋    | 444/780 [6:41:08<5:04:27, 54.37s/it]                                                     {'loss': 0.2839, 'grad_norm': 0.58984375, 'learning_rate': 8.23186489356604e-06, 'epoch': 1.14}
 57%|█████▋    | 444/780 [6:41:08<5:04:27, 54.37s/it] 57%|█████▋    | 445/780 [6:42:02<5:03:25, 54.35s/it]                                                     {'loss': 0.2217, 'grad_norm': 0.53515625, 'learning_rate': 8.191194656678905e-06, 'epoch': 1.14}
 57%|█████▋    | 445/780 [6:42:02<5:03:25, 54.35s/it] 57%|█████▋    | 446/780 [6:42:56<5:02:28, 54.34s/it]                                                     {'loss': 0.2079, 'grad_norm': 0.51953125, 'learning_rate': 8.150555327284417e-06, 'epoch': 1.14}
 57%|█████▋    | 446/780 [6:42:56<5:02:28, 54.34s/it] 57%|█████▋    | 447/780 [6:43:50<5:01:23, 54.30s/it]                                                     {'loss': 0.2544, 'grad_norm': 0.5078125, 'learning_rate': 8.109947599796599e-06, 'epoch': 1.14}
 57%|█████▋    | 447/780 [6:43:50<5:01:23, 54.30s/it] 57%|█████▋    | 448/780 [6:44:45<5:00:25, 54.29s/it]                                                     {'loss': 0.2353, 'grad_norm': 0.5234375, 'learning_rate': 8.069372168089466e-06, 'epoch': 1.15}
 57%|█████▋    | 448/780 [6:44:45<5:00:25, 54.29s/it] 58%|█████▊    | 449/780 [6:45:39<4:59:19, 54.26s/it]                                                     {'loss': 0.2399, 'grad_norm': 0.51171875, 'learning_rate': 8.0288297254852e-06, 'epoch': 1.15}
 58%|█████▊    | 449/780 [6:45:39<4:59:19, 54.26s/it] 58%|█████▊    | 450/780 [6:46:33<4:58:27, 54.26s/it]                                                     {'loss': 0.232, 'grad_norm': 0.482421875, 'learning_rate': 7.988320964742276e-06, 'epoch': 1.15}
 58%|█████▊    | 450/780 [6:46:33<4:58:27, 54.26s/it] 58%|█████▊    | 451/780 [6:47:27<4:57:36, 54.28s/it]                                                     {'loss': 0.2051, 'grad_norm': 0.48046875, 'learning_rate': 7.947846578043658e-06, 'epoch': 1.15}
 58%|█████▊    | 451/780 [6:47:27<4:57:36, 54.28s/it] 58%|█████▊    | 452/780 [6:48:22<4:56:50, 54.30s/it]                                                     {'loss': 0.2434, 'grad_norm': 0.474609375, 'learning_rate': 7.907407256984935e-06, 'epoch': 1.16}
 58%|█████▊    | 452/780 [6:48:22<4:56:50, 54.30s/it] 58%|█████▊    | 453/780 [6:49:16<4:55:54, 54.30s/it]                                                     {'loss': 0.2379, 'grad_norm': 0.515625, 'learning_rate': 7.867003692562533e-06, 'epoch': 1.16}
 58%|█████▊    | 453/780 [6:49:16<4:55:54, 54.30s/it] 58%|█████▊    | 454/780 [6:50:10<4:54:39, 54.23s/it]                                                     {'loss': 0.232, 'grad_norm': 0.5546875, 'learning_rate': 7.826636575161884e-06, 'epoch': 1.16}
 58%|█████▊    | 454/780 [6:50:10<4:54:39, 54.23s/it] 58%|█████▊    | 455/780 [6:51:04<4:53:55, 54.26s/it]                                                     {'loss': 0.2078, 'grad_norm': 0.53125, 'learning_rate': 7.786306594545658e-06, 'epoch': 1.16}
 58%|█████▊    | 455/780 [6:51:05<4:53:55, 54.26s/it] 58%|█████▊    | 456/780 [6:51:59<4:53:03, 54.27s/it]                                                     {'loss': 0.2185, 'grad_norm': 0.5078125, 'learning_rate': 7.746014439841941e-06, 'epoch': 1.17}
 58%|█████▊    | 456/780 [6:51:59<4:53:03, 54.27s/it] 59%|█████▊    | 457/780 [6:52:53<4:52:08, 54.27s/it]                                                     {'loss': 0.2319, 'grad_norm': 0.51953125, 'learning_rate': 7.705760799532485e-06, 'epoch': 1.17}
 59%|█████▊    | 457/780 [6:52:53<4:52:08, 54.27s/it] 59%|█████▊    | 458/780 [6:53:47<4:51:11, 54.26s/it]                                                     {'loss': 0.2242, 'grad_norm': 0.5390625, 'learning_rate': 7.66554636144095e-06, 'epoch': 1.17}
 59%|█████▊    | 458/780 [6:53:47<4:51:11, 54.26s/it] 59%|█████▉    | 459/780 [6:54:41<4:49:59, 54.21s/it]                                                     {'loss': 0.2352, 'grad_norm': 0.59375, 'learning_rate': 7.625371812721115e-06, 'epoch': 1.17}
 59%|█████▉    | 459/780 [6:54:41<4:49:59, 54.21s/it] 59%|█████▉    | 460/780 [6:55:36<4:49:11, 54.22s/it]                                                     {'loss': 0.2139, 'grad_norm': 0.43359375, 'learning_rate': 7.585237839845183e-06, 'epoch': 1.18}
 59%|█████▉    | 460/780 [6:55:36<4:49:11, 54.22s/it] 59%|█████▉    | 461/780 [6:56:30<4:48:24, 54.25s/it]                                                     {'loss': 0.1956, 'grad_norm': 0.484375, 'learning_rate': 7.545145128592009e-06, 'epoch': 1.18}
 59%|█████▉    | 461/780 [6:56:30<4:48:24, 54.25s/it] 59%|█████▉    | 462/780 [6:57:24<4:47:30, 54.25s/it]                                                     {'loss': 0.2331, 'grad_norm': 0.51953125, 'learning_rate': 7.505094364035417e-06, 'epoch': 1.18}
 59%|█████▉    | 462/780 [6:57:24<4:47:30, 54.25s/it] 59%|█████▉    | 463/780 [6:58:19<4:46:47, 54.28s/it]                                                     {'loss': 0.2687, 'grad_norm': 0.546875, 'learning_rate': 7.46508623053246e-06, 'epoch': 1.18}
 59%|█████▉    | 463/780 [6:58:19<4:46:47, 54.28s/it] 59%|█████▉    | 464/780 [6:59:13<4:45:44, 54.25s/it]                                                     {'loss': 0.2156, 'grad_norm': 0.53125, 'learning_rate': 7.425121411711762e-06, 'epoch': 1.19}
 59%|█████▉    | 464/780 [6:59:13<4:45:44, 54.25s/it] 60%|█████▉    | 465/780 [7:00:07<4:44:43, 54.23s/it]                                                     {'loss': 0.25, 'grad_norm': 0.57421875, 'learning_rate': 7.385200590461803e-06, 'epoch': 1.19}
 60%|█████▉    | 465/780 [7:00:07<4:44:43, 54.23s/it] 60%|█████▉    | 466/780 [7:01:01<4:43:57, 54.26s/it]                                                     {'loss': 0.2257, 'grad_norm': 0.490234375, 'learning_rate': 7.34532444891928e-06, 'epoch': 1.19}
 60%|█████▉    | 466/780 [7:01:01<4:43:57, 54.26s/it] 60%|█████▉    | 467/780 [7:01:56<4:43:20, 54.32s/it]                                                     {'loss': 0.202, 'grad_norm': 0.546875, 'learning_rate': 7.305493668457421e-06, 'epoch': 1.19}
 60%|█████▉    | 467/780 [7:01:56<4:43:20, 54.32s/it] 60%|██████    | 468/780 [7:02:50<4:42:16, 54.28s/it]                                                     {'loss': 0.1949, 'grad_norm': 0.50390625, 'learning_rate': 7.2657089296743766e-06, 'epoch': 1.2}
 60%|██████    | 468/780 [7:02:50<4:42:16, 54.28s/it] 60%|██████    | 469/780 [7:03:44<4:41:20, 54.28s/it]                                                     {'loss': 0.2296, 'grad_norm': 0.51171875, 'learning_rate': 7.225970912381557e-06, 'epoch': 1.2}
 60%|██████    | 469/780 [7:03:44<4:41:20, 54.28s/it] 60%|██████    | 470/780 [7:04:38<4:40:27, 54.28s/it]                                                     {'loss': 0.2642, 'grad_norm': 0.52734375, 'learning_rate': 7.1862802955920365e-06, 'epoch': 1.2}
 60%|██████    | 470/780 [7:04:39<4:40:27, 54.28s/it] 60%|██████    | 471/780 [7:05:33<4:39:41, 54.31s/it]                                                     {'loss': 0.2384, 'grad_norm': 0.494140625, 'learning_rate': 7.14663775750895e-06, 'epoch': 1.2}
 60%|██████    | 471/780 [7:05:33<4:39:41, 54.31s/it] 61%|██████    | 472/780 [7:06:27<4:38:44, 54.30s/it]                                                     {'loss': 0.2038, 'grad_norm': 0.478515625, 'learning_rate': 7.1070439755138905e-06, 'epoch': 1.21}
 61%|██████    | 472/780 [7:06:27<4:38:44, 54.30s/it] 61%|██████    | 473/780 [7:07:21<4:37:37, 54.26s/it]                                                     {'loss': 0.2571, 'grad_norm': 0.5078125, 'learning_rate': 7.067499626155354e-06, 'epoch': 1.21}
 61%|██████    | 473/780 [7:07:21<4:37:37, 54.26s/it] 61%|██████    | 474/780 [7:08:15<4:36:40, 54.25s/it]                                                     {'loss': 0.2067, 'grad_norm': 0.6328125, 'learning_rate': 7.028005385137162e-06, 'epoch': 1.21}
 61%|██████    | 474/780 [7:08:16<4:36:40, 54.25s/it] 61%|██████    | 475/780 [7:09:10<4:35:57, 54.29s/it]                                                     {'loss': 0.2281, 'grad_norm': 0.458984375, 'learning_rate': 6.988561927306927e-06, 'epoch': 1.22}
 61%|██████    | 475/780 [7:09:10<4:35:57, 54.29s/it] 61%|██████    | 476/780 [7:10:04<4:35:04, 54.29s/it]                                                     {'loss': 0.24, 'grad_norm': 0.5390625, 'learning_rate': 6.949169926644513e-06, 'epoch': 1.22}
 61%|██████    | 476/780 [7:10:04<4:35:04, 54.29s/it] 61%|██████    | 477/780 [7:10:58<4:33:58, 54.25s/it]                                                     {'loss': 0.2535, 'grad_norm': 0.58984375, 'learning_rate': 6.909830056250527e-06, 'epoch': 1.22}
 61%|██████    | 477/780 [7:10:58<4:33:58, 54.25s/it] 61%|██████▏   | 478/780 [7:11:53<4:32:57, 54.23s/it]                                                     {'loss': 0.2301, 'grad_norm': 0.6484375, 'learning_rate': 6.8705429883348095e-06, 'epoch': 1.22}
 61%|██████▏   | 478/780 [7:11:53<4:32:57, 54.23s/it] 61%|██████▏   | 479/780 [7:12:46<4:31:29, 54.12s/it]                                                     {'loss': 0.2136, 'grad_norm': 0.50390625, 'learning_rate': 6.831309394204957e-06, 'epoch': 1.23}
 61%|██████▏   | 479/780 [7:12:46<4:31:29, 54.12s/it] 62%|██████▏   | 480/780 [7:13:41<4:30:43, 54.15s/it]                                                     {'loss': 0.2189, 'grad_norm': 0.5390625, 'learning_rate': 6.7921299442548425e-06, 'epoch': 1.23}
 62%|██████▏   | 480/780 [7:13:41<4:30:43, 54.15s/it] 62%|██████▏   | 481/780 [7:14:35<4:29:53, 54.16s/it]                                                     {'loss': 0.2411, 'grad_norm': 0.5546875, 'learning_rate': 6.7530053079531664e-06, 'epoch': 1.23}
 62%|██████▏   | 481/780 [7:14:35<4:29:53, 54.16s/it] 62%|██████▏   | 482/780 [7:15:29<4:29:14, 54.21s/it]                                                     {'loss': 0.2167, 'grad_norm': 0.51171875, 'learning_rate': 6.713936153832012e-06, 'epoch': 1.23}
 62%|██████▏   | 482/780 [7:15:29<4:29:14, 54.21s/it] 62%|██████▏   | 483/780 [7:16:23<4:28:24, 54.22s/it]                                                     {'loss': 0.2077, 'grad_norm': 0.5703125, 'learning_rate': 6.674923149475433e-06, 'epoch': 1.24}
 62%|██████▏   | 483/780 [7:16:23<4:28:24, 54.22s/it] 62%|██████▏   | 484/780 [7:17:18<4:27:41, 54.26s/it]                                                     {'loss': 0.2336, 'grad_norm': 0.51171875, 'learning_rate': 6.635966961508031e-06, 'epoch': 1.24}
 62%|██████▏   | 484/780 [7:17:18<4:27:41, 54.26s/it] 62%|██████▏   | 485/780 [7:18:12<4:26:45, 54.26s/it]                                                     {'loss': 0.2261, 'grad_norm': 0.578125, 'learning_rate': 6.59706825558357e-06, 'epoch': 1.24}
 62%|██████▏   | 485/780 [7:18:12<4:26:45, 54.26s/it] 62%|██████▏   | 486/780 [7:19:06<4:25:54, 54.27s/it]                                                     {'loss': 0.2318, 'grad_norm': 0.5703125, 'learning_rate': 6.558227696373617e-06, 'epoch': 1.24}
 62%|██████▏   | 486/780 [7:19:06<4:25:54, 54.27s/it] 62%|██████▏   | 487/780 [7:20:01<4:25:13, 54.31s/it]                                                     {'loss': 0.2665, 'grad_norm': 0.515625, 'learning_rate': 6.519445947556156e-06, 'epoch': 1.25}
 62%|██████▏   | 487/780 [7:20:01<4:25:13, 54.31s/it] 63%|██████▎   | 488/780 [7:20:55<4:24:31, 54.35s/it]                                                     {'loss': 0.2363, 'grad_norm': 0.546875, 'learning_rate': 6.480723671804281e-06, 'epoch': 1.25}
 63%|██████▎   | 488/780 [7:20:55<4:24:31, 54.35s/it] 63%|██████▎   | 489/780 [7:21:49<4:23:36, 54.35s/it]                                                     {'loss': 0.2184, 'grad_norm': 0.515625, 'learning_rate': 6.442061530774835e-06, 'epoch': 1.25}
 63%|██████▎   | 489/780 [7:21:50<4:23:36, 54.35s/it] 63%|██████▎   | 490/780 [7:22:44<4:22:38, 54.34s/it]                                                     {'loss': 0.197, 'grad_norm': 0.54296875, 'learning_rate': 6.4034601850971475e-06, 'epoch': 1.25}
 63%|██████▎   | 490/780 [7:22:44<4:22:38, 54.34s/it] 63%|██████▎   | 491/780 [7:23:38<4:21:02, 54.20s/it]                                                     {'loss': 0.22, 'grad_norm': 0.55859375, 'learning_rate': 6.364920294361701e-06, 'epoch': 1.26}
 63%|██████▎   | 491/780 [7:23:38<4:21:02, 54.20s/it] 63%|██████▎   | 492/780 [7:24:32<4:20:18, 54.23s/it]                                                     {'loss': 0.2301, 'grad_norm': 0.58203125, 'learning_rate': 6.326442517108901e-06, 'epoch': 1.26}
 63%|██████▎   | 492/780 [7:24:32<4:20:18, 54.23s/it] 63%|██████▎   | 493/780 [7:25:26<4:19:32, 54.26s/it]                                                     {'loss': 0.2126, 'grad_norm': 0.5234375, 'learning_rate': 6.2880275108177915e-06, 'epoch': 1.26}
 63%|██████▎   | 493/780 [7:25:26<4:19:32, 54.26s/it] 63%|██████▎   | 494/780 [7:26:21<4:18:50, 54.30s/it]                                                     {'loss': 0.2612, 'grad_norm': 0.5, 'learning_rate': 6.249675931894845e-06, 'epoch': 1.26}
 63%|██████▎   | 494/780 [7:26:21<4:18:50, 54.30s/it] 63%|██████▎   | 495/780 [7:27:15<4:17:55, 54.30s/it]                                                     {'loss': 0.1924, 'grad_norm': 0.5546875, 'learning_rate': 6.211388435662722e-06, 'epoch': 1.27}
 63%|██████▎   | 495/780 [7:27:15<4:17:55, 54.30s/it] 64%|██████▎   | 496/780 [7:28:09<4:16:56, 54.28s/it]                                                     {'loss': 0.2342, 'grad_norm': 0.609375, 'learning_rate': 6.173165676349103e-06, 'epoch': 1.27}
 64%|██████▎   | 496/780 [7:28:09<4:16:56, 54.28s/it] 64%|██████▎   | 497/780 [7:29:04<4:16:05, 54.30s/it]                                                     {'loss': 0.2142, 'grad_norm': 0.59375, 'learning_rate': 6.13500830707548e-06, 'epoch': 1.27}
 64%|██████▎   | 497/780 [7:29:04<4:16:05, 54.30s/it] 64%|██████▍   | 498/780 [7:29:58<4:15:05, 54.28s/it]                                                     {'loss': 0.2463, 'grad_norm': 0.53515625, 'learning_rate': 6.0969169798460105e-06, 'epoch': 1.27}
 64%|██████▍   | 498/780 [7:29:58<4:15:05, 54.28s/it] 64%|██████▍   | 499/780 [7:30:52<4:14:15, 54.29s/it]                                                     {'loss': 0.2359, 'grad_norm': 0.51171875, 'learning_rate': 6.058892345536387e-06, 'epoch': 1.28}
 64%|██████▍   | 499/780 [7:30:52<4:14:15, 54.29s/it] 64%|██████▍   | 500/780 [7:31:46<4:13:19, 54.28s/it]                                                     {'loss': 0.2325, 'grad_norm': 0.498046875, 'learning_rate': 6.020935053882688e-06, 'epoch': 1.28}
 64%|██████▍   | 500/780 [7:31:46<4:13:19, 54.28s/it] 64%|██████▍   | 501/780 [7:32:41<4:12:17, 54.26s/it]                                                     {'loss': 0.1999, 'grad_norm': 0.474609375, 'learning_rate': 5.983045753470308e-06, 'epoch': 1.28}
 64%|██████▍   | 501/780 [7:32:41<4:12:17, 54.26s/it] 64%|██████▍   | 502/780 [7:33:35<4:11:27, 54.27s/it]                                                     {'loss': 0.2264, 'grad_norm': 0.51171875, 'learning_rate': 5.9452250917228434e-06, 'epoch': 1.28}
 64%|██████▍   | 502/780 [7:33:35<4:11:27, 54.27s/it] 64%|██████▍   | 503/780 [7:34:29<4:10:34, 54.28s/it]                                                     {'loss': 0.2584, 'grad_norm': 0.53515625, 'learning_rate': 5.907473714891061e-06, 'epoch': 1.29}
 64%|██████▍   | 503/780 [7:34:29<4:10:34, 54.28s/it] 65%|██████▍   | 504/780 [7:35:24<4:09:49, 54.31s/it]                                                     {'loss': 0.2438, 'grad_norm': 0.53125, 'learning_rate': 5.869792268041824e-06, 'epoch': 1.29}
 65%|██████▍   | 504/780 [7:35:24<4:09:49, 54.31s/it] 65%|██████▍   | 505/780 [7:36:18<4:08:53, 54.30s/it]                                                     {'loss': 0.2352, 'grad_norm': 0.62109375, 'learning_rate': 5.832181395047099e-06, 'epoch': 1.29}
 65%|██████▍   | 505/780 [7:36:18<4:08:53, 54.30s/it] 65%|██████▍   | 506/780 [7:37:12<4:07:58, 54.30s/it]                                                     {'loss': 0.1986, 'grad_norm': 0.494140625, 'learning_rate': 5.794641738572925e-06, 'epoch': 1.29}
 65%|██████▍   | 506/780 [7:37:12<4:07:58, 54.30s/it] 65%|██████▌   | 507/780 [7:38:06<4:06:54, 54.26s/it]                                                     {'loss': 0.2745, 'grad_norm': 0.51171875, 'learning_rate': 5.7571739400684644e-06, 'epoch': 1.3}
 65%|██████▌   | 507/780 [7:38:06<4:06:54, 54.26s/it] 65%|██████▌   | 508/780 [7:39:01<4:06:09, 54.30s/it]                                                     {'loss': 0.232, 'grad_norm': 0.49609375, 'learning_rate': 5.7197786397550096e-06, 'epoch': 1.3}
 65%|██████▌   | 508/780 [7:39:01<4:06:09, 54.30s/it] 65%|██████▌   | 509/780 [7:39:55<4:05:19, 54.31s/it]                                                     {'loss': 0.2389, 'grad_norm': 0.5, 'learning_rate': 5.6824564766150724e-06, 'epoch': 1.3}
 65%|██████▌   | 509/780 [7:39:55<4:05:19, 54.31s/it] 65%|██████▌   | 510/780 [7:40:49<4:04:21, 54.30s/it]                                                     {'loss': 0.1989, 'grad_norm': 0.494140625, 'learning_rate': 5.645208088381442e-06, 'epoch': 1.3}
 65%|██████▌   | 510/780 [7:40:49<4:04:21, 54.30s/it] 66%|██████▌   | 511/780 [7:41:44<4:03:22, 54.29s/it]                                                     {'loss': 0.2975, 'grad_norm': 0.609375, 'learning_rate': 5.608034111526298e-06, 'epoch': 1.31}
 66%|██████▌   | 511/780 [7:41:44<4:03:22, 54.29s/it] 66%|██████▌   | 512/780 [7:42:38<4:02:37, 54.32s/it]                                                     {'loss': 0.2015, 'grad_norm': 0.494140625, 'learning_rate': 5.570935181250346e-06, 'epoch': 1.31}
 66%|██████▌   | 512/780 [7:42:38<4:02:37, 54.32s/it] 66%|██████▌   | 513/780 [7:43:32<4:01:48, 54.34s/it]                                                     {'loss': 0.2396, 'grad_norm': 0.55078125, 'learning_rate': 5.533911931471936e-06, 'epoch': 1.31}
 66%|██████▌   | 513/780 [7:43:32<4:01:48, 54.34s/it] 66%|██████▌   | 514/780 [7:44:27<4:00:53, 54.34s/it]                                                     {'loss': 0.2707, 'grad_norm': 0.58203125, 'learning_rate': 5.496964994816265e-06, 'epoch': 1.31}
 66%|██████▌   | 514/780 [7:44:27<4:00:53, 54.34s/it] 66%|██████▌   | 515/780 [7:45:21<3:59:59, 54.34s/it]                                                     {'loss': 0.2605, 'grad_norm': 0.6171875, 'learning_rate': 5.460095002604533e-06, 'epoch': 1.32}
 66%|██████▌   | 515/780 [7:45:21<3:59:59, 54.34s/it] 66%|██████▌   | 516/780 [7:46:15<3:59:01, 54.32s/it]                                                     {'loss': 0.2205, 'grad_norm': 0.58203125, 'learning_rate': 5.423302584843186e-06, 'epoch': 1.32}
 66%|██████▌   | 516/780 [7:46:15<3:59:01, 54.32s/it] 66%|██████▋   | 517/780 [7:47:10<3:58:01, 54.30s/it]                                                     {'loss': 0.238, 'grad_norm': 0.5546875, 'learning_rate': 5.386588370213124e-06, 'epoch': 1.32}
 66%|██████▋   | 517/780 [7:47:10<3:58:01, 54.30s/it] 66%|██████▋   | 518/780 [7:48:04<3:57:00, 54.28s/it]                                                     {'loss': 0.2172, 'grad_norm': 0.55859375, 'learning_rate': 5.349952986058981e-06, 'epoch': 1.33}
 66%|██████▋   | 518/780 [7:48:04<3:57:00, 54.28s/it] 67%|██████▋   | 519/780 [7:48:58<3:56:10, 54.29s/it]                                                     {'loss': 0.2445, 'grad_norm': 0.498046875, 'learning_rate': 5.3133970583783865e-06, 'epoch': 1.33}
 67%|██████▋   | 519/780 [7:48:58<3:56:10, 54.29s/it] 67%|██████▋   | 520/780 [7:49:52<3:55:18, 54.30s/it]                                                     {'loss': 0.2263, 'grad_norm': 0.486328125, 'learning_rate': 5.276921211811293e-06, 'epoch': 1.33}
 67%|██████▋   | 520/780 [7:49:52<3:55:18, 54.30s/it] 67%|██████▋   | 521/780 [7:50:47<3:54:24, 54.30s/it]                                                     {'loss': 0.2344, 'grad_norm': 0.50390625, 'learning_rate': 5.240526069629265e-06, 'epoch': 1.33}
 67%|██████▋   | 521/780 [7:50:47<3:54:24, 54.30s/it] 67%|██████▋   | 522/780 [7:51:41<3:53:39, 54.34s/it]                                                     {'loss': 0.2291, 'grad_norm': 0.462890625, 'learning_rate': 5.204212253724876e-06, 'epoch': 1.34}
 67%|██████▋   | 522/780 [7:51:41<3:53:39, 54.34s/it] 67%|██████▋   | 523/780 [7:52:35<3:52:35, 54.30s/it]                                                     {'loss': 0.2456, 'grad_norm': 0.5546875, 'learning_rate': 5.167980384601041e-06, 'epoch': 1.34}
 67%|██████▋   | 523/780 [7:52:35<3:52:35, 54.30s/it] 67%|██████▋   | 524/780 [7:53:30<3:51:37, 54.29s/it]                                                     {'loss': 0.2077, 'grad_norm': 0.490234375, 'learning_rate': 5.131831081360439e-06, 'epoch': 1.34}
 67%|██████▋   | 524/780 [7:53:30<3:51:37, 54.29s/it] 67%|██████▋   | 525/780 [7:54:24<3:50:39, 54.27s/it]                                                     {'loss': 0.2516, 'grad_norm': 0.50390625, 'learning_rate': 5.095764961694923e-06, 'epoch': 1.34}
 67%|██████▋   | 525/780 [7:54:24<3:50:39, 54.27s/it] 67%|██████▋   | 526/780 [7:55:18<3:49:37, 54.24s/it]                                                     {'loss': 0.2143, 'grad_norm': 0.53515625, 'learning_rate': 5.059782641874962e-06, 'epoch': 1.35}
 67%|██████▋   | 526/780 [7:55:18<3:49:37, 54.24s/it] 68%|██████▊   | 527/780 [7:56:12<3:48:41, 54.23s/it]                                                     {'loss': 0.2288, 'grad_norm': 0.51953125, 'learning_rate': 5.023884736739132e-06, 'epoch': 1.35}
 68%|██████▊   | 527/780 [7:56:12<3:48:41, 54.23s/it] 68%|██████▊   | 528/780 [7:57:06<3:47:44, 54.23s/it]                                                     {'loss': 0.2322, 'grad_norm': 0.482421875, 'learning_rate': 4.988071859683579e-06, 'epoch': 1.35}
 68%|██████▊   | 528/780 [7:57:06<3:47:44, 54.23s/it] 68%|██████▊   | 529/780 [7:58:01<3:46:44, 54.20s/it]                                                     {'loss': 0.2098, 'grad_norm': 0.57421875, 'learning_rate': 4.952344622651566e-06, 'epoch': 1.35}
 68%|██████▊   | 529/780 [7:58:01<3:46:44, 54.20s/it] 68%|██████▊   | 530/780 [7:58:55<3:45:50, 54.20s/it]                                                     {'loss': 0.2444, 'grad_norm': 0.54296875, 'learning_rate': 4.916703636122995e-06, 'epoch': 1.36}
 68%|██████▊   | 530/780 [7:58:55<3:45:50, 54.20s/it] 68%|██████▊   | 531/780 [7:59:49<3:45:04, 54.24s/it]                                                     {'loss': 0.2273, 'grad_norm': 0.482421875, 'learning_rate': 4.881149509103993e-06, 'epoch': 1.36}
 68%|██████▊   | 531/780 [7:59:49<3:45:04, 54.24s/it] 68%|██████▊   | 532/780 [8:00:43<3:44:07, 54.22s/it]                                                     {'loss': 0.2183, 'grad_norm': 0.55078125, 'learning_rate': 4.845682849116489e-06, 'epoch': 1.36}
 68%|██████▊   | 532/780 [8:00:43<3:44:07, 54.22s/it] 68%|██████▊   | 533/780 [8:01:38<3:43:21, 54.26s/it]                                                     {'loss': 0.2424, 'grad_norm': 0.5078125, 'learning_rate': 4.8103042621878515e-06, 'epoch': 1.36}
 68%|██████▊   | 533/780 [8:01:38<3:43:21, 54.26s/it] 68%|██████▊   | 534/780 [8:02:32<3:42:27, 54.26s/it]                                                     {'loss': 0.2236, 'grad_norm': 0.5, 'learning_rate': 4.775014352840512e-06, 'epoch': 1.37}
 68%|██████▊   | 534/780 [8:02:32<3:42:27, 54.26s/it] 69%|██████▊   | 535/780 [8:03:26<3:41:36, 54.27s/it]                                                     {'loss': 0.2085, 'grad_norm': 0.478515625, 'learning_rate': 4.739813724081661e-06, 'epoch': 1.37}
 69%|██████▊   | 535/780 [8:03:26<3:41:36, 54.27s/it] 69%|██████▊   | 536/780 [8:04:20<3:40:41, 54.27s/it]                                                     {'loss': 0.2083, 'grad_norm': 0.51953125, 'learning_rate': 4.704702977392914e-06, 'epoch': 1.37}
 69%|██████▊   | 536/780 [8:04:21<3:40:41, 54.27s/it] 69%|██████▉   | 537/780 [8:05:15<3:39:53, 54.29s/it]                                                     {'loss': 0.204, 'grad_norm': 0.470703125, 'learning_rate': 4.669682712720065e-06, 'epoch': 1.37}
 69%|██████▉   | 537/780 [8:05:15<3:39:53, 54.29s/it] 69%|██████▉   | 538/780 [8:06:09<3:39:08, 54.33s/it]                                                     {'loss': 0.2887, 'grad_norm': 0.498046875, 'learning_rate': 4.634753528462806e-06, 'epoch': 1.38}
 69%|██████▉   | 538/780 [8:06:09<3:39:08, 54.33s/it] 69%|██████▉   | 539/780 [8:07:03<3:37:58, 54.27s/it]                                                     {'loss': 0.1893, 'grad_norm': 0.53515625, 'learning_rate': 4.599916021464531e-06, 'epoch': 1.38}
 69%|██████▉   | 539/780 [8:07:03<3:37:58, 54.27s/it] 69%|██████▉   | 540/780 [8:07:58<3:36:58, 54.24s/it]                                                     {'loss': 0.2247, 'grad_norm': 0.55859375, 'learning_rate': 4.565170787002108e-06, 'epoch': 1.38}
 69%|██████▉   | 540/780 [8:07:58<3:36:58, 54.24s/it] 69%|██████▉   | 541/780 [8:08:52<3:36:11, 54.27s/it]                                                     {'loss': 0.2353, 'grad_norm': 0.546875, 'learning_rate': 4.530518418775734e-06, 'epoch': 1.38}
 69%|██████▉   | 541/780 [8:08:52<3:36:11, 54.27s/it] 69%|██████▉   | 542/780 [8:09:46<3:35:16, 54.27s/it]                                                     {'loss': 0.2068, 'grad_norm': 0.5390625, 'learning_rate': 4.495959508898766e-06, 'epoch': 1.39}
 69%|██████▉   | 542/780 [8:09:46<3:35:16, 54.27s/it] 70%|██████▉   | 543/780 [8:10:40<3:34:23, 54.28s/it]                                                     {'loss': 0.2421, 'grad_norm': 0.50390625, 'learning_rate': 4.4614946478876305e-06, 'epoch': 1.39}
 70%|██████▉   | 543/780 [8:10:40<3:34:23, 54.28s/it] 70%|██████▉   | 544/780 [8:11:35<3:33:23, 54.25s/it]                                                     {'loss': 0.2344, 'grad_norm': 0.546875, 'learning_rate': 4.427124424651703e-06, 'epoch': 1.39}
 70%|██████▉   | 544/780 [8:11:35<3:33:23, 54.25s/it] 70%|██████▉   | 545/780 [8:12:29<3:32:32, 54.27s/it]                                                     {'loss': 0.2329, 'grad_norm': 0.51953125, 'learning_rate': 4.392849426483275e-06, 'epoch': 1.39}
 70%|██████▉   | 545/780 [8:12:29<3:32:32, 54.27s/it] 70%|███████   | 546/780 [8:13:23<3:31:33, 54.25s/it]                                                     {'loss': 0.204, 'grad_norm': 0.515625, 'learning_rate': 4.35867023904749e-06, 'epoch': 1.4}
 70%|███████   | 546/780 [8:13:23<3:31:33, 54.25s/it] 70%|███████   | 547/780 [8:14:17<3:30:30, 54.21s/it]                                                     {'loss': 0.2431, 'grad_norm': 0.5703125, 'learning_rate': 4.324587446372365e-06, 'epoch': 1.4}
 70%|███████   | 547/780 [8:14:17<3:30:30, 54.21s/it] 70%|███████   | 548/780 [8:15:11<3:29:29, 54.18s/it]                                                     {'loss': 0.2583, 'grad_norm': 0.58984375, 'learning_rate': 4.290601630838781e-06, 'epoch': 1.4}
 70%|███████   | 548/780 [8:15:11<3:29:29, 54.18s/it] 70%|███████   | 549/780 [8:16:06<3:28:48, 54.24s/it]                                                     {'loss': 0.2101, 'grad_norm': 0.484375, 'learning_rate': 4.256713373170565e-06, 'epoch': 1.4}
 70%|███████   | 549/780 [8:16:06<3:28:48, 54.24s/it] 71%|███████   | 550/780 [8:17:00<3:27:51, 54.22s/it]                                                     {'loss': 0.1987, 'grad_norm': 0.515625, 'learning_rate': 4.22292325242453e-06, 'epoch': 1.41}
 71%|███████   | 550/780 [8:17:00<3:27:51, 54.22s/it] 71%|███████   | 551/780 [8:17:54<3:26:58, 54.23s/it]                                                     {'loss': 0.1874, 'grad_norm': 0.54296875, 'learning_rate': 4.189231845980618e-06, 'epoch': 1.41}
 71%|███████   | 551/780 [8:17:54<3:26:58, 54.23s/it] 71%|███████   | 552/780 [8:18:48<3:26:03, 54.23s/it]                                                     {'loss': 0.2003, 'grad_norm': 0.515625, 'learning_rate': 4.155639729532e-06, 'epoch': 1.41}
 71%|███████   | 552/780 [8:18:48<3:26:03, 54.23s/it] 71%|███████   | 553/780 [8:19:43<3:25:09, 54.23s/it]                                                     {'loss': 0.2344, 'grad_norm': 0.5234375, 'learning_rate': 4.12214747707527e-06, 'epoch': 1.41}
 71%|███████   | 553/780 [8:19:43<3:25:09, 54.23s/it] 71%|███████   | 554/780 [8:20:37<3:24:18, 54.24s/it]                                                     {'loss': 0.2682, 'grad_norm': 0.515625, 'learning_rate': 4.0887556609006055e-06, 'epoch': 1.42}
 71%|███████   | 554/780 [8:20:37<3:24:18, 54.24s/it] 71%|███████   | 555/780 [8:21:31<3:22:47, 54.08s/it]                                                     {'loss': 0.2289, 'grad_norm': 0.59375, 'learning_rate': 4.055464851582022e-06, 'epoch': 1.42}
 71%|███████   | 555/780 [8:21:31<3:22:47, 54.08s/it] 71%|███████▏  | 556/780 [8:22:25<3:22:06, 54.14s/it]                                                     {'loss': 0.231, 'grad_norm': 0.50390625, 'learning_rate': 4.0222756179675915e-06, 'epoch': 1.42}
 71%|███████▏  | 556/780 [8:22:25<3:22:06, 54.14s/it] 71%|███████▏  | 557/780 [8:23:19<3:21:24, 54.19s/it]                                                     {'loss': 0.2254, 'grad_norm': 0.6015625, 'learning_rate': 3.989188527169749e-06, 'epoch': 1.42}
 71%|███████▏  | 557/780 [8:23:19<3:21:24, 54.19s/it] 72%|███████▏  | 558/780 [8:24:14<3:20:43, 54.25s/it]                                                     {'loss': 0.2287, 'grad_norm': 0.48046875, 'learning_rate': 3.956204144555582e-06, 'epoch': 1.43}
 72%|███████▏  | 558/780 [8:24:14<3:20:43, 54.25s/it] 72%|███████▏  | 559/780 [8:25:08<3:19:57, 54.29s/it]                                                     {'loss': 0.1941, 'grad_norm': 0.53515625, 'learning_rate': 3.923323033737188e-06, 'epoch': 1.43}
 72%|███████▏  | 559/780 [8:25:08<3:19:57, 54.29s/it] 72%|███████▏  | 560/780 [8:26:02<3:19:04, 54.29s/it]                                                     {'loss': 0.1982, 'grad_norm': 0.455078125, 'learning_rate': 3.890545756562022e-06, 'epoch': 1.43}
 72%|███████▏  | 560/780 [8:26:02<3:19:04, 54.29s/it] 72%|███████▏  | 561/780 [8:26:57<3:18:22, 54.35s/it]                                                     {'loss': 0.2221, 'grad_norm': 0.5078125, 'learning_rate': 3.857872873103322e-06, 'epoch': 1.44}
 72%|███████▏  | 561/780 [8:26:57<3:18:22, 54.35s/it] 72%|███████▏  | 562/780 [8:27:51<3:17:39, 54.40s/it]                                                     {'loss': 0.193, 'grad_norm': 0.52734375, 'learning_rate': 3.825304941650512e-06, 'epoch': 1.44}
 72%|███████▏  | 562/780 [8:27:51<3:17:39, 54.40s/it] 72%|███████▏  | 563/780 [8:28:45<3:16:27, 54.32s/it]                                                     {'loss': 0.2473, 'grad_norm': 0.56640625, 'learning_rate': 3.792842518699689e-06, 'epoch': 1.44}
 72%|███████▏  | 563/780 [8:28:45<3:16:27, 54.32s/it] 72%|███████▏  | 564/780 [8:29:40<3:15:27, 54.30s/it]                                                     {'loss': 0.2851, 'grad_norm': 0.58203125, 'learning_rate': 3.7604861589440913e-06, 'epoch': 1.44}
 72%|███████▏  | 564/780 [8:29:40<3:15:27, 54.30s/it] 72%|███████▏  | 565/780 [8:30:34<3:14:36, 54.31s/it]                                                     {'loss': 0.218, 'grad_norm': 0.515625, 'learning_rate': 3.72823641526463e-06, 'epoch': 1.45}
 72%|███████▏  | 565/780 [8:30:34<3:14:36, 54.31s/it] 73%|███████▎  | 566/780 [8:31:28<3:13:43, 54.32s/it]                                                     {'loss': 0.2263, 'grad_norm': 0.47265625, 'learning_rate': 3.69609383872045e-06, 'epoch': 1.45}
 73%|███████▎  | 566/780 [8:31:28<3:13:43, 54.32s/it] 73%|███████▎  | 567/780 [8:32:22<3:12:42, 54.28s/it]                                                     {'loss': 0.2392, 'grad_norm': 0.59375, 'learning_rate': 3.6640589785394955e-06, 'epoch': 1.45}
 73%|███████▎  | 567/780 [8:32:23<3:12:42, 54.28s/it] 73%|███████▎  | 568/780 [8:33:17<3:11:45, 54.27s/it]                                                     {'loss': 0.2386, 'grad_norm': 0.73046875, 'learning_rate': 3.6321323821091434e-06, 'epoch': 1.45}
 73%|███████▎  | 568/780 [8:33:17<3:11:45, 54.27s/it] 73%|███████▎  | 569/780 [8:34:11<3:10:36, 54.20s/it]                                                     {'loss': 0.2179, 'grad_norm': 0.59765625, 'learning_rate': 3.6003145949668338e-06, 'epoch': 1.46}
 73%|███████▎  | 569/780 [8:34:11<3:10:36, 54.20s/it] 73%|███████▎  | 570/780 [8:35:05<3:09:41, 54.20s/it]                                                     {'loss': 0.1826, 'grad_norm': 0.4609375, 'learning_rate': 3.5686061607907674e-06, 'epoch': 1.46}
 73%|███████▎  | 570/780 [8:35:05<3:09:41, 54.20s/it] 73%|███████▎  | 571/780 [8:35:59<3:08:54, 54.23s/it]                                                     {'loss': 0.2016, 'grad_norm': 0.490234375, 'learning_rate': 3.5370076213905904e-06, 'epoch': 1.46}
 73%|███████▎  | 571/780 [8:35:59<3:08:54, 54.23s/it] 73%|███████▎  | 572/780 [8:36:54<3:08:00, 54.23s/it]                                                     {'loss': 0.2468, 'grad_norm': 0.578125, 'learning_rate': 3.505519516698165e-06, 'epoch': 1.46}
 73%|███████▎  | 572/780 [8:36:54<3:08:00, 54.23s/it] 73%|███████▎  | 573/780 [8:37:48<3:07:11, 54.26s/it]                                                     {'loss': 0.2454, 'grad_norm': 0.546875, 'learning_rate': 3.4741423847583134e-06, 'epoch': 1.47}
 73%|███████▎  | 573/780 [8:37:48<3:07:11, 54.26s/it] 74%|███████▎  | 574/780 [8:38:42<3:06:07, 54.21s/it]                                                     {'loss': 0.2264, 'grad_norm': 0.515625, 'learning_rate': 3.442876761719657e-06, 'epoch': 1.47}
 74%|███████▎  | 574/780 [8:38:42<3:06:07, 54.21s/it] 74%|███████▎  | 575/780 [8:39:36<3:05:06, 54.18s/it]                                                     {'loss': 0.2822, 'grad_norm': 0.60546875, 'learning_rate': 3.4117231818254205e-06, 'epoch': 1.47}
 74%|███████▎  | 575/780 [8:39:36<3:05:06, 54.18s/it] 74%|███████▍  | 576/780 [8:40:30<3:04:11, 54.17s/it]                                                     {'loss': 0.2471, 'grad_norm': 0.53125, 'learning_rate': 3.380682177404335e-06, 'epoch': 1.47}
 74%|███████▍  | 576/780 [8:40:30<3:04:11, 54.17s/it] 74%|███████▍  | 577/780 [8:41:25<3:03:30, 54.24s/it]                                                     {'loss': 0.2508, 'grad_norm': 0.455078125, 'learning_rate': 3.349754278861517e-06, 'epoch': 1.48}
 74%|███████▍  | 577/780 [8:41:25<3:03:30, 54.24s/it] 74%|███████▍  | 578/780 [8:42:19<3:02:40, 54.26s/it]                                                     {'loss': 0.2346, 'grad_norm': 0.51953125, 'learning_rate': 3.318940014669423e-06, 'epoch': 1.48}
 74%|███████▍  | 578/780 [8:42:19<3:02:40, 54.26s/it] 74%|███████▍  | 579/780 [8:43:13<3:01:57, 54.32s/it]                                                     {'loss': 0.2284, 'grad_norm': 0.458984375, 'learning_rate': 3.288239911358807e-06, 'epoch': 1.48}
 74%|███████▍  | 579/780 [8:43:13<3:01:57, 54.32s/it] 74%|███████▍  | 580/780 [8:44:08<3:00:59, 54.30s/it]                                                     {'loss': 0.2516, 'grad_norm': 0.578125, 'learning_rate': 3.2576544935097264e-06, 'epoch': 1.48}
 74%|███████▍  | 580/780 [8:44:08<3:00:59, 54.30s/it] 74%|███████▍  | 581/780 [8:45:02<3:00:08, 54.31s/it]                                                     {'loss': 0.2362, 'grad_norm': 0.578125, 'learning_rate': 3.2271842837425917e-06, 'epoch': 1.49}
 74%|███████▍  | 581/780 [8:45:02<3:00:08, 54.31s/it] 75%|███████▍  | 582/780 [8:45:56<2:59:10, 54.30s/it]                                                     {'loss': 0.2322, 'grad_norm': 0.57421875, 'learning_rate': 3.196829802709209e-06, 'epoch': 1.49}
 75%|███████▍  | 582/780 [8:45:56<2:59:10, 54.30s/it] 75%|███████▍  | 583/780 [8:46:50<2:58:10, 54.27s/it]                                                     {'loss': 0.2677, 'grad_norm': 0.5546875, 'learning_rate': 3.1665915690839165e-06, 'epoch': 1.49}
 75%|███████▍  | 583/780 [8:46:50<2:58:10, 54.27s/it] 75%|███████▍  | 584/780 [8:47:45<2:57:29, 54.34s/it]                                                     {'loss': 0.2214, 'grad_norm': 0.46875, 'learning_rate': 3.1364700995546906e-06, 'epoch': 1.49}
 75%|███████▍  | 584/780 [8:47:45<2:57:29, 54.34s/it] 75%|███████▌  | 585/780 [8:48:39<2:56:38, 54.35s/it]                                                     {'loss': 0.2402, 'grad_norm': 0.5546875, 'learning_rate': 3.1064659088143424e-06, 'epoch': 1.5}
 75%|███████▌  | 585/780 [8:48:39<2:56:38, 54.35s/it] 75%|███████▌  | 586/780 [8:49:33<2:55:35, 54.31s/it]                                                     {'loss': 0.2165, 'grad_norm': 0.5546875, 'learning_rate': 3.0765795095517026e-06, 'epoch': 1.5}
 75%|███████▌  | 586/780 [8:49:34<2:55:35, 54.31s/it] 75%|███████▌  | 587/780 [8:50:28<2:54:34, 54.27s/it]                                                     {'loss': 0.1943, 'grad_norm': 0.53125, 'learning_rate': 3.0468114124428806e-06, 'epoch': 1.5}
 75%|███████▌  | 587/780 [8:50:28<2:54:34, 54.27s/it] 75%|███████▌  | 588/780 [8:51:22<2:53:46, 54.31s/it]                                                     {'loss': 0.2631, 'grad_norm': 0.5546875, 'learning_rate': 3.0171621261425164e-06, 'epoch': 1.5}
 75%|███████▌  | 588/780 [8:51:22<2:53:46, 54.31s/it] 76%|███████▌  | 589/780 [8:52:16<2:52:55, 54.32s/it]                                                     {'loss': 0.2446, 'grad_norm': 0.5078125, 'learning_rate': 2.9876321572751143e-06, 'epoch': 1.51}
 76%|███████▌  | 589/780 [8:52:16<2:52:55, 54.32s/it] 76%|███████▌  | 590/780 [8:53:11<2:52:04, 54.34s/it]                                                     {'loss': 0.235, 'grad_norm': 0.478515625, 'learning_rate': 2.9582220104263603e-06, 'epoch': 1.51}
 76%|███████▌  | 590/780 [8:53:11<2:52:04, 54.34s/it] 76%|███████▌  | 591/780 [8:54:05<2:51:06, 54.32s/it]                                                     {'loss': 0.2413, 'grad_norm': 0.55859375, 'learning_rate': 2.9289321881345257e-06, 'epoch': 1.51}
 76%|███████▌  | 591/780 [8:54:05<2:51:06, 54.32s/it] 76%|███████▌  | 592/780 [8:54:59<2:50:11, 54.31s/it]                                                     {'loss': 0.2167, 'grad_norm': 0.56640625, 'learning_rate': 2.8997631908818556e-06, 'epoch': 1.51}
 76%|███████▌  | 592/780 [8:54:59<2:50:11, 54.31s/it] 76%|███████▌  | 593/780 [8:55:54<2:49:13, 54.30s/it]                                                     {'loss': 0.2415, 'grad_norm': 0.546875, 'learning_rate': 2.8707155170860303e-06, 'epoch': 1.52}
 76%|███████▌  | 593/780 [8:55:54<2:49:13, 54.30s/it] 76%|███████▌  | 594/780 [8:56:48<2:48:18, 54.29s/it]                                                     {'loss': 0.2049, 'grad_norm': 0.515625, 'learning_rate': 2.8417896630916552e-06, 'epoch': 1.52}
 76%|███████▌  | 594/780 [8:56:48<2:48:18, 54.29s/it] 76%|███████▋  | 595/780 [8:57:42<2:47:26, 54.31s/it]                                                     {'loss': 0.2448, 'grad_norm': 0.55078125, 'learning_rate': 2.812986123161762e-06, 'epoch': 1.52}
 76%|███████▋  | 595/780 [8:57:42<2:47:26, 54.31s/it] 76%|███████▋  | 596/780 [8:58:37<2:46:34, 54.32s/it]                                                     {'loss': 0.293, 'grad_norm': 0.75390625, 'learning_rate': 2.7843053894693805e-06, 'epoch': 1.52}
 76%|███████▋  | 596/780 [8:58:37<2:46:34, 54.32s/it] 77%|███████▋  | 597/780 [8:59:31<2:45:40, 54.32s/it]                                                     {'loss': 0.2333, 'grad_norm': 0.53515625, 'learning_rate': 2.7557479520891104e-06, 'epoch': 1.53}
 77%|███████▋  | 597/780 [8:59:31<2:45:40, 54.32s/it] 77%|███████▋  | 598/780 [9:00:25<2:44:39, 54.28s/it]                                                     {'loss': 0.2008, 'grad_norm': 0.51171875, 'learning_rate': 2.7273142989887726e-06, 'epoch': 1.53}
 77%|███████▋  | 598/780 [9:00:25<2:44:39, 54.28s/it] 77%|███████▋  | 599/780 [9:01:19<2:43:46, 54.29s/it]                                                     {'loss': 0.2625, 'grad_norm': 0.53125, 'learning_rate': 2.6990049160210386e-06, 'epoch': 1.53}
 77%|███████▋  | 599/780 [9:01:19<2:43:46, 54.29s/it] 77%|███████▋  | 600/780 [9:02:14<2:42:49, 54.28s/it]                                                     {'loss': 0.2667, 'grad_norm': 0.515625, 'learning_rate': 2.670820286915161e-06, 'epoch': 1.54}
 77%|███████▋  | 600/780 [9:02:14<2:42:49, 54.28s/it] 77%|███████▋  | 601/780 [9:03:08<2:41:40, 54.19s/it]                                                     {'loss': 0.2021, 'grad_norm': 0.53515625, 'learning_rate': 2.642760893268684e-06, 'epoch': 1.54}
 77%|███████▋  | 601/780 [9:03:08<2:41:40, 54.19s/it] 77%|███████▋  | 602/780 [9:04:02<2:40:53, 54.23s/it]                                                     {'loss': 0.2507, 'grad_norm': 0.53125, 'learning_rate': 2.6148272145392294e-06, 'epoch': 1.54}
 77%|███████▋  | 602/780 [9:04:02<2:40:53, 54.23s/it] 77%|███████▋  | 603/780 [9:04:56<2:39:59, 54.23s/it]                                                     {'loss': 0.2557, 'grad_norm': 0.5859375, 'learning_rate': 2.587019728036292e-06, 'epoch': 1.54}
 77%|███████▋  | 603/780 [9:04:56<2:39:59, 54.23s/it] 77%|███████▋  | 604/780 [9:05:50<2:39:07, 54.25s/it]                                                     {'loss': 0.2135, 'grad_norm': 0.515625, 'learning_rate': 2.559338908913096e-06, 'epoch': 1.55}
 77%|███████▋  | 604/780 [9:05:51<2:39:07, 54.25s/it] 78%|███████▊  | 605/780 [9:06:45<2:38:16, 54.26s/it]                                                     {'loss': 0.2658, 'grad_norm': 0.56640625, 'learning_rate': 2.5317852301584642e-06, 'epoch': 1.55}
 78%|███████▊  | 605/780 [9:06:45<2:38:16, 54.26s/it] 78%|███████▊  | 606/780 [9:07:39<2:37:30, 54.31s/it]                                                     {'loss': 0.1998, 'grad_norm': 0.5, 'learning_rate': 2.504359162588741e-06, 'epoch': 1.55}
 78%|███████▊  | 606/780 [9:07:39<2:37:30, 54.31s/it] 78%|███████▊  | 607/780 [9:08:34<2:36:38, 54.32s/it]                                                     {'loss': 0.2105, 'grad_norm': 0.5390625, 'learning_rate': 2.4770611748397556e-06, 'epoch': 1.55}
 78%|███████▊  | 607/780 [9:08:34<2:36:38, 54.32s/it] 78%|███████▊  | 608/780 [9:09:28<2:35:43, 54.32s/it]                                                     {'loss': 0.2123, 'grad_norm': 0.47265625, 'learning_rate': 2.4498917333587934e-06, 'epoch': 1.56}
 78%|███████▊  | 608/780 [9:09:28<2:35:43, 54.32s/it] 78%|███████▊  | 609/780 [9:10:22<2:34:51, 54.34s/it]                                                     {'loss': 0.2216, 'grad_norm': 0.515625, 'learning_rate': 2.422851302396655e-06, 'epoch': 1.56}
 78%|███████▊  | 609/780 [9:10:22<2:34:51, 54.34s/it] 78%|███████▊  | 610/780 [9:11:17<2:33:54, 54.32s/it]                                                     {'loss': 0.2365, 'grad_norm': 0.54296875, 'learning_rate': 2.395940343999691e-06, 'epoch': 1.56}
 78%|███████▊  | 610/780 [9:11:17<2:33:54, 54.32s/it] 78%|███████▊  | 611/780 [9:12:11<2:33:03, 54.34s/it]                                                     {'loss': 0.2264, 'grad_norm': 0.482421875, 'learning_rate': 2.369159318001937e-06, 'epoch': 1.56}
 78%|███████▊  | 611/780 [9:12:11<2:33:03, 54.34s/it] 78%|███████▊  | 612/780 [9:13:05<2:32:04, 54.32s/it]                                                     {'loss': 0.2375, 'grad_norm': 0.57421875, 'learning_rate': 2.3425086820172295e-06, 'epoch': 1.57}
 78%|███████▊  | 612/780 [9:13:05<2:32:04, 54.32s/it] 79%|███████▊  | 613/780 [9:13:59<2:31:06, 54.29s/it]                                                     {'loss': 0.2295, 'grad_norm': 0.515625, 'learning_rate': 2.315988891431412e-06, 'epoch': 1.57}
 79%|███████▊  | 613/780 [9:13:59<2:31:06, 54.29s/it] 79%|███████▊  | 614/780 [9:14:54<2:30:02, 54.23s/it]                                                     {'loss': 0.214, 'grad_norm': 0.58203125, 'learning_rate': 2.2896003993945292e-06, 'epoch': 1.57}
 79%|███████▊  | 614/780 [9:14:54<2:30:02, 54.23s/it] 79%|███████▉  | 615/780 [9:15:48<2:29:08, 54.23s/it]                                                     {'loss': 0.2106, 'grad_norm': 0.5546875, 'learning_rate': 2.263343656813107e-06, 'epoch': 1.57}
 79%|███████▉  | 615/780 [9:15:48<2:29:08, 54.23s/it] 79%|███████▉  | 616/780 [9:16:42<2:28:14, 54.24s/it]                                                     {'loss': 0.2157, 'grad_norm': 0.5234375, 'learning_rate': 2.237219112342426e-06, 'epoch': 1.58}
 79%|███████▉  | 616/780 [9:16:42<2:28:14, 54.24s/it] 79%|███████▉  | 617/780 [9:17:36<2:27:27, 54.28s/it]                                                     {'loss': 0.2135, 'grad_norm': 0.4765625, 'learning_rate': 2.211227212378877e-06, 'epoch': 1.58}
 79%|███████▉  | 617/780 [9:17:36<2:27:27, 54.28s/it] 79%|███████▉  | 618/780 [9:18:31<2:26:33, 54.28s/it]                                                     {'loss': 0.1885, 'grad_norm': 0.4765625, 'learning_rate': 2.18536840105231e-06, 'epoch': 1.58}
 79%|███████▉  | 618/780 [9:18:31<2:26:33, 54.28s/it] 79%|███████▉  | 619/780 [9:19:25<2:25:31, 54.23s/it]                                                     {'loss': 0.2523, 'grad_norm': 0.6328125, 'learning_rate': 2.1596431202184707e-06, 'epoch': 1.58}
 79%|███████▉  | 619/780 [9:19:25<2:25:31, 54.23s/it] 79%|███████▉  | 620/780 [9:20:19<2:24:48, 54.30s/it]                                                     {'loss': 0.212, 'grad_norm': 0.427734375, 'learning_rate': 2.1340518094514262e-06, 'epoch': 1.59}
 79%|███████▉  | 620/780 [9:20:19<2:24:48, 54.30s/it] 80%|███████▉  | 621/780 [9:21:14<2:24:08, 54.39s/it]                                                     {'loss': 0.2238, 'grad_norm': 0.50390625, 'learning_rate': 2.1085949060360654e-06, 'epoch': 1.59}
 80%|███████▉  | 621/780 [9:21:14<2:24:08, 54.39s/it] 80%|███████▉  | 622/780 [9:22:08<2:23:05, 54.34s/it]                                                     {'loss': 0.1956, 'grad_norm': 0.5, 'learning_rate': 2.0832728449606364e-06, 'epoch': 1.59}
 80%|███████▉  | 622/780 [9:22:08<2:23:05, 54.34s/it] 80%|███████▉  | 623/780 [9:23:02<2:22:06, 54.31s/it]                                                     {'loss': 0.1885, 'grad_norm': 0.55078125, 'learning_rate': 2.0580860589092897e-06, 'epoch': 1.59}
 80%|███████▉  | 623/780 [9:23:02<2:22:06, 54.31s/it] 80%|████████  | 624/780 [9:23:57<2:21:17, 54.34s/it]                                                     {'loss': 0.2107, 'grad_norm': 0.5078125, 'learning_rate': 2.033034978254714e-06, 'epoch': 1.6}
 80%|████████  | 624/780 [9:23:57<2:21:17, 54.34s/it] 80%|████████  | 625/780 [9:24:51<2:20:25, 54.36s/it]                                                     {'loss': 0.2158, 'grad_norm': 0.453125, 'learning_rate': 2.008120031050753e-06, 'epoch': 1.6}
 80%|████████  | 625/780 [9:24:51<2:20:25, 54.36s/it] 80%|████████  | 626/780 [9:25:45<2:19:30, 54.36s/it]                                                     {'loss': 0.2291, 'grad_norm': 0.48828125, 'learning_rate': 1.983341643025117e-06, 'epoch': 1.6}
 80%|████████  | 626/780 [9:25:46<2:19:30, 54.36s/it] 80%|████████  | 627/780 [9:26:40<2:18:35, 54.35s/it]                                                     {'loss': 0.221, 'grad_norm': 0.49609375, 'learning_rate': 1.9587002375720864e-06, 'epoch': 1.6}
 80%|████████  | 627/780 [9:26:40<2:18:35, 54.35s/it] 81%|████████  | 628/780 [9:27:34<2:17:32, 54.30s/it]                                                     {'loss': 0.2178, 'grad_norm': 0.6015625, 'learning_rate': 1.934196235745297e-06, 'epoch': 1.61}
 81%|████████  | 628/780 [9:27:34<2:17:32, 54.30s/it] 81%|████████  | 629/780 [9:28:28<2:16:39, 54.30s/it]                                                     {'loss': 0.2153, 'grad_norm': 0.55078125, 'learning_rate': 1.9098300562505266e-06, 'epoch': 1.61}
 81%|████████  | 629/780 [9:28:28<2:16:39, 54.30s/it] 81%|████████  | 630/780 [9:29:23<2:15:45, 54.30s/it]                                                     {'loss': 0.2428, 'grad_norm': 0.498046875, 'learning_rate': 1.8856021154385595e-06, 'epoch': 1.61}
 81%|████████  | 630/780 [9:29:23<2:15:45, 54.30s/it] 81%|████████  | 631/780 [9:30:17<2:14:50, 54.30s/it]                                                     {'loss': 0.2199, 'grad_norm': 0.52734375, 'learning_rate': 1.861512827298051e-06, 'epoch': 1.61}
 81%|████████  | 631/780 [9:30:17<2:14:50, 54.30s/it] 81%|████████  | 632/780 [9:31:11<2:13:53, 54.28s/it]                                                     {'loss': 0.2189, 'grad_norm': 0.56640625, 'learning_rate': 1.8375626034484772e-06, 'epoch': 1.62}
 81%|████████  | 632/780 [9:31:11<2:13:53, 54.28s/it] 81%|████████  | 633/780 [9:32:06<2:13:05, 54.32s/it]                                                     {'loss': 0.2271, 'grad_norm': 0.43359375, 'learning_rate': 1.8137518531330768e-06, 'epoch': 1.62}
 81%|████████  | 633/780 [9:32:06<2:13:05, 54.32s/it] 81%|████████▏ | 634/780 [9:33:00<2:12:10, 54.32s/it]                                                     {'loss': 0.229, 'grad_norm': 0.51171875, 'learning_rate': 1.7900809832118814e-06, 'epoch': 1.62}
 81%|████████▏ | 634/780 [9:33:00<2:12:10, 54.32s/it] 81%|████████▏ | 635/780 [9:33:54<2:11:23, 54.37s/it]                                                     {'loss': 0.2522, 'grad_norm': 0.515625, 'learning_rate': 1.7665503981547428e-06, 'epoch': 1.62}
 81%|████████▏ | 635/780 [9:33:54<2:11:23, 54.37s/it] 82%|████████▏ | 636/780 [9:34:49<2:10:25, 54.35s/it]                                                     {'loss': 0.2268, 'grad_norm': 0.57421875, 'learning_rate': 1.743160500034443e-06, 'epoch': 1.63}
 82%|████████▏ | 636/780 [9:34:49<2:10:25, 54.35s/it] 82%|████████▏ | 637/780 [9:35:43<2:09:25, 54.30s/it]                                                     {'loss': 0.21, 'grad_norm': 0.5234375, 'learning_rate': 1.7199116885197996e-06, 'epoch': 1.63}
 82%|████████▏ | 637/780 [9:35:43<2:09:25, 54.30s/it] 82%|████████▏ | 638/780 [9:36:37<2:08:32, 54.31s/it]                                                     {'loss': 0.2296, 'grad_norm': 0.5390625, 'learning_rate': 1.6968043608688611e-06, 'epoch': 1.63}
 82%|████████▏ | 638/780 [9:36:37<2:08:32, 54.31s/it] 82%|████████▏ | 639/780 [9:37:32<2:07:41, 54.33s/it]                                                     {'loss': 0.2158, 'grad_norm': 0.498046875, 'learning_rate': 1.6738389119220966e-06, 'epoch': 1.63}
 82%|████████▏ | 639/780 [9:37:32<2:07:41, 54.33s/it] 82%|████████▏ | 640/780 [9:38:26<2:06:48, 54.34s/it]                                                     {'loss': 0.2592, 'grad_norm': 0.490234375, 'learning_rate': 1.65101573409567e-06, 'epoch': 1.64}
 82%|████████▏ | 640/780 [9:38:26<2:06:48, 54.34s/it] 82%|████████▏ | 641/780 [9:39:20<2:05:49, 54.31s/it]                                                     {'loss': 0.2168, 'grad_norm': 0.53515625, 'learning_rate': 1.6283352173747148e-06, 'epoch': 1.64}
 82%|████████▏ | 641/780 [9:39:20<2:05:49, 54.31s/it] 82%|████████▏ | 642/780 [9:40:14<2:04:53, 54.30s/it]                                                     {'loss': 0.2187, 'grad_norm': 0.50390625, 'learning_rate': 1.6057977493066868e-06, 'epoch': 1.64}
 82%|████████▏ | 642/780 [9:40:14<2:04:53, 54.30s/it] 82%|████████▏ | 643/780 [9:41:09<2:03:55, 54.27s/it]                                                     {'loss': 0.2322, 'grad_norm': 0.51953125, 'learning_rate': 1.5834037149947291e-06, 'epoch': 1.65}
 82%|████████▏ | 643/780 [9:41:09<2:03:55, 54.27s/it] 83%|████████▎ | 644/780 [9:42:03<2:03:02, 54.28s/it]                                                     {'loss': 0.2261, 'grad_norm': 0.443359375, 'learning_rate': 1.5611534970911058e-06, 'epoch': 1.65}
 83%|████████▎ | 644/780 [9:42:03<2:03:02, 54.28s/it] 83%|████████▎ | 645/780 [9:42:57<2:02:08, 54.29s/it]                                                     {'loss': 0.2668, 'grad_norm': 0.5625, 'learning_rate': 1.5390474757906449e-06, 'epoch': 1.65}
 83%|████████▎ | 645/780 [9:42:57<2:02:08, 54.29s/it] 83%|████████▎ | 646/780 [9:43:51<2:01:11, 54.27s/it]                                                     {'loss': 0.2186, 'grad_norm': 0.58984375, 'learning_rate': 1.5170860288242638e-06, 'epoch': 1.65}
 83%|████████▎ | 646/780 [9:43:52<2:01:11, 54.27s/it] 83%|████████▎ | 647/780 [9:44:46<2:00:11, 54.22s/it]                                                     {'loss': 0.2101, 'grad_norm': 0.56640625, 'learning_rate': 1.4952695314524912e-06, 'epoch': 1.66}
 83%|████████▎ | 647/780 [9:44:46<2:00:11, 54.22s/it] 83%|████████▎ | 648/780 [9:45:40<1:59:16, 54.22s/it]                                                     {'loss': 0.2874, 'grad_norm': 0.55078125, 'learning_rate': 1.4735983564590784e-06, 'epoch': 1.66}
 83%|████████▎ | 648/780 [9:45:40<1:59:16, 54.22s/it] 83%|████████▎ | 649/780 [9:46:34<1:58:07, 54.10s/it]                                                     {'loss': 0.2183, 'grad_norm': 0.458984375, 'learning_rate': 1.4520728741446087e-06, 'epoch': 1.66}
 83%|████████▎ | 649/780 [9:46:34<1:58:07, 54.10s/it] 83%|████████▎ | 650/780 [9:47:28<1:57:19, 54.15s/it]                                                     {'loss': 0.2126, 'grad_norm': 0.48828125, 'learning_rate': 1.4306934523201898e-06, 'epoch': 1.66}
 83%|████████▎ | 650/780 [9:47:28<1:57:19, 54.15s/it] 83%|████████▎ | 651/780 [9:48:22<1:56:27, 54.17s/it]                                                     {'loss': 0.2273, 'grad_norm': 0.486328125, 'learning_rate': 1.409460456301147e-06, 'epoch': 1.67}
 83%|████████▎ | 651/780 [9:48:22<1:56:27, 54.17s/it] 84%|████████▎ | 652/780 [9:49:16<1:55:32, 54.16s/it]                                                     {'loss': 0.292, 'grad_norm': 0.5625, 'learning_rate': 1.3883742489008033e-06, 'epoch': 1.67}
 84%|████████▎ | 652/780 [9:49:16<1:55:32, 54.16s/it] 84%|████████▎ | 653/780 [9:50:10<1:54:34, 54.13s/it]                                                     {'loss': 0.2175, 'grad_norm': 0.51953125, 'learning_rate': 1.367435190424261e-06, 'epoch': 1.67}
 84%|████████▎ | 653/780 [9:50:10<1:54:34, 54.13s/it] 84%|████████▍ | 654/780 [9:51:05<1:53:44, 54.16s/it]                                                     {'loss': 0.2342, 'grad_norm': 0.52734375, 'learning_rate': 1.3466436386622583e-06, 'epoch': 1.67}
 84%|████████▍ | 654/780 [9:51:05<1:53:44, 54.16s/it] 84%|████████▍ | 655/780 [9:51:59<1:52:44, 54.12s/it]                                                     {'loss': 0.2014, 'grad_norm': 0.578125, 'learning_rate': 1.3259999488850473e-06, 'epoch': 1.68}
 84%|████████▍ | 655/780 [9:51:59<1:52:44, 54.12s/it] 84%|████████▍ | 656/780 [9:52:53<1:51:54, 54.15s/it]                                                     {'loss': 0.2404, 'grad_norm': 0.51953125, 'learning_rate': 1.305504473836331e-06, 'epoch': 1.68}
 84%|████████▍ | 656/780 [9:52:53<1:51:54, 54.15s/it] 84%|████████▍ | 657/780 [9:53:47<1:51:05, 54.19s/it]                                                     {'loss': 0.2395, 'grad_norm': 0.51171875, 'learning_rate': 1.2851575637272262e-06, 'epoch': 1.68}
 84%|████████▍ | 657/780 [9:53:47<1:51:05, 54.19s/it] 84%|████████▍ | 658/780 [9:54:41<1:50:06, 54.15s/it]                                                     {'loss': 0.2216, 'grad_norm': 0.54296875, 'learning_rate': 1.2649595662302905e-06, 'epoch': 1.68}
 84%|████████▍ | 658/780 [9:54:41<1:50:06, 54.15s/it] 84%|████████▍ | 659/780 [9:55:35<1:49:16, 54.18s/it]                                                     {'loss': 0.2143, 'grad_norm': 0.50390625, 'learning_rate': 1.2449108264735721e-06, 'epoch': 1.69}
 84%|████████▍ | 659/780 [9:55:35<1:49:16, 54.18s/it] 85%|████████▍ | 660/780 [9:56:30<1:48:25, 54.21s/it]                                                     {'loss': 0.2495, 'grad_norm': 0.53125, 'learning_rate': 1.225011687034714e-06, 'epoch': 1.69}
 85%|████████▍ | 660/780 [9:56:30<1:48:25, 54.21s/it] 85%|████████▍ | 661/780 [9:57:24<1:47:26, 54.17s/it]                                                     {'loss': 0.1908, 'grad_norm': 0.5546875, 'learning_rate': 1.2052624879351105e-06, 'epoch': 1.69}
 85%|████████▍ | 661/780 [9:57:24<1:47:26, 54.17s/it] 85%|████████▍ | 662/780 [9:58:18<1:46:30, 54.15s/it]                                                     {'loss': 0.2506, 'grad_norm': 0.52734375, 'learning_rate': 1.1856635666340788e-06, 'epoch': 1.69}
 85%|████████▍ | 662/780 [9:58:18<1:46:30, 54.15s/it] 85%|████████▌ | 663/780 [9:59:12<1:45:41, 54.20s/it]                                                     {'loss': 0.2297, 'grad_norm': 0.5078125, 'learning_rate': 1.1662152580231145e-06, 'epoch': 1.7}
 85%|████████▌ | 663/780 [9:59:12<1:45:41, 54.20s/it] 85%|████████▌ | 664/780 [10:00:06<1:44:51, 54.24s/it]                                                      {'loss': 0.2544, 'grad_norm': 0.5234375, 'learning_rate': 1.1469178944201475e-06, 'epoch': 1.7}
 85%|████████▌ | 664/780 [10:00:07<1:44:51, 54.24s/it] 85%|████████▌ | 665/780 [10:01:01<1:43:56, 54.23s/it]                                                      {'loss': 0.248, 'grad_norm': 0.52734375, 'learning_rate': 1.127771805563882e-06, 'epoch': 1.7}
 85%|████████▌ | 665/780 [10:01:01<1:43:56, 54.23s/it] 85%|████████▌ | 666/780 [10:01:55<1:43:05, 54.25s/it]                                                      {'loss': 0.214, 'grad_norm': 0.51953125, 'learning_rate': 1.1087773186081474e-06, 'epoch': 1.7}
 85%|████████▌ | 666/780 [10:01:55<1:43:05, 54.25s/it] 86%|████████▌ | 667/780 [10:02:49<1:42:16, 54.31s/it]                                                      {'loss': 0.2332, 'grad_norm': 0.498046875, 'learning_rate': 1.0899347581163222e-06, 'epoch': 1.71}
 86%|████████▌ | 667/780 [10:02:49<1:42:16, 54.31s/it] 86%|████████▌ | 668/780 [10:03:44<1:41:28, 54.36s/it]                                                      {'loss': 0.2033, 'grad_norm': 0.4765625, 'learning_rate': 1.0712444460557713e-06, 'epoch': 1.71}
 86%|████████▌ | 668/780 [10:03:44<1:41:28, 54.36s/it] 86%|████████▌ | 669/780 [10:04:38<1:40:34, 54.37s/it]                                                      {'loss': 0.2439, 'grad_norm': 0.8671875, 'learning_rate': 1.0527067017923654e-06, 'epoch': 1.71}
 86%|████████▌ | 669/780 [10:04:38<1:40:34, 54.37s/it] 86%|████████▌ | 670/780 [10:05:33<1:39:36, 54.33s/it]                                                      {'loss': 0.2167, 'grad_norm': 0.5234375, 'learning_rate': 1.0343218420850021e-06, 'epoch': 1.71}
 86%|████████▌ | 670/780 [10:05:33<1:39:36, 54.33s/it] 86%|████████▌ | 671/780 [10:06:27<1:38:35, 54.27s/it]                                                      {'loss': 0.2052, 'grad_norm': 0.6015625, 'learning_rate': 1.0160901810802114e-06, 'epoch': 1.72}
 86%|████████▌ | 671/780 [10:06:27<1:38:35, 54.27s/it] 86%|████████▌ | 672/780 [10:07:21<1:37:41, 54.27s/it]                                                      {'loss': 0.2408, 'grad_norm': 0.515625, 'learning_rate': 9.980120303067742e-07, 'epoch': 1.72}
 86%|████████▌ | 672/780 [10:07:21<1:37:41, 54.27s/it] 86%|████████▋ | 673/780 [10:08:15<1:36:47, 54.28s/it]                                                      {'loss': 0.1933, 'grad_norm': 0.4765625, 'learning_rate': 9.800876986704111e-07, 'epoch': 1.72}
 86%|████████▋ | 673/780 [10:08:15<1:36:47, 54.28s/it] 86%|████████▋ | 674/780 [10:09:09<1:35:47, 54.23s/it]                                                      {'loss': 0.1776, 'grad_norm': 0.51171875, 'learning_rate': 9.623174924484923e-07, 'epoch': 1.72}
 86%|████████▋ | 674/780 [10:09:09<1:35:47, 54.23s/it] 87%|████████▋ | 675/780 [10:10:04<1:34:52, 54.22s/it]                                                      {'loss': 0.2254, 'grad_norm': 0.53125, 'learning_rate': 9.447017152848126e-07, 'epoch': 1.73}
 87%|████████▋ | 675/780 [10:10:04<1:34:52, 54.22s/it] 87%|████████▋ | 676/780 [10:10:58<1:33:58, 54.22s/it]                                                      {'loss': 0.2305, 'grad_norm': 0.4921875, 'learning_rate': 9.272406681844015e-07, 'epoch': 1.73}
 87%|████████▋ | 676/780 [10:10:58<1:33:58, 54.22s/it] 87%|████████▋ | 677/780 [10:11:52<1:32:51, 54.10s/it]                                                      {'loss': 0.2236, 'grad_norm': 0.5078125, 'learning_rate': 9.09934649508375e-07, 'epoch': 1.73}
 87%|████████▋ | 677/780 [10:11:52<1:32:51, 54.10s/it] 87%|████████▋ | 678/780 [10:12:46<1:31:58, 54.11s/it]                                                      {'loss': 0.2258, 'grad_norm': 0.55859375, 'learning_rate': 8.927839549688466e-07, 'epoch': 1.73}
 87%|████████▋ | 678/780 [10:12:46<1:31:58, 54.11s/it] 87%|████████▋ | 679/780 [10:13:40<1:31:06, 54.12s/it]                                                      {'loss': 0.2363, 'grad_norm': 0.498046875, 'learning_rate': 8.757888776238621e-07, 'epoch': 1.74}
 87%|████████▋ | 679/780 [10:13:40<1:31:06, 54.12s/it] 87%|████████▋ | 680/780 [10:14:34<1:30:14, 54.15s/it]                                                      {'loss': 0.2397, 'grad_norm': 0.58203125, 'learning_rate': 8.589497078724063e-07, 'epoch': 1.74}
 87%|████████▋ | 680/780 [10:14:34<1:30:14, 54.15s/it] 87%|████████▋ | 681/780 [10:15:28<1:29:20, 54.15s/it]                                                      {'loss': 0.1857, 'grad_norm': 0.57421875, 'learning_rate': 8.42266733449425e-07, 'epoch': 1.74}
 87%|████████▋ | 681/780 [10:15:28<1:29:20, 54.15s/it] 87%|████████▋ | 682/780 [10:16:23<1:28:33, 54.22s/it]                                                      {'loss': 0.2392, 'grad_norm': 0.5234375, 'learning_rate': 8.257402394209258e-07, 'epoch': 1.74}
 87%|████████▋ | 682/780 [10:16:23<1:28:33, 54.22s/it] 88%|████████▊ | 683/780 [10:17:17<1:27:37, 54.20s/it]                                                      {'loss': 0.2122, 'grad_norm': 0.55078125, 'learning_rate': 8.093705081790892e-07, 'epoch': 1.75}
 88%|████████▊ | 683/780 [10:17:17<1:27:37, 54.20s/it] 88%|████████▊ | 684/780 [10:18:11<1:26:42, 54.19s/it]                                                      {'loss': 0.2084, 'grad_norm': 0.53125, 'learning_rate': 7.931578194374601e-07, 'epoch': 1.75}
 88%|████████▊ | 684/780 [10:18:11<1:26:42, 54.19s/it] 88%|████████▊ | 685/780 [10:19:05<1:25:49, 54.20s/it]                                                      {'loss': 0.2016, 'grad_norm': 0.53125, 'learning_rate': 7.771024502261526e-07, 'epoch': 1.75}
 88%|████████▊ | 685/780 [10:19:05<1:25:49, 54.20s/it] 88%|████████▊ | 686/780 [10:19:59<1:24:53, 54.18s/it]                                                      {'loss': 0.2601, 'grad_norm': 0.65625, 'learning_rate': 7.612046748871327e-07, 'epoch': 1.76}
 88%|████████▊ | 686/780 [10:19:59<1:24:53, 54.18s/it] 88%|████████▊ | 687/780 [10:20:54<1:24:02, 54.22s/it]                                                      {'loss': 0.2471, 'grad_norm': 0.5390625, 'learning_rate': 7.454647650695157e-07, 'epoch': 1.76}
 88%|████████▊ | 687/780 [10:20:54<1:24:02, 54.22s/it] 88%|████████▊ | 688/780 [10:21:48<1:23:09, 54.23s/it]                                                      {'loss': 0.2397, 'grad_norm': 0.53515625, 'learning_rate': 7.298829897249304e-07, 'epoch': 1.76}
 88%|████████▊ | 688/780 [10:21:48<1:23:09, 54.23s/it] 88%|████████▊ | 689/780 [10:22:42<1:22:15, 54.24s/it]                                                      {'loss': 0.245, 'grad_norm': 0.494140625, 'learning_rate': 7.144596151029304e-07, 'epoch': 1.76}
 88%|████████▊ | 689/780 [10:22:42<1:22:15, 54.24s/it] 88%|████████▊ | 690/780 [10:23:36<1:21:18, 54.21s/it]                                                      {'loss': 0.198, 'grad_norm': 0.5234375, 'learning_rate': 6.991949047464286e-07, 'epoch': 1.77}
 88%|████████▊ | 690/780 [10:23:36<1:21:18, 54.21s/it] 89%|████████▊ | 691/780 [10:24:31<1:20:27, 54.24s/it]                                                      {'loss': 0.2137, 'grad_norm': 0.5390625, 'learning_rate': 6.840891194872112e-07, 'epoch': 1.77}
 89%|████████▊ | 691/780 [10:24:31<1:20:27, 54.24s/it] 89%|████████▊ | 692/780 [10:25:25<1:19:35, 54.26s/it]                                                      {'loss': 0.2067, 'grad_norm': 0.5390625, 'learning_rate': 6.691425174414679e-07, 'epoch': 1.77}
 89%|████████▊ | 692/780 [10:25:25<1:19:35, 54.26s/it] 89%|████████▉ | 693/780 [10:26:19<1:18:43, 54.29s/it]                                                      {'loss': 0.2107, 'grad_norm': 0.46875, 'learning_rate': 6.543553540053926e-07, 'epoch': 1.77}
 89%|████████▉ | 693/780 [10:26:19<1:18:43, 54.29s/it] 89%|████████▉ | 694/780 [10:27:14<1:17:49, 54.30s/it]                                                      {'loss': 0.2632, 'grad_norm': 0.61328125, 'learning_rate': 6.397278818508035e-07, 'epoch': 1.78}
 89%|████████▉ | 694/780 [10:27:14<1:17:49, 54.30s/it] 89%|████████▉ | 695/780 [10:28:08<1:16:56, 54.31s/it]                                                      {'loss': 0.1829, 'grad_norm': 0.6015625, 'learning_rate': 6.252603509208466e-07, 'epoch': 1.78}
 89%|████████▉ | 695/780 [10:28:08<1:16:56, 54.31s/it] 89%|████████▉ | 696/780 [10:29:02<1:16:02, 54.31s/it]                                                      {'loss': 0.2226, 'grad_norm': 0.52734375, 'learning_rate': 6.109530084257043e-07, 'epoch': 1.78}
 89%|████████▉ | 696/780 [10:29:02<1:16:02, 54.31s/it] 89%|████████▉ | 697/780 [10:29:56<1:15:05, 54.29s/it]                                                      {'loss': 0.2539, 'grad_norm': 0.6328125, 'learning_rate': 5.968060988383884e-07, 'epoch': 1.78}
 89%|████████▉ | 697/780 [10:29:56<1:15:05, 54.29s/it] 89%|████████▉ | 698/780 [10:30:51<1:14:17, 54.36s/it]                                                      {'loss': 0.1991, 'grad_norm': 0.51953125, 'learning_rate': 5.828198638905458e-07, 'epoch': 1.79}
 89%|████████▉ | 698/780 [10:30:51<1:14:17, 54.36s/it] 90%|████████▉ | 699/780 [10:31:45<1:13:12, 54.22s/it]                                                      {'loss': 0.2247, 'grad_norm': 0.56640625, 'learning_rate': 5.689945425683474e-07, 'epoch': 1.79}
 90%|████████▉ | 699/780 [10:31:45<1:13:12, 54.22s/it] 90%|████████▉ | 700/780 [10:32:39<1:12:17, 54.22s/it]                                                      {'loss': 0.2029, 'grad_norm': 0.57421875, 'learning_rate': 5.55330371108388e-07, 'epoch': 1.79}
 90%|████████▉ | 700/780 [10:32:39<1:12:17, 54.22s/it] 90%|████████▉ | 701/780 [10:33:33<1:11:21, 54.19s/it]                                                      {'loss': 0.1665, 'grad_norm': 0.494140625, 'learning_rate': 5.418275829936537e-07, 'epoch': 1.79}
 90%|████████▉ | 701/780 [10:33:33<1:11:21, 54.19s/it] 90%|█████████ | 702/780 [10:34:27<1:10:28, 54.21s/it]                                                      {'loss': 0.2105, 'grad_norm': 0.5, 'learning_rate': 5.284864089495423e-07, 'epoch': 1.8}
 90%|█████████ | 702/780 [10:34:28<1:10:28, 54.21s/it] 90%|█████████ | 703/780 [10:35:22<1:09:34, 54.21s/it]                                                      {'loss': 0.2182, 'grad_norm': 0.53125, 'learning_rate': 5.15307076939906e-07, 'epoch': 1.8}
 90%|█████████ | 703/780 [10:35:22<1:09:34, 54.21s/it] 90%|█████████ | 704/780 [10:36:16<1:08:44, 54.27s/it]                                                      {'loss': 0.246, 'grad_norm': 0.53125, 'learning_rate': 5.022898121631681e-07, 'epoch': 1.8}
 90%|█████████ | 704/780 [10:36:16<1:08:44, 54.27s/it] 90%|█████████ | 705/780 [10:37:10<1:07:52, 54.30s/it]                                                      {'loss': 0.2244, 'grad_norm': 0.58203125, 'learning_rate': 4.894348370484648e-07, 'epoch': 1.8}
 90%|█████████ | 705/780 [10:37:10<1:07:52, 54.30s/it] 91%|█████████ | 706/780 [10:38:05<1:07:03, 54.37s/it]                                                      {'loss': 0.2314, 'grad_norm': 0.46875, 'learning_rate': 4.7674237125185597e-07, 'epoch': 1.81}
 91%|█████████ | 706/780 [10:38:05<1:07:03, 54.37s/it] 91%|█████████ | 707/780 [10:38:59<1:06:12, 54.41s/it]                                                      {'loss': 0.2367, 'grad_norm': 0.484375, 'learning_rate': 4.642126316525586e-07, 'epoch': 1.81}
 91%|█████████ | 707/780 [10:39:00<1:06:12, 54.41s/it] 91%|█████████ | 708/780 [10:39:54<1:05:15, 54.38s/it]                                                      {'loss': 0.1981, 'grad_norm': 0.546875, 'learning_rate': 4.518458323492558e-07, 'epoch': 1.81}
 91%|█████████ | 708/780 [10:39:54<1:05:15, 54.38s/it] 91%|█████████ | 709/780 [10:40:48<1:04:21, 54.39s/it]                                                      {'loss': 0.2422, 'grad_norm': 0.5546875, 'learning_rate': 4.396421846564236e-07, 'epoch': 1.81}
 91%|█████████ | 709/780 [10:40:48<1:04:21, 54.39s/it] 91%|█████████ | 710/780 [10:41:43<1:03:26, 54.38s/it]                                                      {'loss': 0.2687, 'grad_norm': 0.5234375, 'learning_rate': 4.276018971007323e-07, 'epoch': 1.82}
 91%|█████████ | 710/780 [10:41:43<1:03:26, 54.38s/it] 91%|█████████ | 711/780 [10:42:37<1:02:28, 54.33s/it]                                                      {'loss': 0.213, 'grad_norm': 1.921875, 'learning_rate': 4.1572517541747294e-07, 'epoch': 1.82}
 91%|█████████ | 711/780 [10:42:37<1:02:28, 54.33s/it] 91%|█████████▏| 712/780 [10:43:31<1:01:30, 54.28s/it]                                                      {'loss': 0.2445, 'grad_norm': 0.5390625, 'learning_rate': 4.040122225470533e-07, 'epoch': 1.82}
 91%|█████████▏| 712/780 [10:43:31<1:01:30, 54.28s/it] 91%|█████████▏| 713/780 [10:44:25<1:00:33, 54.23s/it]                                                      {'loss': 0.2119, 'grad_norm': 0.546875, 'learning_rate': 3.924632386315186e-07, 'epoch': 1.82}
 91%|█████████▏| 713/780 [10:44:25<1:00:33, 54.23s/it] 92%|█████████▏| 714/780 [10:45:19<59:41, 54.26s/it]                                                      {'loss': 0.2387, 'grad_norm': 0.5859375, 'learning_rate': 3.8107842101114067e-07, 'epoch': 1.83}
 92%|█████████▏| 714/780 [10:45:19<59:41, 54.26s/it] 92%|█████████▏| 715/780 [10:46:14<58:47, 54.27s/it]                                                    {'loss': 0.1974, 'grad_norm': 0.4296875, 'learning_rate': 3.698579642210398e-07, 'epoch': 1.83}
 92%|█████████▏| 715/780 [10:46:14<58:47, 54.27s/it] 92%|█████████▏| 716/780 [10:47:08<57:53, 54.28s/it]                                                    {'loss': 0.2187, 'grad_norm': 0.5859375, 'learning_rate': 3.588020599878639e-07, 'epoch': 1.83}
 92%|█████████▏| 716/780 [10:47:08<57:53, 54.28s/it] 92%|█████████▏| 717/780 [10:48:02<56:53, 54.19s/it]                                                    {'loss': 0.1979, 'grad_norm': 0.4921875, 'learning_rate': 3.4791089722651437e-07, 'epoch': 1.83}
 92%|█████████▏| 717/780 [10:48:02<56:53, 54.19s/it] 92%|█████████▏| 718/780 [10:48:56<56:03, 54.25s/it]                                                    {'loss': 0.247, 'grad_norm': 0.625, 'learning_rate': 3.371846620369101e-07, 'epoch': 1.84}
 92%|█████████▏| 718/780 [10:48:56<56:03, 54.25s/it] 92%|█████████▏| 719/780 [10:49:51<55:11, 54.28s/it]                                                    {'loss': 0.2678, 'grad_norm': 0.5859375, 'learning_rate': 3.2662353770081755e-07, 'epoch': 1.84}
 92%|█████████▏| 719/780 [10:49:51<55:11, 54.28s/it] 92%|█████████▏| 720/780 [10:50:45<54:15, 54.26s/it]                                                    {'loss': 0.2597, 'grad_norm': 0.53515625, 'learning_rate': 3.16227704678711e-07, 'epoch': 1.84}
 92%|█████████▏| 720/780 [10:50:45<54:15, 54.26s/it] 92%|█████████▏| 721/780 [10:51:39<53:20, 54.24s/it]                                                    {'loss': 0.1864, 'grad_norm': 0.453125, 'learning_rate': 3.059973406066963e-07, 'epoch': 1.84}
 92%|█████████▏| 721/780 [10:51:39<53:20, 54.24s/it] 93%|█████████▎| 722/780 [10:52:33<52:26, 54.26s/it]                                                    {'loss': 0.2417, 'grad_norm': 0.5390625, 'learning_rate': 2.959326202934665e-07, 'epoch': 1.85}
 93%|█████████▎| 722/780 [10:52:33<52:26, 54.26s/it] 93%|█████████▎| 723/780 [10:53:28<51:31, 54.24s/it]                                                    {'loss': 0.1994, 'grad_norm': 0.59375, 'learning_rate': 2.860337157173243e-07, 'epoch': 1.85}
 93%|█████████▎| 723/780 [10:53:28<51:31, 54.24s/it] 93%|█████████▎| 724/780 [10:54:22<50:38, 54.26s/it]                                                    {'loss': 0.2414, 'grad_norm': 0.486328125, 'learning_rate': 2.7630079602323447e-07, 'epoch': 1.85}
 93%|█████████▎| 724/780 [10:54:22<50:38, 54.26s/it] 93%|█████████▎| 725/780 [10:55:16<49:46, 54.31s/it]                                                    {'loss': 0.2167, 'grad_norm': 0.52734375, 'learning_rate': 2.667340275199426e-07, 'epoch': 1.86}
 93%|█████████▎| 725/780 [10:55:16<49:46, 54.31s/it] 93%|█████████▎| 726/780 [10:56:10<48:50, 54.26s/it]                                                    {'loss': 0.2657, 'grad_norm': 0.6328125, 'learning_rate': 2.573335736771254e-07, 'epoch': 1.86}
 93%|█████████▎| 726/780 [10:56:11<48:50, 54.26s/it] 93%|█████████▎| 727/780 [10:57:05<47:58, 54.32s/it]                                                    {'loss': 0.2461, 'grad_norm': 0.453125, 'learning_rate': 2.4809959512260285e-07, 'epoch': 1.86}
 93%|█████████▎| 727/780 [10:57:05<47:58, 54.32s/it] 93%|█████████▎| 728/780 [10:57:59<47:03, 54.31s/it]                                                    {'loss': 0.2388, 'grad_norm': 0.53515625, 'learning_rate': 2.390322496395914e-07, 'epoch': 1.86}
 93%|█████████▎| 728/780 [10:57:59<47:03, 54.31s/it] 93%|█████████▎| 729/780 [10:58:54<46:10, 54.32s/it]                                                    {'loss': 0.2271, 'grad_norm': 0.48046875, 'learning_rate': 2.3013169216400732e-07, 'epoch': 1.87}
 93%|█████████▎| 729/780 [10:58:54<46:10, 54.32s/it] 94%|█████████▎| 730/780 [10:59:48<45:17, 54.35s/it]                                                    {'loss': 0.207, 'grad_norm': 0.48828125, 'learning_rate': 2.2139807478182008e-07, 'epoch': 1.87}
 94%|█████████▎| 730/780 [10:59:48<45:17, 54.35s/it] 94%|█████████▎| 731/780 [11:00:42<44:21, 54.31s/it]                                                    {'loss': 0.2368, 'grad_norm': 0.6171875, 'learning_rate': 2.1283154672645522e-07, 'epoch': 1.87}
 94%|█████████▎| 731/780 [11:00:42<44:21, 54.31s/it] 94%|█████████▍| 732/780 [11:01:36<43:26, 54.31s/it]                                                    {'loss': 0.2548, 'grad_norm': 0.5546875, 'learning_rate': 2.0443225437624003e-07, 'epoch': 1.87}
 94%|█████████▍| 732/780 [11:01:37<43:26, 54.31s/it] 94%|█████████▍| 733/780 [11:02:31<42:31, 54.29s/it]                                                    {'loss': 0.2095, 'grad_norm': 0.51953125, 'learning_rate': 1.9620034125190645e-07, 'epoch': 1.88}
 94%|█████████▍| 733/780 [11:02:31<42:31, 54.29s/it] 94%|█████████▍| 734/780 [11:03:25<41:37, 54.29s/it]                                                    {'loss': 0.2265, 'grad_norm': 0.52734375, 'learning_rate': 1.881359480141376e-07, 'epoch': 1.88}
 94%|█████████▍| 734/780 [11:03:25<41:37, 54.29s/it] 94%|█████████▍| 735/780 [11:04:19<40:45, 54.34s/it]                                                    {'loss': 0.2547, 'grad_norm': 0.47265625, 'learning_rate': 1.8023921246116405e-07, 'epoch': 1.88}
 94%|█████████▍| 735/780 [11:04:20<40:45, 54.34s/it] 94%|█████████▍| 736/780 [11:05:14<39:52, 54.37s/it]                                                    {'loss': 0.1956, 'grad_norm': 0.470703125, 'learning_rate': 1.7251026952640583e-07, 'epoch': 1.88}
 94%|█████████▍| 736/780 [11:05:14<39:52, 54.37s/it] 94%|█████████▍| 737/780 [11:06:08<39:00, 54.42s/it]                                                    {'loss': 0.2598, 'grad_norm': 0.53515625, 'learning_rate': 1.6494925127617632e-07, 'epoch': 1.89}
 94%|█████████▍| 737/780 [11:06:09<39:00, 54.42s/it] 95%|█████████▍| 738/780 [11:07:03<38:02, 54.34s/it]                                                    {'loss': 0.238, 'grad_norm': 0.640625, 'learning_rate': 1.5755628690741432e-07, 'epoch': 1.89}
 95%|█████████▍| 738/780 [11:07:03<38:02, 54.34s/it] 95%|█████████▍| 739/780 [11:07:57<37:06, 54.30s/it]                                                    {'loss': 0.2275, 'grad_norm': 0.4921875, 'learning_rate': 1.5033150274548325e-07, 'epoch': 1.89}
 95%|█████████▍| 739/780 [11:07:57<37:06, 54.30s/it] 95%|█████████▍| 740/780 [11:08:51<36:11, 54.29s/it]                                                    {'loss': 0.2523, 'grad_norm': 0.58984375, 'learning_rate': 1.4327502224200874e-07, 'epoch': 1.89}
 95%|█████████▍| 740/780 [11:08:51<36:11, 54.29s/it] 95%|█████████▌| 741/780 [11:09:45<35:14, 54.23s/it]                                                    {'loss': 0.2203, 'grad_norm': 0.58984375, 'learning_rate': 1.3638696597277678e-07, 'epoch': 1.9}
 95%|█████████▌| 741/780 [11:09:45<35:14, 54.23s/it] 95%|█████████▌| 742/780 [11:10:39<34:21, 54.24s/it]                                                    {'loss': 0.2298, 'grad_norm': 0.4609375, 'learning_rate': 1.2966745163566108e-07, 'epoch': 1.9}
 95%|█████████▌| 742/780 [11:10:39<34:21, 54.24s/it] 95%|█████████▌| 743/780 [11:11:34<33:26, 54.24s/it]                                                    {'loss': 0.1972, 'grad_norm': 0.5078125, 'learning_rate': 1.231165940486234e-07, 'epoch': 1.9}
 95%|█████████▌| 743/780 [11:11:34<33:26, 54.24s/it] 95%|█████████▌| 744/780 [11:12:28<32:31, 54.21s/it]                                                    {'loss': 0.2172, 'grad_norm': 0.54296875, 'learning_rate': 1.1673450514774421e-07, 'epoch': 1.9}
 95%|█████████▌| 744/780 [11:12:28<32:31, 54.21s/it] 96%|█████████▌| 745/780 [11:13:22<31:38, 54.24s/it]                                                    {'loss': 0.2018, 'grad_norm': 0.51171875, 'learning_rate': 1.1052129398531508e-07, 'epoch': 1.91}
 96%|█████████▌| 745/780 [11:13:22<31:38, 54.24s/it] 96%|█████████▌| 746/780 [11:14:16<30:44, 54.26s/it]                                                    {'loss': 0.2008, 'grad_norm': 0.48828125, 'learning_rate': 1.0447706672797264e-07, 'epoch': 1.91}
 96%|█████████▌| 746/780 [11:14:16<30:44, 54.26s/it] 96%|█████████▌| 747/780 [11:15:11<29:51, 54.29s/it]                                                    {'loss': 0.2082, 'grad_norm': 0.50390625, 'learning_rate': 9.86019266548821e-08, 'epoch': 1.91}
 96%|█████████▌| 747/780 [11:15:11<29:51, 54.29s/it] 96%|█████████▌| 748/780 [11:16:05<28:57, 54.29s/it]                                                    {'loss': 0.2436, 'grad_norm': 0.53125, 'learning_rate': 9.289597415597873e-08, 'epoch': 1.91}
 96%|█████████▌| 748/780 [11:16:05<28:57, 54.29s/it] 96%|█████████▌| 749/780 [11:16:59<28:02, 54.26s/it]                                                    {'loss': 0.2489, 'grad_norm': 0.56640625, 'learning_rate': 8.735930673024806e-08, 'epoch': 1.92}
 96%|█████████▌| 749/780 [11:16:59<28:02, 54.26s/it] 96%|█████████▌| 750/780 [11:17:54<27:08, 54.28s/it]                                                    {'loss': 0.2313, 'grad_norm': 0.5078125, 'learning_rate': 8.19920189840584e-08, 'epoch': 1.92}
 96%|█████████▌| 750/780 [11:17:54<27:08, 54.28s/it] 96%|█████████▋| 751/780 [11:18:48<26:13, 54.27s/it]                                                    {'loss': 0.2199, 'grad_norm': 0.53515625, 'learning_rate': 7.679420262954984e-08, 'epoch': 1.92}
 96%|█████████▋| 751/780 [11:18:48<26:13, 54.27s/it] 96%|█████████▋| 752/780 [11:19:42<25:18, 54.24s/it]                                                    {'loss': 0.207, 'grad_norm': 0.63671875, 'learning_rate': 7.176594648306113e-08, 'epoch': 1.92}
 96%|█████████▋| 752/780 [11:19:42<25:18, 54.24s/it] 97%|█████████▋| 753/780 [11:20:36<24:23, 54.22s/it]                                                    {'loss': 0.2223, 'grad_norm': 0.52734375, 'learning_rate': 6.690733646361858e-08, 'epoch': 1.93}
 97%|█████████▋| 753/780 [11:20:36<24:23, 54.22s/it] 97%|█████████▋| 754/780 [11:21:30<23:29, 54.21s/it]                                                    {'loss': 0.2156, 'grad_norm': 0.5546875, 'learning_rate': 6.221845559146067e-08, 'epoch': 1.93}
 97%|█████████▋| 754/780 [11:21:30<23:29, 54.21s/it] 97%|█████████▋| 755/780 [11:22:25<22:35, 54.22s/it]                                                    {'loss': 0.2145, 'grad_norm': 0.5625, 'learning_rate': 5.769938398662356e-08, 'epoch': 1.93}
 97%|█████████▋| 755/780 [11:22:25<22:35, 54.22s/it] 97%|█████████▋| 756/780 [11:23:19<21:42, 54.25s/it]                                                    {'loss': 0.2306, 'grad_norm': 0.95703125, 'learning_rate': 5.3350198867574424e-08, 'epoch': 1.93}
 97%|█████████▋| 756/780 [11:23:19<21:42, 54.25s/it] 97%|█████████▋| 757/780 [11:24:13<20:47, 54.25s/it]                                                    {'loss': 0.2551, 'grad_norm': 0.5234375, 'learning_rate': 4.9170974549885844e-08, 'epoch': 1.94}
 97%|█████████▋| 757/780 [11:24:13<20:47, 54.25s/it] 97%|█████████▋| 758/780 [11:25:07<19:53, 54.26s/it]                                                    {'loss': 0.2308, 'grad_norm': 0.53125, 'learning_rate': 4.516178244497127e-08, 'epoch': 1.94}
 97%|█████████▋| 758/780 [11:25:08<19:53, 54.26s/it] 97%|█████████▋| 759/780 [11:26:02<18:59, 54.26s/it]                                                    {'loss': 0.2248, 'grad_norm': 0.52734375, 'learning_rate': 4.132269105886155e-08, 'epoch': 1.94}
 97%|█████████▋| 759/780 [11:26:02<18:59, 54.26s/it] 97%|█████████▋| 760/780 [11:26:56<18:05, 54.28s/it]                                                    {'loss': 0.2029, 'grad_norm': 0.49609375, 'learning_rate': 3.7653765991035876e-08, 'epoch': 1.94}
 97%|█████████▋| 760/780 [11:26:56<18:05, 54.28s/it] 98%|█████████▊| 761/780 [11:27:50<17:11, 54.26s/it]                                                    {'loss': 0.2364, 'grad_norm': 0.51171875, 'learning_rate': 3.4155069933301535e-08, 'epoch': 1.95}
 98%|█████████▊| 761/780 [11:27:50<17:11, 54.26s/it] 98%|█████████▊| 762/780 [11:28:44<16:16, 54.22s/it]                                                    {'loss': 0.2733, 'grad_norm': 0.63671875, 'learning_rate': 3.082666266872036e-08, 'epoch': 1.95}
 98%|█████████▊| 762/780 [11:28:44<16:16, 54.22s/it] 98%|█████████▊| 763/780 [11:29:39<15:21, 54.20s/it]                                                    {'loss': 0.1899, 'grad_norm': 0.51953125, 'learning_rate': 2.766860107058844e-08, 'epoch': 1.95}
 98%|█████████▊| 763/780 [11:29:39<15:21, 54.20s/it] 98%|█████████▊| 764/780 [11:30:33<14:27, 54.20s/it]                                                    {'loss': 0.2083, 'grad_norm': 0.54296875, 'learning_rate': 2.468093910146685e-08, 'epoch': 1.95}
 98%|█████████▊| 764/780 [11:30:33<14:27, 54.20s/it] 98%|█████████▊| 765/780 [11:31:27<13:33, 54.22s/it]                                                    {'loss': 0.182, 'grad_norm': 0.50390625, 'learning_rate': 2.1863727812254653e-08, 'epoch': 1.96}
 98%|█████████▊| 765/780 [11:31:27<13:33, 54.22s/it] 98%|█████████▊| 766/780 [11:32:21<12:39, 54.27s/it]                                                    {'loss': 0.2234, 'grad_norm': 0.52734375, 'learning_rate': 1.9217015341318478e-08, 'epoch': 1.96}
 98%|█████████▊| 766/780 [11:32:21<12:39, 54.27s/it] 98%|█████████▊| 767/780 [11:33:16<11:45, 54.28s/it]                                                    {'loss': 0.2196, 'grad_norm': 0.55859375, 'learning_rate': 1.674084691367428e-08, 'epoch': 1.96}
 98%|█████████▊| 767/780 [11:33:16<11:45, 54.28s/it] 98%|█████████▊| 768/780 [11:34:10<10:51, 54.29s/it]                                                    {'loss': 0.2321, 'grad_norm': 0.5078125, 'learning_rate': 1.4435264840205742e-08, 'epoch': 1.97}
 98%|█████████▊| 768/780 [11:34:10<10:51, 54.29s/it] 99%|█████████▊| 769/780 [11:35:04<09:57, 54.28s/it]                                                    {'loss': 0.2014, 'grad_norm': 0.58203125, 'learning_rate': 1.230030851695263e-08, 'epoch': 1.97}
 99%|█████████▊| 769/780 [11:35:04<09:57, 54.28s/it] 99%|█████████▊| 770/780 [11:35:58<09:02, 54.25s/it]                                                    {'loss': 0.234, 'grad_norm': 0.66796875, 'learning_rate': 1.0336014424424667e-08, 'epoch': 1.97}
 99%|█████████▊| 770/780 [11:35:59<09:02, 54.25s/it] 99%|█████████▉| 771/780 [11:36:53<08:08, 54.26s/it]                                                    {'loss': 0.2567, 'grad_norm': 0.54296875, 'learning_rate': 8.542416126989805e-09, 'epoch': 1.97}
 99%|█████████▉| 771/780 [11:36:53<08:08, 54.26s/it] 99%|█████████▉| 772/780 [11:37:47<07:14, 54.27s/it]                                                    {'loss': 0.2386, 'grad_norm': 0.515625, 'learning_rate': 6.919544272293577e-09, 'epoch': 1.98}
 99%|█████████▉| 772/780 [11:37:47<07:14, 54.27s/it] 99%|█████████▉| 773/780 [11:38:41<06:20, 54.29s/it]                                                    {'loss': 0.2043, 'grad_norm': 0.5390625, 'learning_rate': 5.467426590739511e-09, 'epoch': 1.98}
 99%|█████████▉| 773/780 [11:38:41<06:20, 54.29s/it] 99%|█████████▉| 774/780 [11:39:36<05:26, 54.34s/it]                                                    {'loss': 0.2272, 'grad_norm': 0.5390625, 'learning_rate': 4.186087895011737e-09, 'epoch': 1.98}
 99%|█████████▉| 774/780 [11:39:36<05:26, 54.34s/it] 99%|█████████▉| 775/780 [11:40:30<04:31, 54.32s/it]                                                    {'loss': 0.2472, 'grad_norm': 0.515625, 'learning_rate': 3.0755500796531e-09, 'epoch': 1.98}
 99%|█████████▉| 775/780 [11:40:30<04:31, 54.32s/it] 99%|█████████▉| 776/780 [11:41:25<03:37, 54.36s/it]                                                    {'loss': 0.2484, 'grad_norm': 0.490234375, 'learning_rate': 2.1358321206899067e-09, 'epoch': 1.99}
 99%|█████████▉| 776/780 [11:41:25<03:37, 54.36s/it]100%|█████████▉| 777/780 [11:42:19<02:43, 54.39s/it]                                                    {'loss': 0.2689, 'grad_norm': 0.53125, 'learning_rate': 1.3669500753099586e-09, 'epoch': 1.99}
100%|█████████▉| 777/780 [11:42:19<02:43, 54.39s/it]100%|█████████▉| 778/780 [11:43:13<01:48, 54.39s/it]                                                    {'loss': 0.2083, 'grad_norm': 0.51953125, 'learning_rate': 7.689170815872171e-10, 'epoch': 1.99}
100%|█████████▉| 778/780 [11:43:13<01:48, 54.39s/it]100%|█████████▉| 779/780 [11:44:08<00:54, 54.34s/it]                                                    {'loss': 0.2294, 'grad_norm': 0.52734375, 'learning_rate': 3.4174335825420955e-10, 'epoch': 1.99}
100%|█████████▉| 779/780 [11:44:08<00:54, 54.34s/it]100%|██████████| 780/780 [11:45:02<00:00, 54.33s/it]                                                    {'loss': 0.217, 'grad_norm': 0.55859375, 'learning_rate': 8.543620453105305e-11, 'epoch': 2.0}
100%|██████████| 780/780 [11:45:02<00:00, 54.33s/it]                                                    {'train_runtime': 42347.6918, 'train_samples_per_second': 4.723, 'train_steps_per_second': 0.018, 'train_loss': 0.24892638963766586, 'epoch': 2.0}
100%|██████████| 780/780 [11:45:47<00:00, 54.33s/it]100%|██████████| 780/780 [11:45:47<00:00, 54.29s/it]
[2025-04-26 09:49:59,899] [INFO] [launch.py:351:main] Process 75079 exits successfully.
